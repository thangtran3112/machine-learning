{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da4c42cb",
   "metadata": {},
   "source": [
    "## Image Classification - TensorFlow "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2a4074",
   "metadata": {},
   "source": [
    "https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/image_classification_tensorflow/Amazon_TensorFlow_Image_Classification.ipynb\n",
    "\n",
    "\n",
    "https://github.com/aws/amazon-sagemaker-examples/blob/93fc48d21bf88d07853775f11d6ef7db92110549/introduction_to_amazon_algorithms/jumpstart_image_classification/Amazon_JumpStart_Image_Classification.ipynb\n",
    "\n",
    "\n",
    "https://aws.amazon.com/blogs/machine-learning/transfer-learning-for-tensorflow-image-classification-models-in-amazon-sagemaker/\n",
    "\n",
    "\n",
    "https://aws.amazon.com/blogs/machine-learning/run-image-classification-with-amazon-sagemaker-jumpstart/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6ceed41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 85;\n                var nbb_unformatted_code = \"%load_ext nb_black\";\n                var nbb_formatted_code = \"%load_ext nb_black\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "547f0395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 86;\n                var nbb_unformatted_code = \"import json\\nimport logging\\nfrom datetime import datetime\\nimport pandas as pd\";\n                var nbb_formatted_code = \"import json\\nimport logging\\nfrom datetime import datetime\\nimport pandas as pd\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9326763c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 87;\n                var nbb_unformatted_code = \"import boto3\\nimport sagemaker\\nfrom sagemaker import get_execution_role\\nfrom sagemaker import image_uris,  script_uris, model_uris\\nfrom sagemaker import hyperparameters as hyperparameters_module\\nfrom sagemaker.estimator import Estimator\";\n                var nbb_formatted_code = \"import boto3\\nimport sagemaker\\nfrom sagemaker import get_execution_role\\nfrom sagemaker import image_uris, script_uris, model_uris\\nfrom sagemaker import hyperparameters as hyperparameters_module\\nfrom sagemaker.estimator import Estimator\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import image_uris,  script_uris, model_uris\n",
    "from sagemaker import hyperparameters as hyperparameters_module\n",
    "from sagemaker.estimator import Estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d78e5f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 88;\n                var nbb_unformatted_code = \"boto3.set_stream_logger(name=\\\"botocore.credentials\\\", level=logging.WARNING)\";\n                var nbb_formatted_code = \"boto3.set_stream_logger(name=\\\"botocore.credentials\\\", level=logging.WARNING)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boto3.set_stream_logger(name=\"botocore.credentials\", level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "21d68778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-west-2\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 89;\n                var nbb_unformatted_code = \"sess = sagemaker.Session()\\nregion = sess.boto_region_name\\nprint(region)\";\n                var nbb_formatted_code = \"sess = sagemaker.Session()\\nregion = sess.boto_region_name\\nprint(region)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2bce8711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE_S3_BUCKET: sgmkr-images-training\n",
      "REGION: us-west-2\n",
      "SAGE_MAKER_LOCAL_ROLE: arn:aws:iam::654654352356:role/service-role/AmazonSageMaker-ExecutionRole-20250111T085887\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 90;\n                var nbb_unformatted_code = \"import os\\nfrom dotenv import load_dotenv\\nload_dotenv()\\n# Define the bucket name and region\\nIMAGE_S3_BUCKET = os.getenv(\\\"IMAGE_S3_BUCKET\\\")\\nREGION = os.getenv(\\\"REGION\\\")\\nSAGE_MAKER_LOCAL_ROLE = os.getenv(\\\"SAGE_MAKER_LOCAL_ROLE\\\")\\nprint(f\\\"IMAGE_S3_BUCKET: {IMAGE_S3_BUCKET}\\\")\\nprint(f\\\"REGION: {REGION}\\\")\\nprint(f\\\"SAGE_MAKER_LOCAL_ROLE: {SAGE_MAKER_LOCAL_ROLE}\\\")\";\n                var nbb_formatted_code = \"import os\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\n# Define the bucket name and region\\nIMAGE_S3_BUCKET = os.getenv(\\\"IMAGE_S3_BUCKET\\\")\\nREGION = os.getenv(\\\"REGION\\\")\\nSAGE_MAKER_LOCAL_ROLE = os.getenv(\\\"SAGE_MAKER_LOCAL_ROLE\\\")\\nprint(f\\\"IMAGE_S3_BUCKET: {IMAGE_S3_BUCKET}\\\")\\nprint(f\\\"REGION: {REGION}\\\")\\nprint(f\\\"SAGE_MAKER_LOCAL_ROLE: {SAGE_MAKER_LOCAL_ROLE}\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Define the bucket name and region\n",
    "IMAGE_S3_BUCKET = os.getenv(\"IMAGE_S3_BUCKET\")\n",
    "REGION = os.getenv(\"REGION\")\n",
    "SAGE_MAKER_LOCAL_ROLE = os.getenv(\"SAGE_MAKER_LOCAL_ROLE\")\n",
    "print(f\"IMAGE_S3_BUCKET: {IMAGE_S3_BUCKET}\")\n",
    "print(f\"REGION: {REGION}\")\n",
    "print(f\"SAGE_MAKER_LOCAL_ROLE: {SAGE_MAKER_LOCAL_ROLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af909457",
   "metadata": {},
   "source": [
    "## Preparing and upload data to S3\n",
    "* For pytorch data testing, we need to have /train_imgs/rose, /train_imgs/daisy, train_imgs/dandelion in subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9b794752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'sgmkr-images-training' already exists.\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 91;\n                var nbb_unformatted_code = \"# Create the S3 bucket for Images, if it not exists\\nimport boto3\\nfrom botocore.exceptions import ClientError\\n\\n# Initialize S3 client with the specified region\\ns3_client = boto3.client('s3', region_name=REGION)\\n\\n# Function to check if bucket exists\\ndef bucket_exists(bucket_name):\\n    try:\\n        s3_client.head_bucket(Bucket=bucket_name)\\n        return True\\n    except ClientError:\\n        return False\\n\\n# Function to create bucket if it doesn't exist\\ndef create_bucket(bucket_name, region):\\n    try:\\n        if not bucket_exists(bucket_name):\\n            s3_client.create_bucket(\\n                Bucket=bucket_name,\\n                CreateBucketConfiguration={'LocationConstraint': region}\\n            )\\n            print(f\\\"Bucket '{bucket_name}' created successfully in region '{region}'.\\\")\\n        else:\\n            print(f\\\"Bucket '{bucket_name}' already exists.\\\")\\n    except ClientError as e:\\n        print(f\\\"Error creating bucket: {e}\\\")\\n\\n# Create the bucket\\ncreate_bucket(IMAGE_S3_BUCKET, REGION)\";\n                var nbb_formatted_code = \"# Create the S3 bucket for Images, if it not exists\\nimport boto3\\nfrom botocore.exceptions import ClientError\\n\\n# Initialize S3 client with the specified region\\ns3_client = boto3.client(\\\"s3\\\", region_name=REGION)\\n\\n\\n# Function to check if bucket exists\\ndef bucket_exists(bucket_name):\\n    try:\\n        s3_client.head_bucket(Bucket=bucket_name)\\n        return True\\n    except ClientError:\\n        return False\\n\\n\\n# Function to create bucket if it doesn't exist\\ndef create_bucket(bucket_name, region):\\n    try:\\n        if not bucket_exists(bucket_name):\\n            s3_client.create_bucket(\\n                Bucket=bucket_name,\\n                CreateBucketConfiguration={\\\"LocationConstraint\\\": region},\\n            )\\n            print(f\\\"Bucket '{bucket_name}' created successfully in region '{region}'.\\\")\\n        else:\\n            print(f\\\"Bucket '{bucket_name}' already exists.\\\")\\n    except ClientError as e:\\n        print(f\\\"Error creating bucket: {e}\\\")\\n\\n\\n# Create the bucket\\ncreate_bucket(IMAGE_S3_BUCKET, REGION)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the S3 bucket for Images, if it not exists\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Initialize S3 client with the specified region\n",
    "s3_client = boto3.client('s3', region_name=REGION)\n",
    "\n",
    "# Function to check if bucket exists\n",
    "def bucket_exists(bucket_name):\n",
    "    try:\n",
    "        s3_client.head_bucket(Bucket=bucket_name)\n",
    "        return True\n",
    "    except ClientError:\n",
    "        return False\n",
    "\n",
    "# Function to create bucket if it doesn't exist\n",
    "def create_bucket(bucket_name, region):\n",
    "    try:\n",
    "        if not bucket_exists(bucket_name):\n",
    "            s3_client.create_bucket(\n",
    "                Bucket=bucket_name,\n",
    "                CreateBucketConfiguration={'LocationConstraint': region}\n",
    "            )\n",
    "            print(f\"Bucket '{bucket_name}' created successfully in region '{region}'.\")\n",
    "        else:\n",
    "            print(f\"Bucket '{bucket_name}' already exists.\")\n",
    "    except ClientError as e:\n",
    "        print(f\"Error creating bucket: {e}\")\n",
    "\n",
    "# Create the bucket\n",
    "create_bucket(IMAGE_S3_BUCKET, REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7d905d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already downloaded\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 92;\n                var nbb_unformatted_code = \"#!/bin/bash\\nif not os.path.exists('./images/flowers'):\\n  !curl -L -o ./images/flowers.zip https://www.kaggle.com/api/v1/datasets/download/alxmamaev/flowers-recognition\\n  !unzip -o ./images/flowers.zip -d ./images\\n  !rm ./images/flowers.zip\\nelse:\\n  print(\\\"Dataset already downloaded\\\")\";\n                var nbb_formatted_code = \"#!/bin/bash\\nif not os.path.exists(\\\"./images/flowers\\\"):\\n    !curl -L -o ./images/flowers.zip https://www.kaggle.com/api/v1/datasets/download/alxmamaev/flowers-recognition\\n    !unzip -o ./images/flowers.zip -d ./images\\n    !rm ./images/flowers.zip\\nelse:\\n    print(\\\"Dataset already downloaded\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "if not os.path.exists('./images/flowers'):\n",
    "  !curl -L -o ./images/flowers.zip https://www.kaggle.com/api/v1/datasets/download/alxmamaev/flowers-recognition\n",
    "  !unzip -o ./images/flowers.zip -d ./images\n",
    "  !rm ./images/flowers.zip\n",
    "else:\n",
    "  print(\"Dataset already downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c00abfd",
   "metadata": {},
   "source": [
    "## Copy Training Images to S3\n",
    "* For the training dataset, we will upload the first `CLASS_TRAIN_SAMPLES` of 30 images for each flower\n",
    "* S3 structures will look like:\n",
    "```\n",
    "- train_imgs\n",
    "--- daisy\n",
    "--- rose\n",
    "--- dandelion\n",
    "--- sunflower\n",
    "--- tulip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "abb859c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are existing files in the prefix pytorch-classification/train_imgs/daisy. Removing all files...\n",
      "Upload completed 50 images for pytorch-classification/train_imgs/daisy\n",
      "There are existing files in the prefix pytorch-classification/train_imgs/rose. Removing all files...\n",
      "Upload completed 50 images for pytorch-classification/train_imgs/rose\n",
      "There are existing files in the prefix pytorch-classification/train_imgs/dandelion. Removing all files...\n",
      "Upload completed 50 images for pytorch-classification/train_imgs/dandelion\n",
      "There are existing files in the prefix pytorch-classification/train_imgs/sunflower. Removing all files...\n",
      "Upload completed 50 images for pytorch-classification/train_imgs/sunflower\n",
      "There are existing files in the prefix pytorch-classification/train_imgs/tulip. Removing all files...\n",
      "Upload completed 50 images for pytorch-classification/train_imgs/tulip\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 93;\n                var nbb_unformatted_code = \"import shutil\\n\\nDATA_PATH = \\\"pytorch-classification\\\"\\nCLASS_TRAIN_SAMPLES = 50\\n\\n# Upload the images to the S3 bucket, if the prefix doesn't exist\\ns3_train_imgs_path = \\\"s3://{}/{}/{}\\\".format(IMAGE_S3_BUCKET, DATA_PATH, \\\"train_imgs\\\")\\n\\n# 5 different classes of flowers\\nsubfolders = ['daisy', 'rose', 'dandelion', 'sunflower', 'tulip']\\n\\ndef prefix_exists(bucket_name, prefix):\\n  response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\\n  return 'Contents' in response\\n\\nfor subfolder in subfolders:\\n  s3_subfolder = \\\"{}/{}/{}\\\".format(DATA_PATH, \\\"train_imgs\\\", subfolder)\\n  if prefix_exists(IMAGE_S3_BUCKET, s3_subfolder):\\n    # Remove all objects and files inside the S3 prefix path, before uploading the new files\\n    print(f\\\"There are existing files in the prefix {s3_subfolder}. Removing all files...\\\")\\n    command = f\\\"aws s3 rm s3://{IMAGE_S3_BUCKET}/{s3_subfolder}/ --recursive --quiet\\\"\\n    os.system(command)\\n  \\n  # Create a temporary directory to store the first 30 samples\\n  temp_dir = f\\\"./temp_{subfolder}\\\"\\n  os.makedirs(temp_dir, exist_ok=True)\\n  \\n  # Copy the first 30 samples to the temporary directory\\n  src_dir = f\\\"./images/flowers/{subfolder}\\\"\\n  files = os.listdir(src_dir)[:CLASS_TRAIN_SAMPLES]\\n  for file in files:\\n    shutil.copy(os.path.join(src_dir, file), temp_dir)\\n  \\n  # Upload the first 30 samples to the S3 bucket\\n  command = f\\\"aws s3 cp --recursive {temp_dir} s3://{IMAGE_S3_BUCKET}/{s3_subfolder}/ --quiet\\\"\\n  os.system(command)\\n  print(f\\\"Upload completed {CLASS_TRAIN_SAMPLES} images for {s3_subfolder}\\\")\\n  os.system(command)\\n  \\n  # Remove the temporary directory\\n  shutil.rmtree(temp_dir)\";\n                var nbb_formatted_code = \"import shutil\\n\\nDATA_PATH = \\\"pytorch-classification\\\"\\nCLASS_TRAIN_SAMPLES = 50\\n\\n# Upload the images to the S3 bucket, if the prefix doesn't exist\\ns3_train_imgs_path = \\\"s3://{}/{}/{}\\\".format(IMAGE_S3_BUCKET, DATA_PATH, \\\"train_imgs\\\")\\n\\n# 5 different classes of flowers\\nsubfolders = [\\\"daisy\\\", \\\"rose\\\", \\\"dandelion\\\", \\\"sunflower\\\", \\\"tulip\\\"]\\n\\n\\ndef prefix_exists(bucket_name, prefix):\\n    response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\\n    return \\\"Contents\\\" in response\\n\\n\\nfor subfolder in subfolders:\\n    s3_subfolder = \\\"{}/{}/{}\\\".format(DATA_PATH, \\\"train_imgs\\\", subfolder)\\n    if prefix_exists(IMAGE_S3_BUCKET, s3_subfolder):\\n        # Remove all objects and files inside the S3 prefix path, before uploading the new files\\n        print(\\n            f\\\"There are existing files in the prefix {s3_subfolder}. Removing all files...\\\"\\n        )\\n        command = (\\n            f\\\"aws s3 rm s3://{IMAGE_S3_BUCKET}/{s3_subfolder}/ --recursive --quiet\\\"\\n        )\\n        os.system(command)\\n\\n    # Create a temporary directory to store the first 30 samples\\n    temp_dir = f\\\"./temp_{subfolder}\\\"\\n    os.makedirs(temp_dir, exist_ok=True)\\n\\n    # Copy the first 30 samples to the temporary directory\\n    src_dir = f\\\"./images/flowers/{subfolder}\\\"\\n    files = os.listdir(src_dir)[:CLASS_TRAIN_SAMPLES]\\n    for file in files:\\n        shutil.copy(os.path.join(src_dir, file), temp_dir)\\n\\n    # Upload the first 30 samples to the S3 bucket\\n    command = f\\\"aws s3 cp --recursive {temp_dir} s3://{IMAGE_S3_BUCKET}/{s3_subfolder}/ --quiet\\\"\\n    os.system(command)\\n    print(f\\\"Upload completed {CLASS_TRAIN_SAMPLES} images for {s3_subfolder}\\\")\\n    os.system(command)\\n\\n    # Remove the temporary directory\\n    shutil.rmtree(temp_dir)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "DATA_PATH = \"pytorch-classification\"\n",
    "CLASS_TRAIN_SAMPLES = 50\n",
    "\n",
    "# Upload the images to the S3 bucket, if the prefix doesn't exist\n",
    "s3_train_imgs_path = \"s3://{}/{}/{}\".format(IMAGE_S3_BUCKET, DATA_PATH, \"train_imgs\")\n",
    "\n",
    "# 5 different classes of flowers\n",
    "subfolders = ['daisy', 'rose', 'dandelion', 'sunflower', 'tulip']\n",
    "\n",
    "def prefix_exists(bucket_name, prefix):\n",
    "  response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "  return 'Contents' in response\n",
    "\n",
    "for subfolder in subfolders:\n",
    "  s3_subfolder = \"{}/{}/{}\".format(DATA_PATH, \"train_imgs\", subfolder)\n",
    "  if prefix_exists(IMAGE_S3_BUCKET, s3_subfolder):\n",
    "    # Remove all objects and files inside the S3 prefix path, before uploading the new files\n",
    "    print(f\"There are existing files in the prefix {s3_subfolder}. Removing all files...\")\n",
    "    command = f\"aws s3 rm s3://{IMAGE_S3_BUCKET}/{s3_subfolder}/ --recursive --quiet\"\n",
    "    os.system(command)\n",
    "  \n",
    "  # Create a temporary directory to store the first 30 samples\n",
    "  temp_dir = f\"./temp_{subfolder}\"\n",
    "  os.makedirs(temp_dir, exist_ok=True)\n",
    "  \n",
    "  # Copy the first 30 samples to the temporary directory\n",
    "  src_dir = f\"./images/flowers/{subfolder}\"\n",
    "  files = os.listdir(src_dir)[:CLASS_TRAIN_SAMPLES]\n",
    "  for file in files:\n",
    "    shutil.copy(os.path.join(src_dir, file), temp_dir)\n",
    "  \n",
    "  # Upload the first 30 samples to the S3 bucket\n",
    "  command = f\"aws s3 cp --recursive {temp_dir} s3://{IMAGE_S3_BUCKET}/{s3_subfolder}/ --quiet\"\n",
    "  os.system(command)\n",
    "  print(f\"Upload completed {CLASS_TRAIN_SAMPLES} images for {s3_subfolder}\")\n",
    "  os.system(command)\n",
    "  \n",
    "  # Remove the temporary directory\n",
    "  shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0723d5",
   "metadata": {},
   "source": [
    "## Copy validation images\n",
    "* Copy the next `CLASS_VALIDATION_SAMPLES = 15` images from each flower-type subfolder to corresponding S3 destination\n",
    "* Skip the first `CLASS_TRAINING_SAMPLES = 30` for images, which are already used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "af8a575a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are existing files in the prefix pytorch-classification/valid_imgs/daisy. Removing all files...\n",
      "Upload completed 15 images for pytorch-classification/valid_imgs/daisy\n",
      "There are existing files in the prefix pytorch-classification/valid_imgs/rose. Removing all files...\n",
      "Upload completed 15 images for pytorch-classification/valid_imgs/rose\n",
      "There are existing files in the prefix pytorch-classification/valid_imgs/dandelion. Removing all files...\n",
      "Upload completed 15 images for pytorch-classification/valid_imgs/dandelion\n",
      "There are existing files in the prefix pytorch-classification/valid_imgs/sunflower. Removing all files...\n",
      "Upload completed 15 images for pytorch-classification/valid_imgs/sunflower\n",
      "There are existing files in the prefix pytorch-classification/valid_imgs/tulip. Removing all files...\n",
      "Upload completed 15 images for pytorch-classification/valid_imgs/tulip\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 94;\n                var nbb_unformatted_code = \"CLASS_VALIDATION_SAMPLES = 15\\n\\n# Upload the images to the S3 bucket, if the prefix doesn't exist\\ns3_valid_imgs_path = \\\"s3://{}/{}/{}\\\".format(IMAGE_S3_BUCKET, DATA_PATH, \\\"valid_imgs\\\")\\nfor subfolder in subfolders:\\n  s3_subfolder = \\\"{}/{}/{}\\\".format(DATA_PATH, \\\"valid_imgs\\\", subfolder)\\n  if prefix_exists(IMAGE_S3_BUCKET, s3_subfolder):\\n    # Remove all objects and files inside the S3 prefix path, before uploading the new files\\n    print(f\\\"There are existing files in the prefix {s3_subfolder}. Removing all files...\\\")\\n    command = f\\\"aws s3 rm s3://{IMAGE_S3_BUCKET}/{s3_subfolder}/ --recursive --quiet\\\"\\n    os.system(command)\\n  \\n  # Create a temporary directory to store the validation samples\\n  temp_dir = f\\\"./temp_{subfolder}_valid\\\"\\n  os.makedirs(temp_dir, exist_ok=True)\\n  \\n  # Copy the validation samples to the temporary directory\\n  src_dir = f\\\"./images/flowers/{subfolder}\\\"\\n\\n  # Skip the first CLASS_TRAIN_SAMPLES number samples, in each subfolder, which is used for training\\n  files = os.listdir(src_dir)[CLASS_TRAIN_SAMPLES:CLASS_TRAIN_SAMPLES + CLASS_VALIDATION_SAMPLES]\\n  for file in files:\\n    shutil.copy(os.path.join(src_dir, file), temp_dir)\\n  \\n  # Upload the validation samples to the S3 bucket\\n  command = f\\\"aws s3 cp --recursive {temp_dir} s3://{IMAGE_S3_BUCKET}/{s3_subfolder}/ --quiet\\\"\\n  os.system(command)\\n  print(f\\\"Upload completed {CLASS_VALIDATION_SAMPLES} images for {s3_subfolder}\\\")\\n  \\n  # Remove the temporary directory\\n  shutil.rmtree(temp_dir)\";\n                var nbb_formatted_code = \"CLASS_VALIDATION_SAMPLES = 15\\n\\n# Upload the images to the S3 bucket, if the prefix doesn't exist\\ns3_valid_imgs_path = \\\"s3://{}/{}/{}\\\".format(IMAGE_S3_BUCKET, DATA_PATH, \\\"valid_imgs\\\")\\nfor subfolder in subfolders:\\n    s3_subfolder = \\\"{}/{}/{}\\\".format(DATA_PATH, \\\"valid_imgs\\\", subfolder)\\n    if prefix_exists(IMAGE_S3_BUCKET, s3_subfolder):\\n        # Remove all objects and files inside the S3 prefix path, before uploading the new files\\n        print(\\n            f\\\"There are existing files in the prefix {s3_subfolder}. Removing all files...\\\"\\n        )\\n        command = (\\n            f\\\"aws s3 rm s3://{IMAGE_S3_BUCKET}/{s3_subfolder}/ --recursive --quiet\\\"\\n        )\\n        os.system(command)\\n\\n    # Create a temporary directory to store the validation samples\\n    temp_dir = f\\\"./temp_{subfolder}_valid\\\"\\n    os.makedirs(temp_dir, exist_ok=True)\\n\\n    # Copy the validation samples to the temporary directory\\n    src_dir = f\\\"./images/flowers/{subfolder}\\\"\\n\\n    # Skip the first CLASS_TRAIN_SAMPLES number samples, in each subfolder, which is used for training\\n    files = os.listdir(src_dir)[\\n        CLASS_TRAIN_SAMPLES : CLASS_TRAIN_SAMPLES + CLASS_VALIDATION_SAMPLES\\n    ]\\n    for file in files:\\n        shutil.copy(os.path.join(src_dir, file), temp_dir)\\n\\n    # Upload the validation samples to the S3 bucket\\n    command = f\\\"aws s3 cp --recursive {temp_dir} s3://{IMAGE_S3_BUCKET}/{s3_subfolder}/ --quiet\\\"\\n    os.system(command)\\n    print(f\\\"Upload completed {CLASS_VALIDATION_SAMPLES} images for {s3_subfolder}\\\")\\n\\n    # Remove the temporary directory\\n    shutil.rmtree(temp_dir)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CLASS_VALIDATION_SAMPLES = 15\n",
    "\n",
    "# Upload the images to the S3 bucket, if the prefix doesn't exist\n",
    "s3_valid_imgs_path = \"s3://{}/{}/{}\".format(IMAGE_S3_BUCKET, DATA_PATH, \"valid_imgs\")\n",
    "for subfolder in subfolders:\n",
    "  s3_subfolder = \"{}/{}/{}\".format(DATA_PATH, \"valid_imgs\", subfolder)\n",
    "  if prefix_exists(IMAGE_S3_BUCKET, s3_subfolder):\n",
    "    # Remove all objects and files inside the S3 prefix path, before uploading the new files\n",
    "    print(f\"There are existing files in the prefix {s3_subfolder}. Removing all files...\")\n",
    "    command = f\"aws s3 rm s3://{IMAGE_S3_BUCKET}/{s3_subfolder}/ --recursive --quiet\"\n",
    "    os.system(command)\n",
    "  \n",
    "  # Create a temporary directory to store the validation samples\n",
    "  temp_dir = f\"./temp_{subfolder}_valid\"\n",
    "  os.makedirs(temp_dir, exist_ok=True)\n",
    "  \n",
    "  # Copy the validation samples to the temporary directory\n",
    "  src_dir = f\"./images/flowers/{subfolder}\"\n",
    "\n",
    "  # Skip the first CLASS_TRAIN_SAMPLES number samples, in each subfolder, which is used for training\n",
    "  files = os.listdir(src_dir)[CLASS_TRAIN_SAMPLES:CLASS_TRAIN_SAMPLES + CLASS_VALIDATION_SAMPLES]\n",
    "  for file in files:\n",
    "    shutil.copy(os.path.join(src_dir, file), temp_dir)\n",
    "  \n",
    "  # Upload the validation samples to the S3 bucket\n",
    "  command = f\"aws s3 cp --recursive {temp_dir} s3://{IMAGE_S3_BUCKET}/{s3_subfolder}/ --quiet\"\n",
    "  os.system(command)\n",
    "  print(f\"Upload completed {CLASS_VALIDATION_SAMPLES} images for {s3_subfolder}\")\n",
    "  \n",
    "  # Remove the temporary directory\n",
    "  shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a80107f",
   "metadata": {},
   "source": [
    "## After preparing data, we can jumpstart the existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d2fb9614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of models:  10433\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>version</th>\n",
       "      <th>min_version</th>\n",
       "      <th>spec_key</th>\n",
       "      <th>search_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9795</th>\n",
       "      <td>tensorflow-tc-electra-base-1</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>2.75.0</td>\n",
       "      <td>community_models/tensorflow-tc-electra-base-1/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9751</th>\n",
       "      <td>tensorflow-tc-bert-en-wwm-cased-L-24-H-1024-A-...</td>\n",
       "      <td>2.0.0</td>\n",
       "      <td>2.80.0</td>\n",
       "      <td>community_models/tensorflow-tc-bert-en-wwm-cas...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10400</th>\n",
       "      <td>xgboost-classification-model</td>\n",
       "      <td>1.2.0</td>\n",
       "      <td>2.75.0</td>\n",
       "      <td>community_models/xgboost-classification-model/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>huggingface-tc-roberta-base</td>\n",
       "      <td>2.0.5</td>\n",
       "      <td>2.189.0</td>\n",
       "      <td>community_models/huggingface-tc-roberta-base/s...</td>\n",
       "      <td>[Text, Text Classification]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>huggingface-spc-bert-large-uncased</td>\n",
       "      <td>1.2.0</td>\n",
       "      <td>2.75.0</td>\n",
       "      <td>community_models/huggingface-spc-bert-large-un...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10044</th>\n",
       "      <td>tensorflow-tc-small-bert-bert-en-uncased-L-8-H...</td>\n",
       "      <td>2.0.1</td>\n",
       "      <td>2.189.0</td>\n",
       "      <td>community_models/tensorflow-tc-small-bert-bert...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3387</th>\n",
       "      <td>huggingface-txt2img-nitrosocke-nitro-diffusion</td>\n",
       "      <td>2.0.3</td>\n",
       "      <td>2.189.0</td>\n",
       "      <td>community_models/huggingface-txt2img-nitrosock...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>huggingface-sentencesimilarity-bge-small-en-v1-5</td>\n",
       "      <td>1.1.3</td>\n",
       "      <td>2.189.0</td>\n",
       "      <td>community_models/huggingface-sentencesimilarit...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>huggingface-textgeneration-bloomz-1b1</td>\n",
       "      <td>2.0.0</td>\n",
       "      <td>2.189.0</td>\n",
       "      <td>community_models/huggingface-textgeneration-bl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>huggingface-llm-amazon-falconlite2</td>\n",
       "      <td>1.2.3</td>\n",
       "      <td>2.189.0</td>\n",
       "      <td>community_models/huggingface-llm-amazon-falcon...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>huggingface-eqa-roberta-large</td>\n",
       "      <td>2.0.0</td>\n",
       "      <td>2.189.0</td>\n",
       "      <td>community_models/huggingface-eqa-roberta-large...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>huggingface-spc-distilbert-base-cased</td>\n",
       "      <td>2.0.2</td>\n",
       "      <td>2.189.0</td>\n",
       "      <td>community_models/huggingface-spc-distilbert-ba...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>huggingface-llm-mistral-7b-instruct</td>\n",
       "      <td>3.10.0</td>\n",
       "      <td>2.225.0</td>\n",
       "      <td>community_models/huggingface-llm-mistral-7b-in...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9676</th>\n",
       "      <td>tensorflow-spc-experts-bert-wiki-books-1</td>\n",
       "      <td>2.0.0</td>\n",
       "      <td>2.189.0</td>\n",
       "      <td>community_models/tensorflow-spc-experts-bert-w...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>huggingface-textgeneration1-bloom-7b1</td>\n",
       "      <td>1.2.2</td>\n",
       "      <td>2.144.0</td>\n",
       "      <td>community_models/huggingface-textgeneration1-b...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>lightgbm-regression-model</td>\n",
       "      <td>1.3.0</td>\n",
       "      <td>2.75.0</td>\n",
       "      <td>community_models/lightgbm-regression-model/spe...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7464</th>\n",
       "      <td>tensorflow-ic-imagenet-mobilenet-v1-100-160-cl...</td>\n",
       "      <td>3.0.0</td>\n",
       "      <td>2.80.0</td>\n",
       "      <td>community_models/tensorflow-ic-imagenet-mobile...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>huggingface-spc-distilbert-base-cased</td>\n",
       "      <td>1.2.1</td>\n",
       "      <td>2.75.0</td>\n",
       "      <td>community_models/huggingface-spc-distilbert-ba...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8808</th>\n",
       "      <td>tensorflow-icembedding-imagenet-mobilenet-v2-0...</td>\n",
       "      <td>3.0.2</td>\n",
       "      <td>2.189.0</td>\n",
       "      <td>community_models/tensorflow-icembedding-imagen...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10343</th>\n",
       "      <td>tensorflow-tcembedding-talkheads-ggelu-bert-en...</td>\n",
       "      <td>1.1.0</td>\n",
       "      <td>2.75.0</td>\n",
       "      <td>community_models/tensorflow-tcembedding-talkhe...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model_id version min_version  \\\n",
       "9795                        tensorflow-tc-electra-base-1   1.1.2      2.75.0   \n",
       "9751   tensorflow-tc-bert-en-wwm-cased-L-24-H-1024-A-...   2.0.0      2.80.0   \n",
       "10400                       xgboost-classification-model   1.2.0      2.75.0   \n",
       "1978                         huggingface-tc-roberta-base   2.0.5     2.189.0   \n",
       "1607                  huggingface-spc-bert-large-uncased   1.2.0      2.75.0   \n",
       "10044  tensorflow-tc-small-bert-bert-en-uncased-L-8-H...   2.0.1     2.189.0   \n",
       "3387      huggingface-txt2img-nitrosocke-nitro-diffusion   2.0.3     2.189.0   \n",
       "1410    huggingface-sentencesimilarity-bge-small-en-v1-5   1.1.3     2.189.0   \n",
       "2414               huggingface-textgeneration-bloomz-1b1   2.0.0     2.189.0   \n",
       "325                   huggingface-llm-amazon-falconlite2   1.2.3     2.189.0   \n",
       "282                        huggingface-eqa-roberta-large   2.0.0     2.189.0   \n",
       "1625               huggingface-spc-distilbert-base-cased   2.0.2     2.189.0   \n",
       "837                  huggingface-llm-mistral-7b-instruct  3.10.0     2.225.0   \n",
       "9676            tensorflow-spc-experts-bert-wiki-books-1   2.0.0     2.189.0   \n",
       "2568               huggingface-textgeneration1-bloom-7b1   1.2.2     2.144.0   \n",
       "3947                           lightgbm-regression-model   1.3.0      2.75.0   \n",
       "7464   tensorflow-ic-imagenet-mobilenet-v1-100-160-cl...   3.0.0      2.80.0   \n",
       "1630               huggingface-spc-distilbert-base-cased   1.2.1      2.75.0   \n",
       "8808   tensorflow-icembedding-imagenet-mobilenet-v2-0...   3.0.2     2.189.0   \n",
       "10343  tensorflow-tcembedding-talkheads-ggelu-bert-en...   1.1.0      2.75.0   \n",
       "\n",
       "                                                spec_key  \\\n",
       "9795   community_models/tensorflow-tc-electra-base-1/...   \n",
       "9751   community_models/tensorflow-tc-bert-en-wwm-cas...   \n",
       "10400  community_models/xgboost-classification-model/...   \n",
       "1978   community_models/huggingface-tc-roberta-base/s...   \n",
       "1607   community_models/huggingface-spc-bert-large-un...   \n",
       "10044  community_models/tensorflow-tc-small-bert-bert...   \n",
       "3387   community_models/huggingface-txt2img-nitrosock...   \n",
       "1410   community_models/huggingface-sentencesimilarit...   \n",
       "2414   community_models/huggingface-textgeneration-bl...   \n",
       "325    community_models/huggingface-llm-amazon-falcon...   \n",
       "282    community_models/huggingface-eqa-roberta-large...   \n",
       "1625   community_models/huggingface-spc-distilbert-ba...   \n",
       "837    community_models/huggingface-llm-mistral-7b-in...   \n",
       "9676   community_models/tensorflow-spc-experts-bert-w...   \n",
       "2568   community_models/huggingface-textgeneration1-b...   \n",
       "3947   community_models/lightgbm-regression-model/spe...   \n",
       "7464   community_models/tensorflow-ic-imagenet-mobile...   \n",
       "1630   community_models/huggingface-spc-distilbert-ba...   \n",
       "8808   community_models/tensorflow-icembedding-imagen...   \n",
       "10343  community_models/tensorflow-tcembedding-talkhe...   \n",
       "\n",
       "                   search_keywords  \n",
       "9795                           NaN  \n",
       "9751                           NaN  \n",
       "10400                          NaN  \n",
       "1978   [Text, Text Classification]  \n",
       "1607                           NaN  \n",
       "10044                          NaN  \n",
       "3387                           NaN  \n",
       "1410                           NaN  \n",
       "2414                           NaN  \n",
       "325                            NaN  \n",
       "282                            NaN  \n",
       "1625                           NaN  \n",
       "837                            NaN  \n",
       "9676                           NaN  \n",
       "2568                           NaN  \n",
       "3947                           NaN  \n",
       "7464                           NaN  \n",
       "1630                           NaN  \n",
       "8808                           NaN  \n",
       "10343                          NaN  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 95;\n                var nbb_unformatted_code = \"# Checking for all available jumpstart models\\n# download JumpStart model_manifest file. https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-deploy.html\\nboto3.client(\\\"s3\\\").download_file(\\n    f\\\"jumpstart-cache-prod-{region}\\\", \\\"models_manifest.json\\\", \\\"models_manifest.json\\\"\\n)\\nwith open(\\\"models_manifest.json\\\", \\\"rb\\\") as json_file:\\n    model_list = json.load(json_file)\\n\\nprint(\\\"number of models: \\\", len(model_list))\\nmodel_df = pd.DataFrame(model_list)\\nmodel_df.sample(20)\";\n                var nbb_formatted_code = \"# Checking for all available jumpstart models\\n# download JumpStart model_manifest file. https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-deploy.html\\nboto3.client(\\\"s3\\\").download_file(\\n    f\\\"jumpstart-cache-prod-{region}\\\", \\\"models_manifest.json\\\", \\\"models_manifest.json\\\"\\n)\\nwith open(\\\"models_manifest.json\\\", \\\"rb\\\") as json_file:\\n    model_list = json.load(json_file)\\n\\nprint(\\\"number of models: \\\", len(model_list))\\nmodel_df = pd.DataFrame(model_list)\\nmodel_df.sample(20)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking for all available jumpstart models\n",
    "# download JumpStart model_manifest file. https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-deploy.html\n",
    "boto3.client(\"s3\").download_file(\n",
    "    f\"jumpstart-cache-prod-{region}\", \"models_manifest.json\", \"models_manifest.json\"\n",
    ")\n",
    "with open(\"models_manifest.json\", \"rb\") as json_file:\n",
    "    model_list = json.load(json_file)\n",
    "\n",
    "print(\"number of models: \", len(model_list))\n",
    "model_df = pd.DataFrame(model_list)\n",
    "model_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f6d74265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of icmodels available for inference: 162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pytorch-ic-mobilenet-v2']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 96;\n                var nbb_unformatted_code = \"# filter-out all the Image classifications models from the manifest list.\\nic_models = []\\nfor model in model_list:\\n    model_id = model[\\\"model_id\\\"]\\n    if (\\\"-ic-\\\" in model_id or \\\"-ic1-\\\" in model_id) and model_id not in ic_models:\\n        ic_models.append(model_id)\\n\\nprint(f\\\"Number of icmodels available for inference: {len(ic_models)}\\\")\\n\\n# Looking for all the pytorch-ic-mobilenet models\\npytorch_ic_mobinet_models = []\\nfor model_id in ic_models:\\n    if \\\"pytorch-ic-mobilenet\\\" in model_id:\\n        pytorch_ic_mobinet_models.append(model_id)\\npytorch_ic_mobinet_models\";\n                var nbb_formatted_code = \"# filter-out all the Image classifications models from the manifest list.\\nic_models = []\\nfor model in model_list:\\n    model_id = model[\\\"model_id\\\"]\\n    if (\\\"-ic-\\\" in model_id or \\\"-ic1-\\\" in model_id) and model_id not in ic_models:\\n        ic_models.append(model_id)\\n\\nprint(f\\\"Number of icmodels available for inference: {len(ic_models)}\\\")\\n\\n# Looking for all the pytorch-ic-mobilenet models\\npytorch_ic_mobinet_models = []\\nfor model_id in ic_models:\\n    if \\\"pytorch-ic-mobilenet\\\" in model_id:\\n        pytorch_ic_mobinet_models.append(model_id)\\npytorch_ic_mobinet_models\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filter-out all the Image classifications models from the manifest list.\n",
    "ic_models = []\n",
    "for model in model_list:\n",
    "    model_id = model[\"model_id\"]\n",
    "    if (\"-ic-\" in model_id or \"-ic1-\" in model_id) and model_id not in ic_models:\n",
    "        ic_models.append(model_id)\n",
    "\n",
    "print(f\"Number of icmodels available for inference: {len(ic_models)}\")\n",
    "\n",
    "# Looking for all the pytorch-ic-mobilenet models\n",
    "pytorch_ic_mobinet_models = []\n",
    "for model_id in ic_models:\n",
    "    if \"pytorch-ic-mobilenet\" in model_id:\n",
    "        pytorch_ic_mobinet_models.append(model_id)\n",
    "pytorch_ic_mobinet_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d6ee0e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pytorch-ic-mobilenet-v2'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 97;\n                var nbb_unformatted_code = \"model_id = pytorch_ic_mobinet_models[0]\\nmodel_version = \\\"3.0.8\\\" # use a fixed version for stable results. May upgrade to the latest version\\nmodel_id\";\n                var nbb_formatted_code = \"model_id = pytorch_ic_mobinet_models[0]\\nmodel_version = (\\n    \\\"3.0.8\\\"  # use a fixed version for stable results. May upgrade to the latest version\\n)\\nmodel_id\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = pytorch_ic_mobinet_models[0]\n",
    "model_version = \"3.0.8\" # use a fixed version for stable results. May upgrade to the latest version\n",
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3a5e1a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-training:1.10.0-gpu-py38\n",
      "s3://jumpstart-cache-prod-us-west-2/source-directory-tarballs/pytorch/transfer_learning/ic/prepack/v1.1.0/sourcedir.tar.gz\n",
      "s3://jumpstart-cache-prod-us-west-2/pytorch-training/v2.0.0/train-pytorch-ic-mobilenet-v2.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 98;\n                var nbb_unformatted_code = \"train_instance_type = \\\"ml.g4dn.xlarge\\\"\\n\\ntrain_image_uri = image_uris.retrieve(\\n    region=None,\\n    framework=None,\\n    model_id=model_id,\\n    model_version=model_version,\\n    image_scope=\\\"training\\\",\\n    instance_type=train_instance_type,\\n)\\n\\ntrain_source_uri = script_uris.retrieve(\\n    model_id=model_id, model_version=model_version, script_scope=\\\"training\\\"\\n)\\n\\ntrain_model_uri = model_uris.retrieve(\\n    model_id=model_id, model_version=model_version, model_scope=\\\"training\\\"\\n)\\n\\nprint(train_image_uri)\\nprint(train_source_uri)\\nprint(train_model_uri)\";\n                var nbb_formatted_code = \"train_instance_type = \\\"ml.g4dn.xlarge\\\"\\n\\ntrain_image_uri = image_uris.retrieve(\\n    region=None,\\n    framework=None,\\n    model_id=model_id,\\n    model_version=model_version,\\n    image_scope=\\\"training\\\",\\n    instance_type=train_instance_type,\\n)\\n\\ntrain_source_uri = script_uris.retrieve(\\n    model_id=model_id, model_version=model_version, script_scope=\\\"training\\\"\\n)\\n\\ntrain_model_uri = model_uris.retrieve(\\n    model_id=model_id, model_version=model_version, model_scope=\\\"training\\\"\\n)\\n\\nprint(train_image_uri)\\nprint(train_source_uri)\\nprint(train_model_uri)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_instance_type = \"ml.g4dn.xlarge\"\n",
    "\n",
    "train_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    image_scope=\"training\",\n",
    "    instance_type=train_instance_type,\n",
    ")\n",
    "\n",
    "train_source_uri = script_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, script_scope=\"training\"\n",
    ")\n",
    "\n",
    "train_model_uri = model_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, model_scope=\"training\"\n",
    ")\n",
    "\n",
    "print(train_image_uri)\n",
    "print(train_source_uri)\n",
    "print(train_model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4670fee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_only_top_layer': False, 'epochs': '100', 'learning_rate': '0.0003', 'batch_size': '8', 'reinitialize_top_layer': 'Auto', 'data_augmentation': True}\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 107;\n                var nbb_unformatted_code = \"hyperparameters = hyperparameters_module.retrieve_default(\\n    model_id=model_id, model_version=model_version\\n)\\n\\nhyperparameters[\\\"epochs\\\"] = \\\"100\\\"  # Increase the number of epochs\\nhyperparameters[\\\"learning_rate\\\"] = \\\"0.0003\\\"  # Adjust the learning rate\\nhyperparameters[\\\"batch_size\\\"] = \\\"8\\\"  # Adjust the batch size\\nhyperparameters[\\\"train_only_top_layer\\\"] = False  # Fine-tune more layers\\nhyperparameters[\\\"data_augmentation\\\"] = True  # Enable data augmentation if supported\\n\\nprint(hyperparameters)\";\n                var nbb_formatted_code = \"hyperparameters = hyperparameters_module.retrieve_default(\\n    model_id=model_id, model_version=model_version\\n)\\n\\nhyperparameters[\\\"epochs\\\"] = \\\"100\\\"  # Increase the number of epochs\\nhyperparameters[\\\"learning_rate\\\"] = \\\"0.0003\\\"  # Adjust the learning rate\\nhyperparameters[\\\"batch_size\\\"] = \\\"8\\\"  # Adjust the batch size\\nhyperparameters[\\\"train_only_top_layer\\\"] = False  # Fine-tune more layers\\nhyperparameters[\\\"data_augmentation\\\"] = True  # Enable data augmentation if supported\\n\\nprint(hyperparameters)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyperparameters = hyperparameters_module.retrieve_default(\n",
    "    model_id=model_id, model_version=model_version\n",
    ")\n",
    "\n",
    "hyperparameters[\"epochs\"] = \"60\"  # Increase the number of epochs\n",
    "hyperparameters[\"learning_rate\"] = \"0.0003\"  # Adjust the learning rate\n",
    "hyperparameters[\"batch_size\"] = \"8\"  # Adjust the batch size\n",
    "hyperparameters[\"train_only_top_layer\"] = False  # Fine-tune more layers\n",
    "hyperparameters[\"data_augmentation\"] = True  # Enable data augmentation if supported\n",
    "\n",
    "print(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a43e30cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing existing files in the prefix pytorch-classification/model_output...\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 108;\n                var nbb_unformatted_code = \"s3_output_path = \\\"s3://{}/{}/{}\\\".format(IMAGE_S3_BUCKET, DATA_PATH, \\\"model_output\\\")\\n\\nif prefix_exists(IMAGE_S3_BUCKET, \\\"{}/model_output\\\".format(DATA_PATH)):\\n  print(f\\\"Removing existing files in the prefix {DATA_PATH}/model_output...\\\")\\n  command = f\\\"aws s3 rm s3://{IMAGE_S3_BUCKET}/{DATA_PATH}/model_output/ --recursive --quiet\\\"\\n  os.system(command)\";\n                var nbb_formatted_code = \"s3_output_path = \\\"s3://{}/{}/{}\\\".format(IMAGE_S3_BUCKET, DATA_PATH, \\\"model_output\\\")\\n\\nif prefix_exists(IMAGE_S3_BUCKET, \\\"{}/model_output\\\".format(DATA_PATH)):\\n    print(f\\\"Removing existing files in the prefix {DATA_PATH}/model_output...\\\")\\n    command = f\\\"aws s3 rm s3://{IMAGE_S3_BUCKET}/{DATA_PATH}/model_output/ --recursive --quiet\\\"\\n    os.system(command)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s3_output_path = \"s3://{}/{}/{}\".format(IMAGE_S3_BUCKET, DATA_PATH, \"model_output\")\n",
    "\n",
    "if prefix_exists(IMAGE_S3_BUCKET, \"{}/model_output\".format(DATA_PATH)):\n",
    "  print(f\"Removing existing files in the prefix {DATA_PATH}/model_output...\")\n",
    "  command = f\"aws s3 rm s3://{IMAGE_S3_BUCKET}/{DATA_PATH}/model_output/ --recursive --quiet\"\n",
    "  os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f150bee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in SageMaker Studio. Using custom role for local computer\n",
      "arn:aws:iam::654654352356:role/service-role/AmazonSageMaker-ExecutionRole-20250111T085887\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 109;\n                var nbb_unformatted_code = \"if \\\"SM_CURRENT_HOST\\\" in os.environ:\\n  print(\\\"Running in SageMaker Studio\\\")\\n  # only inside Sagemaker notebook Studio\\n  role_arn = sagemaker.get_execution_role()\\nelse:\\n  print(\\\"Not running in SageMaker Studio. Using custom role for local computer\\\")\\n  # in local computer, we will get it from environment variable\\n  role_arn = SAGE_MAKER_LOCAL_ROLE\\n\\nprint(role_arn)\";\n                var nbb_formatted_code = \"if \\\"SM_CURRENT_HOST\\\" in os.environ:\\n    print(\\\"Running in SageMaker Studio\\\")\\n    # only inside Sagemaker notebook Studio\\n    role_arn = sagemaker.get_execution_role()\\nelse:\\n    print(\\\"Not running in SageMaker Studio. Using custom role for local computer\\\")\\n    # in local computer, we will get it from environment variable\\n    role_arn = SAGE_MAKER_LOCAL_ROLE\\n\\nprint(role_arn)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if \"SM_CURRENT_HOST\" in os.environ:\n",
    "  print(\"Running in SageMaker Studio\")\n",
    "  # only inside Sagemaker notebook Studio\n",
    "  role_arn = sagemaker.get_execution_role()\n",
    "else:\n",
    "  print(\"Not running in SageMaker Studio. Using custom role for local computer\")\n",
    "  # in local computer, we will get it from environment variable\n",
    "  role_arn = SAGE_MAKER_LOCAL_ROLE\n",
    "\n",
    "print(role_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6652c46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 111;\n                var nbb_unformatted_code = \"job_name_prefix = \\\"flowers-clf-js-tf-\\\"\\n\\nclf_estimator = Estimator(\\n    role=role_arn,\\n    image_uri=train_image_uri,\\n    source_dir=train_source_uri,\\n    model_uri=train_model_uri,\\n    entry_point=\\\"transfer_learning.py\\\",\\n    instance_count=1,\\n    instance_type=train_instance_type,\\n    max_run=360000,\\n    hyperparameters=hyperparameters,\\n    output_path=s3_output_path,\\n)\";\n                var nbb_formatted_code = \"job_name_prefix = \\\"flowers-clf-js-tf-\\\"\\n\\nclf_estimator = Estimator(\\n    role=role_arn,\\n    image_uri=train_image_uri,\\n    source_dir=train_source_uri,\\n    model_uri=train_model_uri,\\n    entry_point=\\\"transfer_learning.py\\\",\\n    instance_count=1,\\n    instance_type=train_instance_type,\\n    max_run=360000,\\n    hyperparameters=hyperparameters,\\n    output_path=s3_output_path,\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "job_name_prefix = \"flowers-clf-js-tf-\"\n",
    "\n",
    "clf_estimator = Estimator(\n",
    "    role=role_arn,\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_count=1,\n",
    "    instance_type=train_instance_type,\n",
    "    max_run=360000,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=s3_output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0d46384f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training': 's3://sgmkr-images-training/pytorch-classification/train_imgs', 'validation': 's3://sgmkr-images-training/pytorch-classification/valid_imgs'}\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 112;\n                var nbb_unformatted_code = \"s3_train_imgs = \\\"s3://{}/{}/{}\\\".format(IMAGE_S3_BUCKET, DATA_PATH, \\\"train_imgs\\\")\\ns3_valid_imgs = \\\"s3://{}/{}/{}\\\".format(IMAGE_S3_BUCKET, DATA_PATH, \\\"valid_imgs\\\")\\ndata_channels = {\\n    \\\"training\\\": s3_train_imgs,\\n    \\\"validation\\\": s3_valid_imgs,\\n}\\nprint(data_channels)\";\n                var nbb_formatted_code = \"s3_train_imgs = \\\"s3://{}/{}/{}\\\".format(IMAGE_S3_BUCKET, DATA_PATH, \\\"train_imgs\\\")\\ns3_valid_imgs = \\\"s3://{}/{}/{}\\\".format(IMAGE_S3_BUCKET, DATA_PATH, \\\"valid_imgs\\\")\\ndata_channels = {\\n    \\\"training\\\": s3_train_imgs,\\n    \\\"validation\\\": s3_valid_imgs,\\n}\\nprint(data_channels)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s3_train_imgs = \"s3://{}/{}/{}\".format(IMAGE_S3_BUCKET, DATA_PATH, \"train_imgs\")\n",
    "s3_valid_imgs = \"s3://{}/{}/{}\".format(IMAGE_S3_BUCKET, DATA_PATH, \"valid_imgs\")\n",
    "data_channels = {\n",
    "    \"training\": s3_train_imgs,\n",
    "    \"validation\": s3_valid_imgs,\n",
    "}\n",
    "print(data_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8032dbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flowers-clf-js-tf-2025-01-12-21-43-15\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 113;\n                var nbb_unformatted_code = \"timestamp = (\\n    str(datetime.now().replace(microsecond=0)).replace(\\\" \\\", \\\"-\\\").replace(\\\":\\\", \\\"-\\\")\\n)\\njob_name = job_name_prefix + timestamp\\nprint(job_name)\";\n                var nbb_formatted_code = \"timestamp = (\\n    str(datetime.now().replace(microsecond=0)).replace(\\\" \\\", \\\"-\\\").replace(\\\":\\\", \\\"-\\\")\\n)\\njob_name = job_name_prefix + timestamp\\nprint(job_name)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timestamp = (\n",
    "    str(datetime.now().replace(microsecond=0)).replace(\" \", \"-\").replace(\":\", \"-\")\n",
    ")\n",
    "job_name = job_name_prefix + timestamp\n",
    "print(job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "68d5816e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/12/25 21:43:17] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/telemetry/telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/telemetry/telemetry_logging.py#90\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">90</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/12/25 21:43:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=499062;file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/telemetry/telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=906333;file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/telemetry/telemetry_logging.py#90\u001b\\\u001b[2m90\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name: flowers-clf-js-tf-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> <a href=\"file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name: flowers-clf-js-tf-\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m21\u001b[0m-\u001b[1;36m43\u001b[0m-\u001b[1;36m15\u001b[0m \u001b]8;id=291846;file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=409671;file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-13 05:43:18 Starting - Starting the training job...\n",
      "2025-01-13 05:43:32 Starting - Preparing the instances for training...\n",
      "2025-01-13 05:44:13 Downloading - Downloading the training image.................bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2025-01-13 05:47:11,555 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2025-01-13 05:47:11,584 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2025-01-13 05:47:11,589 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2025-01-13 05:47:11,744 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "/opt/conda/bin/python3.8 -m pip install -r requirements.txt\n",
      "Processing ./lib/sagemaker_jumpstart_prepack_script_utilities/sagemaker_jumpstart_prepack_script_utilities-1.0.0-py2.py3-none-any.whl\n",
      "Installing collected packages: sagemaker-jumpstart-prepack-script-utilities\n",
      "Successfully installed sagemaker-jumpstart-prepack-script-utilities-1.0.0\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "2025-01-13 05:47:13,285 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"model\": \"/opt/ml/input/data/model\",\n",
      "        \"training\": \"/opt/ml/input/data/training\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": \"8\",\n",
      "        \"data_augmentation\": true,\n",
      "        \"epochs\": \"100\",\n",
      "        \"learning_rate\": \"0.0003\",\n",
      "        \"reinitialize_top_layer\": \"Auto\",\n",
      "        \"train_only_top_layer\": false\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"model\": {\n",
      "            \"ContentType\": \"application/x-sagemaker-model\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"flowers-clf-js-tf-2025-01-12-21-43-15\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://jumpstart-cache-prod-us-west-2/source-directory-tarballs/pytorch/transfer_learning/ic/prepack/v1.1.0/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"transfer_learning\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"transfer_learning.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"batch_size\":\"8\",\"data_augmentation\":true,\"epochs\":\"100\",\"learning_rate\":\"0.0003\",\"reinitialize_top_layer\":\"Auto\",\"train_only_top_layer\":false}\n",
      "SM_USER_ENTRY_POINT=transfer_learning.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"model\",\"training\",\"validation\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_MODULE_NAME=transfer_learning\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=4\n",
      "SM_NUM_GPUS=1\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://jumpstart-cache-prod-us-west-2/source-directory-tarballs/pytorch/transfer_learning/ic/prepack/v1.1.0/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"model\":\"/opt/ml/input/data/model\",\"training\":\"/opt/ml/input/data/training\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":\"8\",\"data_augmentation\":true,\"epochs\":\"100\",\"learning_rate\":\"0.0003\",\"reinitialize_top_layer\":\"Auto\",\"train_only_top_layer\":false},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"flowers-clf-js-tf-2025-01-12-21-43-15\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://jumpstart-cache-prod-us-west-2/source-directory-tarballs/pytorch/transfer_learning/ic/prepack/v1.1.0/sourcedir.tar.gz\",\"module_name\":\"transfer_learning\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"transfer_learning.py\"}\n",
      "SM_USER_ARGS=[\"--batch_size\",\"8\",\"--data_augmentation\",\"True\",\"--epochs\",\"100\",\"--learning_rate\",\"0.0003\",\"--reinitialize_top_layer\",\"Auto\",\"--train_only_top_layer\",\"False\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_MODEL=/opt/ml/input/data/model\n",
      "SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "SM_HP_BATCH_SIZE=8\n",
      "SM_HP_DATA_AUGMENTATION=true\n",
      "SM_HP_EPOCHS=100\n",
      "SM_HP_LEARNING_RATE=0.0003\n",
      "SM_HP_REINITIALIZE_TOP_LAYER=Auto\n",
      "SM_HP_TRAIN_ONLY_TOP_LAYER=false\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.8 transfer_learning.py --batch_size 8 --data_augmentation True --epochs 100 --learning_rate 0.0003 --reinitialize_top_layer Auto --train_only_top_layer False\n",
      "dataset sizes: {'train': 200, 'val': 50}\n",
      "prediction class indices mapping to input training data labels: {'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}\n",
      "'_input_model_extracted/__models_info__.json' file could not be found.\n",
      "\n",
      "2025-01-13 05:47:00 Training - Training image download completed. Training in progress.Epoch 0/99\n",
      "[2025-01-13 05:47:17.554 algo-1:39 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2025-01-13 05:47:17.641 algo-1:39 INFO profiler_config_parser.py:102] User has disabled profiler.\n",
      "[2025-01-13 05:47:17.641 algo-1:39 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[2025-01-13 05:47:17.641 algo-1:39 INFO hook.py:200] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[2025-01-13 05:47:17.642 algo-1:39 INFO hook.py:255] Saving to /opt/ml/output/tensors\n",
      "[2025-01-13 05:47:17.642 algo-1:39 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "[2025-01-13 05:47:17.977 algo-1:39 INFO hook.py:591] name:features.0.0.weight count_params:864\n",
      "[2025-01-13 05:47:17.977 algo-1:39 INFO hook.py:591] name:features.0.1.weight count_params:32\n",
      "[2025-01-13 05:47:17.977 algo-1:39 INFO hook.py:591] name:features.0.1.bias count_params:32\n",
      "[2025-01-13 05:47:17.977 algo-1:39 INFO hook.py:591] name:features.1.conv.0.0.weight count_params:288\n",
      "[2025-01-13 05:47:17.978 algo-1:39 INFO hook.py:591] name:features.1.conv.0.1.weight count_params:32\n",
      "[2025-01-13 05:47:17.978 algo-1:39 INFO hook.py:591] name:features.1.conv.0.1.bias count_params:32\n",
      "[2025-01-13 05:47:17.978 algo-1:39 INFO hook.py:591] name:features.1.conv.1.weight count_params:512\n",
      "[2025-01-13 05:47:17.978 algo-1:39 INFO hook.py:591] name:features.1.conv.2.weight count_params:16\n",
      "[2025-01-13 05:47:17.978 algo-1:39 INFO hook.py:591] name:features.1.conv.2.bias count_params:16\n",
      "[2025-01-13 05:47:17.978 algo-1:39 INFO hook.py:591] name:features.2.conv.0.0.weight count_params:1536\n",
      "[2025-01-13 05:47:17.978 algo-1:39 INFO hook.py:591] name:features.2.conv.0.1.weight count_params:96\n",
      "[2025-01-13 05:47:17.978 algo-1:39 INFO hook.py:591] name:features.2.conv.0.1.bias count_params:96\n",
      "[2025-01-13 05:47:17.978 algo-1:39 INFO hook.py:591] name:features.2.conv.1.0.weight count_params:864\n",
      "[2025-01-13 05:47:17.978 algo-1:39 INFO hook.py:591] name:features.2.conv.1.1.weight count_params:96\n",
      "[2025-01-13 05:47:17.978 algo-1:39 INFO hook.py:591] name:features.2.conv.1.1.bias count_params:96\n",
      "[2025-01-13 05:47:17.978 algo-1:39 INFO hook.py:591] name:features.2.conv.2.weight count_params:2304\n",
      "[2025-01-13 05:47:17.978 algo-1:39 INFO hook.py:591] name:features.2.conv.3.weight count_params:24\n",
      "[2025-01-13 05:47:17.978 algo-1:39 INFO hook.py:591] name:features.2.conv.3.bias count_params:24\n",
      "[2025-01-13 05:47:17.978 algo-1:39 INFO hook.py:591] name:features.3.conv.0.0.weight count_params:3456\n",
      "[2025-01-13 05:47:17.978 algo-1:39 INFO hook.py:591] name:features.3.conv.0.1.weight count_params:144\n",
      "[2025-01-13 05:47:17.978 algo-1:39 INFO hook.py:591] name:features.3.conv.0.1.bias count_params:144\n",
      "[2025-01-13 05:47:17.978 algo-1:39 INFO hook.py:591] name:features.3.conv.1.0.weight count_params:1296\n",
      "[2025-01-13 05:47:17.978 algo-1:39 INFO hook.py:591] name:features.3.conv.1.1.weight count_params:144\n",
      "[2025-01-13 05:47:17.978 algo-1:39 INFO hook.py:591] name:features.3.conv.1.1.bias count_params:144\n",
      "[2025-01-13 05:47:17.978 algo-1:39 INFO hook.py:591] name:features.3.conv.2.weight count_params:3456\n",
      "[2025-01-13 05:47:17.978 algo-1:39 INFO hook.py:591] name:features.3.conv.3.weight count_params:24\n",
      "[2025-01-13 05:47:17.979 algo-1:39 INFO hook.py:591] name:features.3.conv.3.bias count_params:24\n",
      "[2025-01-13 05:47:17.979 algo-1:39 INFO hook.py:591] name:features.4.conv.0.0.weight count_params:3456\n",
      "[2025-01-13 05:47:17.979 algo-1:39 INFO hook.py:591] name:features.4.conv.0.1.weight count_params:144\n",
      "[2025-01-13 05:47:17.979 algo-1:39 INFO hook.py:591] name:features.4.conv.0.1.bias count_params:144\n",
      "[2025-01-13 05:47:17.979 algo-1:39 INFO hook.py:591] name:features.4.conv.1.0.weight count_params:1296\n",
      "[2025-01-13 05:47:17.979 algo-1:39 INFO hook.py:591] name:features.4.conv.1.1.weight count_params:144\n",
      "[2025-01-13 05:47:17.979 algo-1:39 INFO hook.py:591] name:features.4.conv.1.1.bias count_params:144\n",
      "[2025-01-13 05:47:17.979 algo-1:39 INFO hook.py:591] name:features.4.conv.2.weight count_params:4608\n",
      "[2025-01-13 05:47:17.979 algo-1:39 INFO hook.py:591] name:features.4.conv.3.weight count_params:32\n",
      "[2025-01-13 05:47:17.979 algo-1:39 INFO hook.py:591] name:features.4.conv.3.bias count_params:32\n",
      "[2025-01-13 05:47:17.979 algo-1:39 INFO hook.py:591] name:features.5.conv.0.0.weight count_params:6144\n",
      "[2025-01-13 05:47:17.979 algo-1:39 INFO hook.py:591] name:features.5.conv.0.1.weight count_params:192\n",
      "[2025-01-13 05:47:17.979 algo-1:39 INFO hook.py:591] name:features.5.conv.0.1.bias count_params:192\n",
      "[2025-01-13 05:47:17.979 algo-1:39 INFO hook.py:591] name:features.5.conv.1.0.weight count_params:1728\n",
      "[2025-01-13 05:47:17.979 algo-1:39 INFO hook.py:591] name:features.5.conv.1.1.weight count_params:192\n",
      "[2025-01-13 05:47:17.979 algo-1:39 INFO hook.py:591] name:features.5.conv.1.1.bias count_params:192\n",
      "[2025-01-13 05:47:17.979 algo-1:39 INFO hook.py:591] name:features.5.conv.2.weight count_params:6144\n",
      "[2025-01-13 05:47:17.979 algo-1:39 INFO hook.py:591] name:features.5.conv.3.weight count_params:32\n",
      "[2025-01-13 05:47:17.979 algo-1:39 INFO hook.py:591] name:features.5.conv.3.bias count_params:32\n",
      "[2025-01-13 05:47:17.979 algo-1:39 INFO hook.py:591] name:features.6.conv.0.0.weight count_params:6144\n",
      "[2025-01-13 05:47:17.979 algo-1:39 INFO hook.py:591] name:features.6.conv.0.1.weight count_params:192\n",
      "[2025-01-13 05:47:17.979 algo-1:39 INFO hook.py:591] name:features.6.conv.0.1.bias count_params:192\n",
      "[2025-01-13 05:47:17.980 algo-1:39 INFO hook.py:591] name:features.6.conv.1.0.weight count_params:1728\n",
      "[2025-01-13 05:47:17.980 algo-1:39 INFO hook.py:591] name:features.6.conv.1.1.weight count_params:192\n",
      "[2025-01-13 05:47:17.980 algo-1:39 INFO hook.py:591] name:features.6.conv.1.1.bias count_params:192\n",
      "[2025-01-13 05:47:17.980 algo-1:39 INFO hook.py:591] name:features.6.conv.2.weight count_params:6144\n",
      "[2025-01-13 05:47:17.980 algo-1:39 INFO hook.py:591] name:features.6.conv.3.weight count_params:32\n",
      "[2025-01-13 05:47:17.980 algo-1:39 INFO hook.py:591] name:features.6.conv.3.bias count_params:32\n",
      "[2025-01-13 05:47:17.980 algo-1:39 INFO hook.py:591] name:features.7.conv.0.0.weight count_params:6144\n",
      "[2025-01-13 05:47:17.980 algo-1:39 INFO hook.py:591] name:features.7.conv.0.1.weight count_params:192\n",
      "[2025-01-13 05:47:17.980 algo-1:39 INFO hook.py:591] name:features.7.conv.0.1.bias count_params:192\n",
      "[2025-01-13 05:47:17.980 algo-1:39 INFO hook.py:591] name:features.7.conv.1.0.weight count_params:1728\n",
      "[2025-01-13 05:47:17.980 algo-1:39 INFO hook.py:591] name:features.7.conv.1.1.weight count_params:192\n",
      "[2025-01-13 05:47:17.980 algo-1:39 INFO hook.py:591] name:features.7.conv.1.1.bias count_params:192\n",
      "[2025-01-13 05:47:17.980 algo-1:39 INFO hook.py:591] name:features.7.conv.2.weight count_params:12288\n",
      "[2025-01-13 05:47:17.980 algo-1:39 INFO hook.py:591] name:features.7.conv.3.weight count_params:64\n",
      "[2025-01-13 05:47:17.980 algo-1:39 INFO hook.py:591] name:features.7.conv.3.bias count_params:64\n",
      "[2025-01-13 05:47:17.980 algo-1:39 INFO hook.py:591] name:features.8.conv.0.0.weight count_params:24576\n",
      "[2025-01-13 05:47:17.980 algo-1:39 INFO hook.py:591] name:features.8.conv.0.1.weight count_params:384\n",
      "[2025-01-13 05:47:17.980 algo-1:39 INFO hook.py:591] name:features.8.conv.0.1.bias count_params:384\n",
      "[2025-01-13 05:47:17.980 algo-1:39 INFO hook.py:591] name:features.8.conv.1.0.weight count_params:3456\n",
      "[2025-01-13 05:47:17.980 algo-1:39 INFO hook.py:591] name:features.8.conv.1.1.weight count_params:384\n",
      "[2025-01-13 05:47:17.980 algo-1:39 INFO hook.py:591] name:features.8.conv.1.1.bias count_params:384\n",
      "[2025-01-13 05:47:17.981 algo-1:39 INFO hook.py:591] name:features.8.conv.2.weight count_params:24576\n",
      "[2025-01-13 05:47:17.981 algo-1:39 INFO hook.py:591] name:features.8.conv.3.weight count_params:64\n",
      "[2025-01-13 05:47:17.981 algo-1:39 INFO hook.py:591] name:features.8.conv.3.bias count_params:64\n",
      "[2025-01-13 05:47:17.981 algo-1:39 INFO hook.py:591] name:features.9.conv.0.0.weight count_params:24576\n",
      "[2025-01-13 05:47:17.981 algo-1:39 INFO hook.py:591] name:features.9.conv.0.1.weight count_params:384\n",
      "[2025-01-13 05:47:17.981 algo-1:39 INFO hook.py:591] name:features.9.conv.0.1.bias count_params:384\n",
      "[2025-01-13 05:47:17.981 algo-1:39 INFO hook.py:591] name:features.9.conv.1.0.weight count_params:3456\n",
      "[2025-01-13 05:47:17.981 algo-1:39 INFO hook.py:591] name:features.9.conv.1.1.weight count_params:384\n",
      "[2025-01-13 05:47:17.981 algo-1:39 INFO hook.py:591] name:features.9.conv.1.1.bias count_params:384\n",
      "[2025-01-13 05:47:17.981 algo-1:39 INFO hook.py:591] name:features.9.conv.2.weight count_params:24576\n",
      "[2025-01-13 05:47:17.981 algo-1:39 INFO hook.py:591] name:features.9.conv.3.weight count_params:64\n",
      "[2025-01-13 05:47:17.981 algo-1:39 INFO hook.py:591] name:features.9.conv.3.bias count_params:64\n",
      "[2025-01-13 05:47:17.981 algo-1:39 INFO hook.py:591] name:features.10.conv.0.0.weight count_params:24576\n",
      "[2025-01-13 05:47:17.981 algo-1:39 INFO hook.py:591] name:features.10.conv.0.1.weight count_params:384\n",
      "[2025-01-13 05:47:17.981 algo-1:39 INFO hook.py:591] name:features.10.conv.0.1.bias count_params:384\n",
      "[2025-01-13 05:47:17.981 algo-1:39 INFO hook.py:591] name:features.10.conv.1.0.weight count_params:3456\n",
      "[2025-01-13 05:47:17.981 algo-1:39 INFO hook.py:591] name:features.10.conv.1.1.weight count_params:384\n",
      "[2025-01-13 05:47:17.981 algo-1:39 INFO hook.py:591] name:features.10.conv.1.1.bias count_params:384\n",
      "[2025-01-13 05:47:17.981 algo-1:39 INFO hook.py:591] name:features.10.conv.2.weight count_params:24576\n",
      "[2025-01-13 05:47:17.981 algo-1:39 INFO hook.py:591] name:features.10.conv.3.weight count_params:64\n",
      "[2025-01-13 05:47:17.981 algo-1:39 INFO hook.py:591] name:features.10.conv.3.bias count_params:64\n",
      "[2025-01-13 05:47:17.981 algo-1:39 INFO hook.py:591] name:features.11.conv.0.0.weight count_params:24576\n",
      "[2025-01-13 05:47:17.982 algo-1:39 INFO hook.py:591] name:features.11.conv.0.1.weight count_params:384\n",
      "[2025-01-13 05:47:17.982 algo-1:39 INFO hook.py:591] name:features.11.conv.0.1.bias count_params:384\n",
      "[2025-01-13 05:47:17.982 algo-1:39 INFO hook.py:591] name:features.11.conv.1.0.weight count_params:3456\n",
      "[2025-01-13 05:47:17.982 algo-1:39 INFO hook.py:591] name:features.11.conv.1.1.weight count_params:384\n",
      "[2025-01-13 05:47:17.982 algo-1:39 INFO hook.py:591] name:features.11.conv.1.1.bias count_params:384\n",
      "[2025-01-13 05:47:17.982 algo-1:39 INFO hook.py:591] name:features.11.conv.2.weight count_params:36864\n",
      "[2025-01-13 05:47:17.982 algo-1:39 INFO hook.py:591] name:features.11.conv.3.weight count_params:96\n",
      "[2025-01-13 05:47:17.982 algo-1:39 INFO hook.py:591] name:features.11.conv.3.bias count_params:96\n",
      "[2025-01-13 05:47:17.982 algo-1:39 INFO hook.py:591] name:features.12.conv.0.0.weight count_params:55296\n",
      "[2025-01-13 05:47:17.982 algo-1:39 INFO hook.py:591] name:features.12.conv.0.1.weight count_params:576\n",
      "[2025-01-13 05:47:17.982 algo-1:39 INFO hook.py:591] name:features.12.conv.0.1.bias count_params:576\n",
      "[2025-01-13 05:47:17.982 algo-1:39 INFO hook.py:591] name:features.12.conv.1.0.weight count_params:5184\n",
      "[2025-01-13 05:47:17.982 algo-1:39 INFO hook.py:591] name:features.12.conv.1.1.weight count_params:576\n",
      "[2025-01-13 05:47:17.982 algo-1:39 INFO hook.py:591] name:features.12.conv.1.1.bias count_params:576\n",
      "[2025-01-13 05:47:17.982 algo-1:39 INFO hook.py:591] name:features.12.conv.2.weight count_params:55296\n",
      "[2025-01-13 05:47:17.982 algo-1:39 INFO hook.py:591] name:features.12.conv.3.weight count_params:96\n",
      "[2025-01-13 05:47:17.982 algo-1:39 INFO hook.py:591] name:features.12.conv.3.bias count_params:96\n",
      "[2025-01-13 05:47:17.982 algo-1:39 INFO hook.py:591] name:features.13.conv.0.0.weight count_params:55296\n",
      "[2025-01-13 05:47:17.982 algo-1:39 INFO hook.py:591] name:features.13.conv.0.1.weight count_params:576\n",
      "[2025-01-13 05:47:17.982 algo-1:39 INFO hook.py:591] name:features.13.conv.0.1.bias count_params:576\n",
      "[2025-01-13 05:47:17.982 algo-1:39 INFO hook.py:591] name:features.13.conv.1.0.weight count_params:5184\n",
      "[2025-01-13 05:47:17.983 algo-1:39 INFO hook.py:591] name:features.13.conv.1.1.weight count_params:576\n",
      "[2025-01-13 05:47:17.983 algo-1:39 INFO hook.py:591] name:features.13.conv.1.1.bias count_params:576\n",
      "[2025-01-13 05:47:17.983 algo-1:39 INFO hook.py:591] name:features.13.conv.2.weight count_params:55296\n",
      "[2025-01-13 05:47:17.983 algo-1:39 INFO hook.py:591] name:features.13.conv.3.weight count_params:96\n",
      "[2025-01-13 05:47:17.983 algo-1:39 INFO hook.py:591] name:features.13.conv.3.bias count_params:96\n",
      "[2025-01-13 05:47:17.983 algo-1:39 INFO hook.py:591] name:features.14.conv.0.0.weight count_params:55296\n",
      "[2025-01-13 05:47:17.983 algo-1:39 INFO hook.py:591] name:features.14.conv.0.1.weight count_params:576\n",
      "[2025-01-13 05:47:17.983 algo-1:39 INFO hook.py:591] name:features.14.conv.0.1.bias count_params:576\n",
      "[2025-01-13 05:47:17.983 algo-1:39 INFO hook.py:591] name:features.14.conv.1.0.weight count_params:5184\n",
      "[2025-01-13 05:47:17.983 algo-1:39 INFO hook.py:591] name:features.14.conv.1.1.weight count_params:576\n",
      "[2025-01-13 05:47:17.983 algo-1:39 INFO hook.py:591] name:features.14.conv.1.1.bias count_params:576\n",
      "[2025-01-13 05:47:17.983 algo-1:39 INFO hook.py:591] name:features.14.conv.2.weight count_params:92160\n",
      "[2025-01-13 05:47:17.983 algo-1:39 INFO hook.py:591] name:features.14.conv.3.weight count_params:160\n",
      "[2025-01-13 05:47:17.983 algo-1:39 INFO hook.py:591] name:features.14.conv.3.bias count_params:160\n",
      "[2025-01-13 05:47:17.983 algo-1:39 INFO hook.py:591] name:features.15.conv.0.0.weight count_params:153600\n",
      "[2025-01-13 05:47:17.983 algo-1:39 INFO hook.py:591] name:features.15.conv.0.1.weight count_params:960\n",
      "[2025-01-13 05:47:17.983 algo-1:39 INFO hook.py:591] name:features.15.conv.0.1.bias count_params:960\n",
      "[2025-01-13 05:47:17.983 algo-1:39 INFO hook.py:591] name:features.15.conv.1.0.weight count_params:8640\n",
      "[2025-01-13 05:47:17.983 algo-1:39 INFO hook.py:591] name:features.15.conv.1.1.weight count_params:960\n",
      "[2025-01-13 05:47:17.983 algo-1:39 INFO hook.py:591] name:features.15.conv.1.1.bias count_params:960\n",
      "[2025-01-13 05:47:17.983 algo-1:39 INFO hook.py:591] name:features.15.conv.2.weight count_params:153600\n",
      "[2025-01-13 05:47:17.983 algo-1:39 INFO hook.py:591] name:features.15.conv.3.weight count_params:160\n",
      "[2025-01-13 05:47:17.984 algo-1:39 INFO hook.py:591] name:features.15.conv.3.bias count_params:160\n",
      "[2025-01-13 05:47:17.984 algo-1:39 INFO hook.py:591] name:features.16.conv.0.0.weight count_params:153600\n",
      "[2025-01-13 05:47:17.984 algo-1:39 INFO hook.py:591] name:features.16.conv.0.1.weight count_params:960\n",
      "[2025-01-13 05:47:17.984 algo-1:39 INFO hook.py:591] name:features.16.conv.0.1.bias count_params:960\n",
      "[2025-01-13 05:47:17.984 algo-1:39 INFO hook.py:591] name:features.16.conv.1.0.weight count_params:8640\n",
      "[2025-01-13 05:47:17.984 algo-1:39 INFO hook.py:591] name:features.16.conv.1.1.weight count_params:960\n",
      "[2025-01-13 05:47:17.984 algo-1:39 INFO hook.py:591] name:features.16.conv.1.1.bias count_params:960\n",
      "[2025-01-13 05:47:17.984 algo-1:39 INFO hook.py:591] name:features.16.conv.2.weight count_params:153600\n",
      "[2025-01-13 05:47:17.984 algo-1:39 INFO hook.py:591] name:features.16.conv.3.weight count_params:160\n",
      "[2025-01-13 05:47:17.984 algo-1:39 INFO hook.py:591] name:features.16.conv.3.bias count_params:160\n",
      "[2025-01-13 05:47:17.984 algo-1:39 INFO hook.py:591] name:features.17.conv.0.0.weight count_params:153600\n",
      "[2025-01-13 05:47:17.984 algo-1:39 INFO hook.py:591] name:features.17.conv.0.1.weight count_params:960\n",
      "[2025-01-13 05:47:17.984 algo-1:39 INFO hook.py:591] name:features.17.conv.0.1.bias count_params:960\n",
      "[2025-01-13 05:47:17.984 algo-1:39 INFO hook.py:591] name:features.17.conv.1.0.weight count_params:8640\n",
      "[2025-01-13 05:47:17.984 algo-1:39 INFO hook.py:591] name:features.17.conv.1.1.weight count_params:960\n",
      "[2025-01-13 05:47:17.984 algo-1:39 INFO hook.py:591] name:features.17.conv.1.1.bias count_params:960\n",
      "[2025-01-13 05:47:17.984 algo-1:39 INFO hook.py:591] name:features.17.conv.2.weight count_params:307200\n",
      "[2025-01-13 05:47:17.984 algo-1:39 INFO hook.py:591] name:features.17.conv.3.weight count_params:320\n",
      "[2025-01-13 05:47:17.984 algo-1:39 INFO hook.py:591] name:features.17.conv.3.bias count_params:320\n",
      "[2025-01-13 05:47:17.984 algo-1:39 INFO hook.py:591] name:features.18.0.weight count_params:409600\n",
      "[2025-01-13 05:47:17.985 algo-1:39 INFO hook.py:591] name:features.18.1.weight count_params:1280\n",
      "[2025-01-13 05:47:17.985 algo-1:39 INFO hook.py:591] name:features.18.1.bias count_params:1280\n",
      "[2025-01-13 05:47:17.985 algo-1:39 INFO hook.py:591] name:classifier.1.weight count_params:6400\n",
      "[2025-01-13 05:47:17.985 algo-1:39 INFO hook.py:591] name:classifier.1.bias count_params:5\n",
      "[2025-01-13 05:47:17.985 algo-1:39 INFO hook.py:593] Total Trainable Params: 2230277\n",
      "[2025-01-13 05:47:17.985 algo-1:39 INFO hook.py:424] Monitoring the collections: losses\n",
      "[2025-01-13 05:47:17.986 algo-1:39 INFO hook.py:488] Hook is writing from the hook with pid: 39\n",
      "train Loss: 1.0906 train Acc: 0.5650\n",
      "val Loss: 0.6563 val Acc: 0.6800\n",
      "Epoch 1/99\n",
      "train Loss: 0.5562 train Acc: 0.7900\n",
      "val Loss: 0.5620 val Acc: 0.8200\n",
      "Epoch 2/99\n",
      "train Loss: 0.5433 train Acc: 0.8150\n",
      "val Loss: 0.5939 val Acc: 0.7800\n",
      "Epoch 3/99\n",
      "train Loss: 0.5202 train Acc: 0.8200\n",
      "val Loss: 0.6285 val Acc: 0.7600\n",
      "Epoch 4/99\n",
      "train Loss: 0.5336 train Acc: 0.8150\n",
      "val Loss: 0.6841 val Acc: 0.7600\n",
      "Epoch 5/99\n",
      "train Loss: 0.5799 train Acc: 0.7800\n",
      "val Loss: 0.6475 val Acc: 0.7800\n",
      "Epoch 6/99\n",
      "train Loss: 0.5567 train Acc: 0.8100\n",
      "val Loss: 0.5852 val Acc: 0.7600\n",
      "Epoch 7/99\n",
      "train Loss: 0.4996 train Acc: 0.8450\n",
      "val Loss: 0.6056 val Acc: 0.7200\n",
      "Epoch 8/99\n",
      "train Loss: 0.6294 train Acc: 0.7750\n",
      "val Loss: 0.5227 val Acc: 0.8200\n",
      "Epoch 9/99\n",
      "train Loss: 0.5716 train Acc: 0.8050\n",
      "val Loss: 0.6323 val Acc: 0.7000\n",
      "Epoch 10/99\n",
      "train Loss: 0.5149 train Acc: 0.8050\n",
      "val Loss: 0.6256 val Acc: 0.7400\n",
      "Epoch 11/99\n",
      "train Loss: 0.5279 train Acc: 0.8000\n",
      "val Loss: 0.5141 val Acc: 0.8200\n",
      "Epoch 12/99\n",
      "train Loss: 0.5419 train Acc: 0.8100\n",
      "val Loss: 0.5652 val Acc: 0.7800\n",
      "Epoch 13/99\n",
      "train Loss: 0.4827 train Acc: 0.8500\n",
      "val Loss: 0.7148 val Acc: 0.7400\n",
      "Epoch 14/99\n",
      "train Loss: 0.5401 train Acc: 0.8200\n",
      "val Loss: 0.5786 val Acc: 0.8000\n",
      "Epoch 15/99\n",
      "train Loss: 0.5473 train Acc: 0.8050\n",
      "val Loss: 0.6629 val Acc: 0.7200\n",
      "Epoch 16/99\n",
      "train Loss: 0.5217 train Acc: 0.8250\n",
      "val Loss: 0.6029 val Acc: 0.7800\n",
      "Epoch 17/99\n",
      "train Loss: 0.5935 train Acc: 0.8150\n",
      "val Loss: 0.5692 val Acc: 0.7800\n",
      "Epoch 18/99\n",
      "train Loss: 0.5076 train Acc: 0.8450\n",
      "val Loss: 0.5914 val Acc: 0.7400\n",
      "Epoch 19/99\n",
      "train Loss: 0.5682 train Acc: 0.7900\n",
      "val Loss: 0.6495 val Acc: 0.7200\n",
      "Epoch 20/99\n",
      "train Loss: 0.5097 train Acc: 0.8200\n",
      "val Loss: 0.6390 val Acc: 0.7600\n",
      "Epoch 21/99\n",
      "train Loss: 0.5210 train Acc: 0.8000\n",
      "val Loss: 0.6013 val Acc: 0.7200\n",
      "Epoch 22/99\n",
      "train Loss: 0.5298 train Acc: 0.8250\n",
      "val Loss: 0.5890 val Acc: 0.7400\n",
      "Epoch 23/99\n",
      "train Loss: 0.6038 train Acc: 0.8300\n",
      "val Loss: 0.5883 val Acc: 0.7800\n",
      "Epoch 24/99\n",
      "train Loss: 0.5938 train Acc: 0.8150\n",
      "val Loss: 0.6363 val Acc: 0.7200\n",
      "Epoch 25/99\n",
      "train Loss: 0.4618 train Acc: 0.8500\n",
      "val Loss: 0.6324 val Acc: 0.7800\n",
      "Epoch 26/99\n",
      "train Loss: 0.4910 train Acc: 0.8350\n",
      "val Loss: 0.5595 val Acc: 0.8000\n",
      "Epoch 27/99\n",
      "train Loss: 0.5516 train Acc: 0.7850\n",
      "val Loss: 0.6036 val Acc: 0.8000\n",
      "Epoch 28/99\n",
      "train Loss: 0.6281 train Acc: 0.7600\n",
      "val Loss: 0.4712 val Acc: 0.8400\n",
      "Epoch 29/99\n",
      "train Loss: 0.5042 train Acc: 0.8600\n",
      "val Loss: 0.5649 val Acc: 0.7600\n",
      "Epoch 30/99\n",
      "train Loss: 0.5639 train Acc: 0.7900\n",
      "val Loss: 0.6120 val Acc: 0.8200\n",
      "Epoch 31/99\n",
      "train Loss: 0.5219 train Acc: 0.8250\n",
      "val Loss: 0.6333 val Acc: 0.7400\n",
      "Epoch 32/99\n",
      "train Loss: 0.5366 train Acc: 0.8000\n",
      "val Loss: 0.6306 val Acc: 0.6600\n",
      "Epoch 33/99\n",
      "train Loss: 0.5032 train Acc: 0.8150\n",
      "val Loss: 0.5748 val Acc: 0.7400\n",
      "Epoch 34/99\n",
      "train Loss: 0.5072 train Acc: 0.8150\n",
      "val Loss: 0.6545 val Acc: 0.7200\n",
      "Epoch 35/99\n",
      "train Loss: 0.5843 train Acc: 0.8100\n",
      "val Loss: 0.6032 val Acc: 0.7200\n",
      "Epoch 36/99\n",
      "train Loss: 0.5250 train Acc: 0.8300\n",
      "val Loss: 0.4758 val Acc: 0.8400\n",
      "Epoch 37/99\n",
      "train Loss: 0.5392 train Acc: 0.8100\n",
      "val Loss: 0.5018 val Acc: 0.8400\n",
      "Epoch 38/99\n",
      "train Loss: 0.6043 train Acc: 0.7800\n",
      "val Loss: 0.6141 val Acc: 0.7400\n",
      "Epoch 39/99\n",
      "train Loss: 0.4961 train Acc: 0.8500\n",
      "val Loss: 0.6205 val Acc: 0.7600\n",
      "Epoch 40/99\n",
      "train Loss: 0.5376 train Acc: 0.8350\n",
      "val Loss: 0.6702 val Acc: 0.7200\n",
      "Epoch 41/99\n",
      "train Loss: 0.5222 train Acc: 0.8300\n",
      "val Loss: 0.6360 val Acc: 0.7400\n",
      "Epoch 42/99\n",
      "train Loss: 0.5169 train Acc: 0.8250\n",
      "val Loss: 0.6778 val Acc: 0.7800\n",
      "Epoch 43/99\n",
      "train Loss: 0.5822 train Acc: 0.8100\n",
      "val Loss: 0.6272 val Acc: 0.7200\n",
      "Epoch 44/99\n",
      "train Loss: 0.5067 train Acc: 0.8350\n",
      "val Loss: 0.7275 val Acc: 0.6600\n",
      "Epoch 45/99\n",
      "train Loss: 0.5011 train Acc: 0.8200\n",
      "val Loss: 0.7683 val Acc: 0.6800\n",
      "Epoch 46/99\n",
      "train Loss: 0.5658 train Acc: 0.8000\n",
      "val Loss: 0.7196 val Acc: 0.7000\n",
      "Epoch 47/99\n",
      "train Loss: 0.5225 train Acc: 0.8250\n",
      "val Loss: 0.6371 val Acc: 0.7200\n",
      "Epoch 48/99\n",
      "train Loss: 0.5550 train Acc: 0.7950\n",
      "val Loss: 0.5747 val Acc: 0.8000\n",
      "Epoch 49/99\n",
      "train Loss: 0.4830 train Acc: 0.8350\n",
      "val Loss: 0.7190 val Acc: 0.7200\n",
      "Epoch 50/99\n",
      "train Loss: 0.5189 train Acc: 0.8000\n",
      "val Loss: 0.6722 val Acc: 0.7000\n",
      "Epoch 51/99\n",
      "train Loss: 0.4954 train Acc: 0.8300\n",
      "val Loss: 0.6752 val Acc: 0.7400\n",
      "Epoch 52/99\n",
      "train Loss: 0.5542 train Acc: 0.7950\n",
      "val Loss: 0.7303 val Acc: 0.7000\n",
      "Epoch 53/99\n",
      "train Loss: 0.5408 train Acc: 0.7950\n",
      "val Loss: 0.5553 val Acc: 0.7800\n",
      "Epoch 54/99\n",
      "train Loss: 0.5439 train Acc: 0.7800\n",
      "val Loss: 0.6199 val Acc: 0.7600\n",
      "Epoch 55/99\n",
      "train Loss: 0.5109 train Acc: 0.8050\n",
      "val Loss: 0.6317 val Acc: 0.7200\n",
      "Epoch 56/99\n",
      "train Loss: 0.5829 train Acc: 0.8000\n",
      "val Loss: 0.5918 val Acc: 0.7200\n",
      "Epoch 57/99\n",
      "train Loss: 0.5985 train Acc: 0.8000\n",
      "val Loss: 0.6134 val Acc: 0.8200\n",
      "Epoch 58/99\n",
      "train Loss: 0.4641 train Acc: 0.8500\n",
      "val Loss: 0.5382 val Acc: 0.8400\n",
      "Epoch 59/99\n",
      "train Loss: 0.5665 train Acc: 0.8300\n",
      "val Loss: 0.5145 val Acc: 0.8600\n",
      "Epoch 60/99\n",
      "train Loss: 0.5675 train Acc: 0.7650\n",
      "val Loss: 0.5647 val Acc: 0.7600\n",
      "Epoch 61/99\n",
      "train Loss: 0.5161 train Acc: 0.8300\n",
      "val Loss: 0.5847 val Acc: 0.7000\n",
      "Epoch 62/99\n",
      "train Loss: 0.5298 train Acc: 0.8050\n",
      "val Loss: 0.6316 val Acc: 0.7600\n",
      "Epoch 63/99\n",
      "train Loss: 0.4856 train Acc: 0.8250\n",
      "val Loss: 0.6087 val Acc: 0.7600\n",
      "Epoch 64/99\n",
      "train Loss: 0.5402 train Acc: 0.8250\n",
      "val Loss: 0.6578 val Acc: 0.7600\n",
      "Epoch 65/99\n",
      "train Loss: 0.5412 train Acc: 0.8100\n",
      "val Loss: 0.6298 val Acc: 0.6800\n",
      "Epoch 66/99\n",
      "train Loss: 0.4999 train Acc: 0.8300\n",
      "val Loss: 0.6763 val Acc: 0.7000\n",
      "Epoch 67/99\n",
      "train Loss: 0.4981 train Acc: 0.8100\n",
      "val Loss: 0.6327 val Acc: 0.7600\n",
      "Epoch 68/99\n",
      "train Loss: 0.4149 train Acc: 0.8800\n",
      "val Loss: 0.5810 val Acc: 0.7600\n",
      "Epoch 69/99\n",
      "train Loss: 0.5950 train Acc: 0.7600\n",
      "val Loss: 0.5007 val Acc: 0.8000\n",
      "Epoch 70/99\n",
      "train Loss: 0.5005 train Acc: 0.8050\n",
      "val Loss: 0.6884 val Acc: 0.6600\n",
      "Epoch 71/99\n",
      "train Loss: 0.5260 train Acc: 0.8250\n",
      "val Loss: 0.6471 val Acc: 0.7000\n",
      "Epoch 72/99\n",
      "train Loss: 0.4977 train Acc: 0.8400\n",
      "val Loss: 0.8483 val Acc: 0.7000\n",
      "Epoch 73/99\n",
      "train Loss: 0.5147 train Acc: 0.8500\n",
      "val Loss: 0.7746 val Acc: 0.6400\n",
      "Epoch 74/99\n",
      "train Loss: 0.4941 train Acc: 0.8150\n",
      "val Loss: 0.6182 val Acc: 0.7400\n",
      "Epoch 75/99\n",
      "train Loss: 0.5327 train Acc: 0.8100\n",
      "val Loss: 0.5905 val Acc: 0.7400\n",
      "Epoch 76/99\n",
      "train Loss: 0.4701 train Acc: 0.8400\n",
      "val Loss: 0.5974 val Acc: 0.7800\n",
      "Epoch 77/99\n",
      "train Loss: 0.5152 train Acc: 0.8200\n",
      "val Loss: 0.5791 val Acc: 0.7800\n",
      "Epoch 78/99\n",
      "train Loss: 0.5385 train Acc: 0.8200\n",
      "val Loss: 0.5872 val Acc: 0.7600\n",
      "Epoch 79/99\n",
      "train Loss: 0.5069 train Acc: 0.8250\n",
      "val Loss: 0.5724 val Acc: 0.7200\n",
      "Epoch 80/99\n",
      "train Loss: 0.5161 train Acc: 0.8200\n",
      "val Loss: 0.6918 val Acc: 0.7200\n",
      "Epoch 81/99\n",
      "train Loss: 0.4631 train Acc: 0.8350\n",
      "val Loss: 0.6071 val Acc: 0.7200\n",
      "Epoch 82/99\n",
      "train Loss: 0.5149 train Acc: 0.8300\n",
      "val Loss: 0.6467 val Acc: 0.7000\n",
      "Epoch 83/99\n",
      "train Loss: 0.5656 train Acc: 0.7950\n",
      "val Loss: 0.6523 val Acc: 0.7400\n",
      "Epoch 84/99\n",
      "train Loss: 0.5339 train Acc: 0.8250\n",
      "val Loss: 0.5686 val Acc: 0.8200\n",
      "Epoch 85/99\n",
      "train Loss: 0.5385 train Acc: 0.8050\n",
      "val Loss: 0.7264 val Acc: 0.7400\n",
      "Epoch 86/99\n",
      "train Loss: 0.4563 train Acc: 0.8400\n",
      "val Loss: 0.5883 val Acc: 0.7800\n",
      "Epoch 87/99\n",
      "train Loss: 0.6340 train Acc: 0.7950\n",
      "val Loss: 0.5793 val Acc: 0.7800\n",
      "Epoch 88/99\n",
      "train Loss: 0.5342 train Acc: 0.7950\n",
      "val Loss: 0.7210 val Acc: 0.6800\n",
      "Epoch 89/99\n",
      "train Loss: 0.5552 train Acc: 0.7950\n",
      "val Loss: 0.5346 val Acc: 0.8400\n",
      "Epoch 90/99\n",
      "train Loss: 0.4914 train Acc: 0.8350\n",
      "val Loss: 0.6787 val Acc: 0.7200\n",
      "Epoch 91/99\n",
      "train Loss: 0.5171 train Acc: 0.8150\n",
      "val Loss: 0.5694 val Acc: 0.8400\n",
      "Epoch 92/99\n",
      "train Loss: 0.4956 train Acc: 0.8350\n",
      "val Loss: 0.6970 val Acc: 0.7800\n",
      "Epoch 93/99\n",
      "train Loss: 0.5981 train Acc: 0.8000\n",
      "val Loss: 0.6431 val Acc: 0.7400\n",
      "Epoch 94/99\n",
      "train Loss: 0.6155 train Acc: 0.8000\n",
      "val Loss: 0.6997 val Acc: 0.6800\n",
      "Epoch 95/99\n",
      "train Loss: 0.5954 train Acc: 0.7800\n",
      "val Loss: 0.6059 val Acc: 0.7800\n",
      "Epoch 96/99\n",
      "train Loss: 0.5267 train Acc: 0.8100\n",
      "val Loss: 0.5333 val Acc: 0.8000\n",
      "Epoch 97/99\n",
      "train Loss: 0.5620 train Acc: 0.7800\n",
      "val Loss: 0.5514 val Acc: 0.7800\n",
      "Epoch 98/99\n",
      "train Loss: 0.5117 train Acc: 0.8350\n",
      "val Loss: 0.7103 val Acc: 0.7200\n",
      "Epoch 99/99\n",
      "train Loss: 0.6183 train Acc: 0.7850\n",
      "val Loss: 0.7751 val Acc: 0.6400\n",
      "Training complete in 3m 25s\n",
      "Best val Acc: 0.860000\n",
      "Info file not found at '_input_model_extracted/__models_info__.json'.\n",
      "2025-01-13 05:50:43,969 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\n",
      "2025-01-13 05:50:59 Uploading - Uploading generated training model\n",
      "2025-01-13 05:50:59 Completed - Training job completed\n",
      "Training seconds: 420\n",
      "Billable seconds: 420\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 114;\n                var nbb_unformatted_code = \"clf_estimator.fit(inputs=data_channels, logs=True, job_name=job_name)\";\n                var nbb_formatted_code = \"clf_estimator.fit(inputs=data_channels, logs=True, job_name=job_name)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_estimator.fit(inputs=data_channels, logs=True, job_name=job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ac068035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 115;\n                var nbb_unformatted_code = \"infer_instance_type = \\\"ml.t2.medium\\\"\";\n                var nbb_formatted_code = \"infer_instance_type = \\\"ml.t2.medium\\\"\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "infer_instance_type = \"ml.t2.medium\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "43e05587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 116;\n                var nbb_unformatted_code = \"deploy_image_uri = image_uris.retrieve(\\n    region=None,\\n    framework=None,\\n    image_scope=\\\"inference\\\",\\n    model_id=model_id,\\n    model_version=model_version,\\n    instance_type=infer_instance_type,\\n)\\n\\ndeploy_source_uri = script_uris.retrieve(\\n    model_id=model_id, model_version=model_version, script_scope=\\\"inference\\\"\\n)\";\n                var nbb_formatted_code = \"deploy_image_uri = image_uris.retrieve(\\n    region=None,\\n    framework=None,\\n    image_scope=\\\"inference\\\",\\n    model_id=model_id,\\n    model_version=model_version,\\n    instance_type=infer_instance_type,\\n)\\n\\ndeploy_source_uri = script_uris.retrieve(\\n    model_id=model_id, model_version=model_version, script_scope=\\\"inference\\\"\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    image_scope=\"inference\",\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    instance_type=infer_instance_type,\n",
    ")\n",
    "\n",
    "deploy_source_uri = script_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, script_scope=\"inference\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b978ae47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 117;\n                var nbb_unformatted_code = \"model_name = job_name\\nendpoint_name = job_name\";\n                var nbb_formatted_code = \"model_name = job_name\\nendpoint_name = job_name\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = job_name\n",
    "endpoint_name = job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f5ce90f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/12/25 21:51:54] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Repacking model artifact                                                  <a href=\"file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/model.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/model.py#819\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">819</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"font-weight: bold\">(</span>s3:<span style=\"color: #e100e1; text-decoration-color: #e100e1\">//sgmkr-images-training/pytorch-classification/model_output/flowers-c</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #e100e1; text-decoration-color: #e100e1\">lf-js-tf-2025-01-12-21-43-15/output/model.tar.gz</span><span style=\"font-weight: bold\">)</span>, script artifact        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"font-weight: bold\">(</span>s3:<span style=\"color: #e100e1; text-decoration-color: #e100e1\">//jumpstart-cache-prod-us-west-2/source-directory-tarballs/pytorch/in</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #e100e1; text-decoration-color: #e100e1\">ference/ic/v2.0.0/sourcedir.tar.gz</span><span style=\"font-weight: bold\">)</span>, and dependencies <span style=\"font-weight: bold\">([])</span> into single    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         tar.gz file located at                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         s3:<span style=\"color: #e100e1; text-decoration-color: #e100e1\">//sagemaker-us-west-2-654654352356/flowers-clf-js-tf-2025-01-12-21-43-</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #e100e1; text-decoration-color: #e100e1\">15/model.tar.gz.</span> This may take some time depending on model size<span style=\"color: #808000; text-decoration-color: #808000\">...</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/12/25 21:51:54]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Repacking model artifact                                                  \u001b]8;id=818680;file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/model.py\u001b\\\u001b[2mmodel.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=204806;file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/model.py#819\u001b\\\u001b[2m819\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1m(\u001b[0ms3:\u001b[38;2;225;0;225m/\u001b[0m\u001b[38;2;225;0;225m/sgmkr-images-training/pytorch-classification/model_output/flowers-c\u001b[0m \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[38;2;225;0;225mlf-js-tf-2025-01-12-21-43-15/output/\u001b[0m\u001b[38;2;225;0;225mmodel.tar.gz\u001b[0m\u001b[1m)\u001b[0m, script artifact        \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1m(\u001b[0ms3:\u001b[38;2;225;0;225m/\u001b[0m\u001b[38;2;225;0;225m/jumpstart-cache-prod-us-west-2/source-directory-tarballs/pytorch/in\u001b[0m \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[38;2;225;0;225mference/ic/v2.0.0/\u001b[0m\u001b[38;2;225;0;225msourcedir.tar.gz\u001b[0m\u001b[1m)\u001b[0m, and dependencies \u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m into single    \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         tar.gz file located at                                                    \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         s3:\u001b[38;2;225;0;225m/\u001b[0m\u001b[38;2;225;0;225m/sagemaker-us-west-2-654654352356/flowers-clf-js-tf-2025-01-12-21-43-\u001b[0m \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[38;2;225;0;225m15/\u001b[0m\u001b[38;2;225;0;225mmodel.tar.gz.\u001b[0m This may take some time depending on model size\u001b[33m...\u001b[0m       \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/12/25 21:52:03] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: flowers-clf-js-tf-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>        <a href=\"file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/12/25 21:52:03]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: flowers-clf-js-tf-\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m21\u001b[0m-\u001b[1;36m43\u001b[0m-\u001b[1;36m15\u001b[0m        \u001b]8;id=192322;file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=439107;file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/12/25 21:52:04] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py#5889\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5889</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         flowers-clf-js-tf-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/12/25 21:52:04]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=626443;file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=199281;file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py#5889\u001b\\\u001b[2m5889\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         flowers-clf-js-tf-\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m21\u001b[0m-\u001b[1;36m43\u001b[0m-\u001b[1;36m15\u001b[0m                                  \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name flowers-clf-js-tf-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>      <a href=\"file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py#4711\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4711</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name flowers-clf-js-tf-\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m21\u001b[0m-\u001b[1;36m43\u001b[0m-\u001b[1;36m15\u001b[0m      \u001b]8;id=488148;file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=124251;file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py#4711\u001b\\\u001b[2m4711\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 118;\n                var nbb_unformatted_code = \"clf_predictor = clf_estimator.deploy(\\n    initial_instance_count=1,\\n    instance_type=infer_instance_type,\\n    entry_point=\\\"inference.py\\\",\\n    image_uri=deploy_image_uri,\\n    source_dir=deploy_source_uri,\\n    endpoint_name=endpoint_name,\\n    model_name=model_name,\\n)\";\n                var nbb_formatted_code = \"clf_predictor = clf_estimator.deploy(\\n    initial_instance_count=1,\\n    instance_type=infer_instance_type,\\n    entry_point=\\\"inference.py\\\",\\n    image_uri=deploy_image_uri,\\n    source_dir=deploy_source_uri,\\n    endpoint_name=endpoint_name,\\n    model_name=model_name,\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_predictor = clf_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=infer_instance_type,\n",
    "    entry_point=\"inference.py\",\n",
    "    image_uri=deploy_image_uri,\n",
    "    source_dir=deploy_source_uri,\n",
    "    endpoint_name=endpoint_name,\n",
    "    model_name=model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e4e51711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 119;\n                var nbb_unformatted_code = \"sgmkr_runt = boto3.client(\\\"runtime.sagemaker\\\")\";\n                var nbb_formatted_code = \"sgmkr_runt = boto3.client(\\\"runtime.sagemaker\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sgmkr_runt = boto3.client(\"runtime.sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0528833a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probabilities': [0.010725224390625954, 0.00042605094495229423, 0.9787600636482239, 0.0002979158016387373, 0.009790708310902119], 'labels': ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip'], 'predicted_label': 'rose'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'rose'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 121;\n                var nbb_unformatted_code = \"with open(\\\"images/rose1.jpg\\\", \\\"rb\\\") as image:\\n    payload = image.read()\\n    # payload = bytearray(payload)\\n\\nresponse = sgmkr_runt.invoke_endpoint(\\n    EndpointName=endpoint_name,\\n    # ContentType = 'image/jpeg',\\n    ContentType=\\\"application/x-image\\\",\\n    Accept=\\\"application/json;verbose\\\",\\n    Body=payload,\\n)\\n\\nprediction = json.loads(response[\\\"Body\\\"].read().decode())\\nprint(prediction)\\nprediction[\\\"predicted_label\\\"]\";\n                var nbb_formatted_code = \"with open(\\\"images/rose1.jpg\\\", \\\"rb\\\") as image:\\n    payload = image.read()\\n    # payload = bytearray(payload)\\n\\nresponse = sgmkr_runt.invoke_endpoint(\\n    EndpointName=endpoint_name,\\n    # ContentType = 'image/jpeg',\\n    ContentType=\\\"application/x-image\\\",\\n    Accept=\\\"application/json;verbose\\\",\\n    Body=payload,\\n)\\n\\nprediction = json.loads(response[\\\"Body\\\"].read().decode())\\nprint(prediction)\\nprediction[\\\"predicted_label\\\"]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"images/rose1.jpg\", \"rb\") as image:\n",
    "    payload = image.read()\n",
    "    # payload = bytearray(payload)\n",
    "\n",
    "response = sgmkr_runt.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    # ContentType = 'image/jpeg',\n",
    "    ContentType=\"application/x-image\",\n",
    "    Accept=\"application/json;verbose\",\n",
    "    Body=payload,\n",
    ")\n",
    "\n",
    "prediction = json.loads(response[\"Body\"].read().decode())\n",
    "print(prediction)\n",
    "prediction[\"predicted_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "19c9decd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probabilities': [0.8895570039749146, 0.0037518879398703575, 0.010604382492601871, 0.05153409391641617, 0.044552627950906754], 'labels': ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip'], 'predicted_label': 'daisy'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'daisy'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 122;\n                var nbb_unformatted_code = \"with open(\\\"images/daisy1.jpg\\\", \\\"rb\\\") as image:\\n    payload = image.read()\\n    # payload = bytearray(payload)\\n\\nresponse = sgmkr_runt.invoke_endpoint(\\n    EndpointName=endpoint_name,\\n    # ContentType = 'image/jpeg',\\n    ContentType=\\\"application/x-image\\\",\\n    Accept=\\\"application/json;verbose\\\",\\n    Body=payload,\\n)\\n\\nprediction = json.loads(response[\\\"Body\\\"].read().decode())\\nprint(prediction)\\nprediction[\\\"predicted_label\\\"]\";\n                var nbb_formatted_code = \"with open(\\\"images/daisy1.jpg\\\", \\\"rb\\\") as image:\\n    payload = image.read()\\n    # payload = bytearray(payload)\\n\\nresponse = sgmkr_runt.invoke_endpoint(\\n    EndpointName=endpoint_name,\\n    # ContentType = 'image/jpeg',\\n    ContentType=\\\"application/x-image\\\",\\n    Accept=\\\"application/json;verbose\\\",\\n    Body=payload,\\n)\\n\\nprediction = json.loads(response[\\\"Body\\\"].read().decode())\\nprint(prediction)\\nprediction[\\\"predicted_label\\\"]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"images/daisy1.jpg\", \"rb\") as image:\n",
    "    payload = image.read()\n",
    "    # payload = bytearray(payload)\n",
    "\n",
    "response = sgmkr_runt.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    # ContentType = 'image/jpeg',\n",
    "    ContentType=\"application/x-image\",\n",
    "    Accept=\"application/json;verbose\",\n",
    "    Body=payload,\n",
    ")\n",
    "\n",
    "prediction = json.loads(response[\"Body\"].read().decode())\n",
    "print(prediction)\n",
    "prediction[\"predicted_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a6d0c9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/12/25 21:59:04] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting endpoint configuration with name:                             <a href=\"file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py#4865\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4865</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         flowers-clf-js-tf-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/12/25 21:59:04]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting endpoint configuration with name:                             \u001b]8;id=176195;file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=721114;file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py#4865\u001b\\\u001b[2m4865\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         flowers-clf-js-tf-\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m21\u001b[0m-\u001b[1;36m43\u001b[0m-\u001b[1;36m15\u001b[0m                                  \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting endpoint with name: flowers-clf-js-tf-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>     <a href=\"file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py#4855\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4855</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting endpoint with name: flowers-clf-js-tf-\u001b[1;36m2025\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m21\u001b[0m-\u001b[1;36m43\u001b[0m-\u001b[1;36m15\u001b[0m     \u001b]8;id=142196;file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631638;file:///home/thangtran3112/aws-sage-maker/machine-learning/venv/lib/python3.12/site-packages/sagemaker/session.py#4855\u001b\\\u001b[2m4855\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 123;\n                var nbb_unformatted_code = \"clf_predictor.delete_endpoint()\";\n                var nbb_formatted_code = \"clf_predictor.delete_endpoint()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
