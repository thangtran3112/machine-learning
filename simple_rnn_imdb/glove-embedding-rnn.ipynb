{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End to end Deep Learning Project Using Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,SimpleRNN,Dense, Input\n",
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0' # disable onednn for Nvidia training only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe embeddings is already downloaded and extracted.\n",
      "GloVe embeddings downloaded and extracted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Check if the file is extracted\n",
    "if os.path.exists(\"glove.6B.100d.txt\"):\n",
    "    print(\"GloVe embeddings is already downloaded and extracted.\")\n",
    "else:\n",
    "    print(\"Downloading GloVe 6B 100-dim. It may take 30 mins to an hour ...\")\n",
    "    # Download the GloVe embeddings\n",
    "    url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Save the zip file\n",
    "    with open(\"glove.6B.zip\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    # Unzip the file\n",
    "    with zipfile.ZipFile(\"glove.6B.zip\", \"r\") as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "\n",
    "# Check if the file is extracted\n",
    "if os.path.exists(\"glove.6B.100d.txt\"):\n",
    "    print(\"GloVe embeddings downloaded and extracted successfully.\")\n",
    "else:\n",
    "    print(\"Failed to download or extract GloVe embeddings.\")\n",
    "\n",
    "# Load GloVe embeddings\n",
    "embedding_index = {}\n",
    "with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = coefs\n",
    "\n",
    "# Determine the vocabulary size from GloVe\n",
    "vocabulary_size = len(embedding_index)\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (25000,), Training labels shape: (25000,)\n",
      "Testing data shape: (25000,), Testing labels shape: (25000,)\n"
     ]
    }
   ],
   "source": [
    "## Load the imdb dataset\n",
    "(X_train,y_train),(X_test,y_test)=imdb.load_data(num_words=vocabulary_size)\n",
    "\n",
    "# Print the shape of the data\n",
    "print(f'Training data shape: {X_train.shape}, Training labels shape: {y_train.shape}')\n",
    "print(f'Testing data shape: {X_train.shape}, Testing labels shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1,\n",
       "  14,\n",
       "  22,\n",
       "  16,\n",
       "  43,\n",
       "  530,\n",
       "  973,\n",
       "  1622,\n",
       "  1385,\n",
       "  65,\n",
       "  458,\n",
       "  4468,\n",
       "  66,\n",
       "  3941,\n",
       "  4,\n",
       "  173,\n",
       "  36,\n",
       "  256,\n",
       "  5,\n",
       "  25,\n",
       "  100,\n",
       "  43,\n",
       "  838,\n",
       "  112,\n",
       "  50,\n",
       "  670,\n",
       "  22665,\n",
       "  9,\n",
       "  35,\n",
       "  480,\n",
       "  284,\n",
       "  5,\n",
       "  150,\n",
       "  4,\n",
       "  172,\n",
       "  112,\n",
       "  167,\n",
       "  21631,\n",
       "  336,\n",
       "  385,\n",
       "  39,\n",
       "  4,\n",
       "  172,\n",
       "  4536,\n",
       "  1111,\n",
       "  17,\n",
       "  546,\n",
       "  38,\n",
       "  13,\n",
       "  447,\n",
       "  4,\n",
       "  192,\n",
       "  50,\n",
       "  16,\n",
       "  6,\n",
       "  147,\n",
       "  2025,\n",
       "  19,\n",
       "  14,\n",
       "  22,\n",
       "  4,\n",
       "  1920,\n",
       "  4613,\n",
       "  469,\n",
       "  4,\n",
       "  22,\n",
       "  71,\n",
       "  87,\n",
       "  12,\n",
       "  16,\n",
       "  43,\n",
       "  530,\n",
       "  38,\n",
       "  76,\n",
       "  15,\n",
       "  13,\n",
       "  1247,\n",
       "  4,\n",
       "  22,\n",
       "  17,\n",
       "  515,\n",
       "  17,\n",
       "  12,\n",
       "  16,\n",
       "  626,\n",
       "  18,\n",
       "  19193,\n",
       "  5,\n",
       "  62,\n",
       "  386,\n",
       "  12,\n",
       "  8,\n",
       "  316,\n",
       "  8,\n",
       "  106,\n",
       "  5,\n",
       "  4,\n",
       "  2223,\n",
       "  5244,\n",
       "  16,\n",
       "  480,\n",
       "  66,\n",
       "  3785,\n",
       "  33,\n",
       "  4,\n",
       "  130,\n",
       "  12,\n",
       "  16,\n",
       "  38,\n",
       "  619,\n",
       "  5,\n",
       "  25,\n",
       "  124,\n",
       "  51,\n",
       "  36,\n",
       "  135,\n",
       "  48,\n",
       "  25,\n",
       "  1415,\n",
       "  33,\n",
       "  6,\n",
       "  22,\n",
       "  12,\n",
       "  215,\n",
       "  28,\n",
       "  77,\n",
       "  52,\n",
       "  5,\n",
       "  14,\n",
       "  407,\n",
       "  16,\n",
       "  82,\n",
       "  10311,\n",
       "  8,\n",
       "  4,\n",
       "  107,\n",
       "  117,\n",
       "  5952,\n",
       "  15,\n",
       "  256,\n",
       "  4,\n",
       "  31050,\n",
       "  7,\n",
       "  3766,\n",
       "  5,\n",
       "  723,\n",
       "  36,\n",
       "  71,\n",
       "  43,\n",
       "  530,\n",
       "  476,\n",
       "  26,\n",
       "  400,\n",
       "  317,\n",
       "  46,\n",
       "  7,\n",
       "  4,\n",
       "  12118,\n",
       "  1029,\n",
       "  13,\n",
       "  104,\n",
       "  88,\n",
       "  4,\n",
       "  381,\n",
       "  15,\n",
       "  297,\n",
       "  98,\n",
       "  32,\n",
       "  2071,\n",
       "  56,\n",
       "  26,\n",
       "  141,\n",
       "  6,\n",
       "  194,\n",
       "  7486,\n",
       "  18,\n",
       "  4,\n",
       "  226,\n",
       "  22,\n",
       "  21,\n",
       "  134,\n",
       "  476,\n",
       "  26,\n",
       "  480,\n",
       "  5,\n",
       "  144,\n",
       "  30,\n",
       "  5535,\n",
       "  18,\n",
       "  51,\n",
       "  36,\n",
       "  28,\n",
       "  224,\n",
       "  92,\n",
       "  25,\n",
       "  104,\n",
       "  4,\n",
       "  226,\n",
       "  65,\n",
       "  16,\n",
       "  38,\n",
       "  1334,\n",
       "  88,\n",
       "  12,\n",
       "  16,\n",
       "  283,\n",
       "  5,\n",
       "  16,\n",
       "  4472,\n",
       "  113,\n",
       "  103,\n",
       "  32,\n",
       "  15,\n",
       "  16,\n",
       "  5345,\n",
       "  19,\n",
       "  178,\n",
       "  32],\n",
       " np.int64(1))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0],y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample review (as integers):[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "Sample label: 1\n"
     ]
    }
   ],
   "source": [
    "## Inspect a sample review and its label\n",
    "sample_review=X_train[0]\n",
    "sample_label=y_train[0]\n",
    "\n",
    "print(f\"Sample review (as integers):{sample_review}\")\n",
    "print(f'Sample label: {sample_label}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{34701: 'fawn',\n",
       " 52006: 'tsukino',\n",
       " 52007: 'nunnery',\n",
       " 16816: 'sonja',\n",
       " 63951: 'vani',\n",
       " 1408: 'woods',\n",
       " 16115: 'spiders',\n",
       " 2345: 'hanging',\n",
       " 2289: 'woody',\n",
       " 52008: 'trawling',\n",
       " 52009: \"hold's\",\n",
       " 11307: 'comically',\n",
       " 40830: 'localized',\n",
       " 30568: 'disobeying',\n",
       " 52010: \"'royale\",\n",
       " 40831: \"harpo's\",\n",
       " 52011: 'canet',\n",
       " 19313: 'aileen',\n",
       " 52012: 'acurately',\n",
       " 52013: \"diplomat's\",\n",
       " 25242: 'rickman',\n",
       " 6746: 'arranged',\n",
       " 52014: 'rumbustious',\n",
       " 52015: 'familiarness',\n",
       " 52016: \"spider'\",\n",
       " 68804: 'hahahah',\n",
       " 52017: \"wood'\",\n",
       " 40833: 'transvestism',\n",
       " 34702: \"hangin'\",\n",
       " 2338: 'bringing',\n",
       " 40834: 'seamier',\n",
       " 34703: 'wooded',\n",
       " 52018: 'bravora',\n",
       " 16817: 'grueling',\n",
       " 1636: 'wooden',\n",
       " 16818: 'wednesday',\n",
       " 52019: \"'prix\",\n",
       " 34704: 'altagracia',\n",
       " 52020: 'circuitry',\n",
       " 11585: 'crotch',\n",
       " 57766: 'busybody',\n",
       " 52021: \"tart'n'tangy\",\n",
       " 14129: 'burgade',\n",
       " 52023: 'thrace',\n",
       " 11038: \"tom's\",\n",
       " 52025: 'snuggles',\n",
       " 29114: 'francesco',\n",
       " 52027: 'complainers',\n",
       " 52125: 'templarios',\n",
       " 40835: '272',\n",
       " 52028: '273',\n",
       " 52130: 'zaniacs',\n",
       " 34706: '275',\n",
       " 27631: 'consenting',\n",
       " 40836: 'snuggled',\n",
       " 15492: 'inanimate',\n",
       " 52030: 'uality',\n",
       " 11926: 'bronte',\n",
       " 4010: 'errors',\n",
       " 3230: 'dialogs',\n",
       " 52031: \"yomada's\",\n",
       " 34707: \"madman's\",\n",
       " 30585: 'dialoge',\n",
       " 52033: 'usenet',\n",
       " 40837: 'videodrome',\n",
       " 26338: \"kid'\",\n",
       " 52034: 'pawed',\n",
       " 30569: \"'girlfriend'\",\n",
       " 52035: \"'pleasure\",\n",
       " 52036: \"'reloaded'\",\n",
       " 40839: \"kazakos'\",\n",
       " 52037: 'rocque',\n",
       " 52038: 'mailings',\n",
       " 11927: 'brainwashed',\n",
       " 16819: 'mcanally',\n",
       " 52039: \"tom''\",\n",
       " 25243: 'kurupt',\n",
       " 21905: 'affiliated',\n",
       " 52040: 'babaganoosh',\n",
       " 40840: \"noe's\",\n",
       " 40841: 'quart',\n",
       " 359: 'kids',\n",
       " 5034: 'uplifting',\n",
       " 7093: 'controversy',\n",
       " 21906: 'kida',\n",
       " 23379: 'kidd',\n",
       " 52041: \"error'\",\n",
       " 52042: 'neurologist',\n",
       " 18510: 'spotty',\n",
       " 30570: 'cobblers',\n",
       " 9878: 'projection',\n",
       " 40842: 'fastforwarding',\n",
       " 52043: 'sters',\n",
       " 52044: \"eggar's\",\n",
       " 52045: 'etherything',\n",
       " 40843: 'gateshead',\n",
       " 34708: 'airball',\n",
       " 25244: 'unsinkable',\n",
       " 7180: 'stern',\n",
       " 52046: \"cervi's\",\n",
       " 40844: 'dnd',\n",
       " 11586: 'dna',\n",
       " 20598: 'insecurity',\n",
       " 52047: \"'reboot'\",\n",
       " 11037: 'trelkovsky',\n",
       " 52048: 'jaekel',\n",
       " 52049: 'sidebars',\n",
       " 52050: \"sforza's\",\n",
       " 17633: 'distortions',\n",
       " 52051: 'mutinies',\n",
       " 30602: 'sermons',\n",
       " 40846: '7ft',\n",
       " 52052: 'boobage',\n",
       " 52053: \"o'bannon's\",\n",
       " 23380: 'populations',\n",
       " 52054: 'chulak',\n",
       " 27633: 'mesmerize',\n",
       " 52055: 'quinnell',\n",
       " 10307: 'yahoo',\n",
       " 52057: 'meteorologist',\n",
       " 42577: 'beswick',\n",
       " 15493: 'boorman',\n",
       " 40847: 'voicework',\n",
       " 52058: \"ster'\",\n",
       " 22922: 'blustering',\n",
       " 52059: 'hj',\n",
       " 27634: 'intake',\n",
       " 5621: 'morally',\n",
       " 40849: 'jumbling',\n",
       " 52060: 'bowersock',\n",
       " 52061: \"'porky's'\",\n",
       " 16821: 'gershon',\n",
       " 40850: 'ludicrosity',\n",
       " 52062: 'coprophilia',\n",
       " 40851: 'expressively',\n",
       " 19500: \"india's\",\n",
       " 34710: \"post's\",\n",
       " 52063: 'wana',\n",
       " 5283: 'wang',\n",
       " 30571: 'wand',\n",
       " 25245: 'wane',\n",
       " 52321: 'edgeways',\n",
       " 34711: 'titanium',\n",
       " 40852: 'pinta',\n",
       " 178: 'want',\n",
       " 30572: 'pinto',\n",
       " 52065: 'whoopdedoodles',\n",
       " 21908: 'tchaikovsky',\n",
       " 2103: 'travel',\n",
       " 52066: \"'victory'\",\n",
       " 11928: 'copious',\n",
       " 22433: 'gouge',\n",
       " 52067: \"chapters'\",\n",
       " 6702: 'barbra',\n",
       " 30573: 'uselessness',\n",
       " 52068: \"wan'\",\n",
       " 27635: 'assimilated',\n",
       " 16116: 'petiot',\n",
       " 52069: 'most\\x85and',\n",
       " 3930: 'dinosaurs',\n",
       " 352: 'wrong',\n",
       " 52070: 'seda',\n",
       " 52071: 'stollen',\n",
       " 34712: 'sentencing',\n",
       " 40853: 'ouroboros',\n",
       " 40854: 'assimilates',\n",
       " 40855: 'colorfully',\n",
       " 27636: 'glenne',\n",
       " 52072: 'dongen',\n",
       " 4760: 'subplots',\n",
       " 52073: 'kiloton',\n",
       " 23381: 'chandon',\n",
       " 34713: \"effect'\",\n",
       " 27637: 'snugly',\n",
       " 40856: 'kuei',\n",
       " 9092: 'welcomed',\n",
       " 30071: 'dishonor',\n",
       " 52075: 'concurrence',\n",
       " 23382: 'stoicism',\n",
       " 14896: \"guys'\",\n",
       " 52077: \"beroemd'\",\n",
       " 6703: 'butcher',\n",
       " 40857: \"melfi's\",\n",
       " 30623: 'aargh',\n",
       " 20599: 'playhouse',\n",
       " 11308: 'wickedly',\n",
       " 1180: 'fit',\n",
       " 52078: 'labratory',\n",
       " 40859: 'lifeline',\n",
       " 1927: 'screaming',\n",
       " 4287: 'fix',\n",
       " 52079: 'cineliterate',\n",
       " 52080: 'fic',\n",
       " 52081: 'fia',\n",
       " 34714: 'fig',\n",
       " 52082: 'fmvs',\n",
       " 52083: 'fie',\n",
       " 52084: 'reentered',\n",
       " 30574: 'fin',\n",
       " 52085: 'doctresses',\n",
       " 52086: 'fil',\n",
       " 12606: 'zucker',\n",
       " 31931: 'ached',\n",
       " 52088: 'counsil',\n",
       " 52089: 'paterfamilias',\n",
       " 13885: 'songwriter',\n",
       " 34715: 'shivam',\n",
       " 9654: 'hurting',\n",
       " 299: 'effects',\n",
       " 52090: 'slauther',\n",
       " 52091: \"'flame'\",\n",
       " 52092: 'sommerset',\n",
       " 52093: 'interwhined',\n",
       " 27638: 'whacking',\n",
       " 52094: 'bartok',\n",
       " 8775: 'barton',\n",
       " 21909: 'frewer',\n",
       " 52095: \"fi'\",\n",
       " 6192: 'ingrid',\n",
       " 30575: 'stribor',\n",
       " 52096: 'approporiately',\n",
       " 52097: 'wobblyhand',\n",
       " 52098: 'tantalisingly',\n",
       " 52099: 'ankylosaurus',\n",
       " 17634: 'parasites',\n",
       " 52100: 'childen',\n",
       " 52101: \"jenkins'\",\n",
       " 52102: 'metafiction',\n",
       " 17635: 'golem',\n",
       " 40860: 'indiscretion',\n",
       " 23383: \"reeves'\",\n",
       " 57781: \"inamorata's\",\n",
       " 52104: 'brittannica',\n",
       " 7916: 'adapt',\n",
       " 30576: \"russo's\",\n",
       " 48246: 'guitarists',\n",
       " 10553: 'abbott',\n",
       " 40861: 'abbots',\n",
       " 17649: 'lanisha',\n",
       " 40863: 'magickal',\n",
       " 52105: 'mattter',\n",
       " 52106: \"'willy\",\n",
       " 34716: 'pumpkins',\n",
       " 52107: 'stuntpeople',\n",
       " 30577: 'estimate',\n",
       " 40864: 'ugghhh',\n",
       " 11309: 'gameplay',\n",
       " 52108: \"wern't\",\n",
       " 40865: \"n'sync\",\n",
       " 16117: 'sickeningly',\n",
       " 40866: 'chiara',\n",
       " 4011: 'disturbed',\n",
       " 40867: 'portmanteau',\n",
       " 52109: 'ineffectively',\n",
       " 82143: \"duchonvey's\",\n",
       " 37519: \"nasty'\",\n",
       " 1285: 'purpose',\n",
       " 52112: 'lazers',\n",
       " 28105: 'lightened',\n",
       " 52113: 'kaliganj',\n",
       " 52114: 'popularism',\n",
       " 18511: \"damme's\",\n",
       " 30578: 'stylistics',\n",
       " 52115: 'mindgaming',\n",
       " 46449: 'spoilerish',\n",
       " 52117: \"'corny'\",\n",
       " 34718: 'boerner',\n",
       " 6792: 'olds',\n",
       " 52118: 'bakelite',\n",
       " 27639: 'renovated',\n",
       " 27640: 'forrester',\n",
       " 52119: \"lumiere's\",\n",
       " 52024: 'gaskets',\n",
       " 884: 'needed',\n",
       " 34719: 'smight',\n",
       " 1297: 'master',\n",
       " 25905: \"edie's\",\n",
       " 40868: 'seeber',\n",
       " 52120: 'hiya',\n",
       " 52121: 'fuzziness',\n",
       " 14897: 'genesis',\n",
       " 12607: 'rewards',\n",
       " 30579: 'enthrall',\n",
       " 40869: \"'about\",\n",
       " 52122: \"recollection's\",\n",
       " 11039: 'mutilated',\n",
       " 52123: 'fatherlands',\n",
       " 52124: \"fischer's\",\n",
       " 5399: 'positively',\n",
       " 34705: '270',\n",
       " 34720: 'ahmed',\n",
       " 9836: 'zatoichi',\n",
       " 13886: 'bannister',\n",
       " 52127: 'anniversaries',\n",
       " 30580: \"helm's\",\n",
       " 52128: \"'work'\",\n",
       " 34721: 'exclaimed',\n",
       " 52129: \"'unfunny'\",\n",
       " 52029: '274',\n",
       " 544: 'feeling',\n",
       " 52131: \"wanda's\",\n",
       " 33266: 'dolan',\n",
       " 52133: '278',\n",
       " 52134: 'peacoat',\n",
       " 40870: 'brawny',\n",
       " 40871: 'mishra',\n",
       " 40872: 'worlders',\n",
       " 52135: 'protags',\n",
       " 52136: 'skullcap',\n",
       " 57596: 'dastagir',\n",
       " 5622: 'affairs',\n",
       " 7799: 'wholesome',\n",
       " 52137: 'hymen',\n",
       " 25246: 'paramedics',\n",
       " 52138: 'unpersons',\n",
       " 52139: 'heavyarms',\n",
       " 52140: 'affaire',\n",
       " 52141: 'coulisses',\n",
       " 40873: 'hymer',\n",
       " 52142: 'kremlin',\n",
       " 30581: 'shipments',\n",
       " 52143: 'pixilated',\n",
       " 30582: \"'00s\",\n",
       " 18512: 'diminishing',\n",
       " 1357: 'cinematic',\n",
       " 14898: 'resonates',\n",
       " 40874: 'simplify',\n",
       " 40875: \"nature'\",\n",
       " 40876: 'temptresses',\n",
       " 16822: 'reverence',\n",
       " 19502: 'resonated',\n",
       " 34722: 'dailey',\n",
       " 52144: '2\\x85',\n",
       " 27641: 'treize',\n",
       " 52145: 'majo',\n",
       " 21910: 'kiya',\n",
       " 52146: 'woolnough',\n",
       " 39797: 'thanatos',\n",
       " 35731: 'sandoval',\n",
       " 40879: 'dorama',\n",
       " 52147: \"o'shaughnessy\",\n",
       " 4988: 'tech',\n",
       " 32018: 'fugitives',\n",
       " 30583: 'teck',\n",
       " 76125: \"'e'\",\n",
       " 40881: 'doesn’t',\n",
       " 52149: 'purged',\n",
       " 657: 'saying',\n",
       " 41095: \"martians'\",\n",
       " 23418: 'norliss',\n",
       " 27642: 'dickey',\n",
       " 52152: 'dicker',\n",
       " 52153: \"'sependipity\",\n",
       " 8422: 'padded',\n",
       " 57792: 'ordell',\n",
       " 40882: \"sturges'\",\n",
       " 52154: 'independentcritics',\n",
       " 5745: 'tempted',\n",
       " 34724: \"atkinson's\",\n",
       " 25247: 'hounded',\n",
       " 52155: 'apace',\n",
       " 15494: 'clicked',\n",
       " 30584: \"'humor'\",\n",
       " 17177: \"martino's\",\n",
       " 52156: \"'supporting\",\n",
       " 52032: 'warmongering',\n",
       " 34725: \"zemeckis's\",\n",
       " 21911: 'lube',\n",
       " 52157: 'shocky',\n",
       " 7476: 'plate',\n",
       " 40883: 'plata',\n",
       " 40884: 'sturgess',\n",
       " 40885: \"nerds'\",\n",
       " 20600: 'plato',\n",
       " 34726: 'plath',\n",
       " 40886: 'platt',\n",
       " 52159: 'mcnab',\n",
       " 27643: 'clumsiness',\n",
       " 3899: 'altogether',\n",
       " 42584: 'massacring',\n",
       " 52160: 'bicenntinial',\n",
       " 40887: 'skaal',\n",
       " 14360: 'droning',\n",
       " 8776: 'lds',\n",
       " 21912: 'jaguar',\n",
       " 34727: \"cale's\",\n",
       " 1777: 'nicely',\n",
       " 4588: 'mummy',\n",
       " 18513: \"lot's\",\n",
       " 10086: 'patch',\n",
       " 50202: 'kerkhof',\n",
       " 52161: \"leader's\",\n",
       " 27644: \"'movie\",\n",
       " 52162: 'uncomfirmed',\n",
       " 40888: 'heirloom',\n",
       " 47360: 'wrangle',\n",
       " 52163: 'emotion\\x85',\n",
       " 52164: \"'stargate'\",\n",
       " 40889: 'pinoy',\n",
       " 40890: 'conchatta',\n",
       " 41128: 'broeke',\n",
       " 40891: 'advisedly',\n",
       " 17636: \"barker's\",\n",
       " 52166: 'descours',\n",
       " 772: 'lots',\n",
       " 9259: 'lotr',\n",
       " 9879: 'irs',\n",
       " 52167: 'lott',\n",
       " 40892: 'xvi',\n",
       " 34728: 'irk',\n",
       " 52168: 'irl',\n",
       " 6887: 'ira',\n",
       " 21913: 'belzer',\n",
       " 52169: 'irc',\n",
       " 27645: 'ire',\n",
       " 40893: 'requisites',\n",
       " 7693: 'discipline',\n",
       " 52961: 'lyoko',\n",
       " 11310: 'extend',\n",
       " 873: 'nature',\n",
       " 52170: \"'dickie'\",\n",
       " 40894: 'optimist',\n",
       " 30586: 'lapping',\n",
       " 3900: 'superficial',\n",
       " 52171: 'vestment',\n",
       " 2823: 'extent',\n",
       " 52172: 'tendons',\n",
       " 52173: \"heller's\",\n",
       " 52174: 'quagmires',\n",
       " 52175: 'miyako',\n",
       " 20601: 'moocow',\n",
       " 52176: \"coles'\",\n",
       " 40895: 'lookit',\n",
       " 52177: 'ravenously',\n",
       " 40896: 'levitating',\n",
       " 52178: 'perfunctorily',\n",
       " 30587: 'lookin',\n",
       " 40898: \"lot'\",\n",
       " 52179: 'lookie',\n",
       " 34870: 'fearlessly',\n",
       " 52181: 'libyan',\n",
       " 40899: 'fondles',\n",
       " 35714: 'gopher',\n",
       " 40901: 'wearying',\n",
       " 52182: \"nz's\",\n",
       " 27646: 'minuses',\n",
       " 52183: 'puposelessly',\n",
       " 52184: 'shandling',\n",
       " 31268: 'decapitates',\n",
       " 11929: 'humming',\n",
       " 40902: \"'nother\",\n",
       " 21914: 'smackdown',\n",
       " 30588: 'underdone',\n",
       " 40903: 'frf',\n",
       " 52185: 'triviality',\n",
       " 25248: 'fro',\n",
       " 8777: 'bothers',\n",
       " 52186: \"'kensington\",\n",
       " 73: 'much',\n",
       " 34730: 'muco',\n",
       " 22615: 'wiseguy',\n",
       " 27648: \"richie's\",\n",
       " 40904: 'tonino',\n",
       " 52187: 'unleavened',\n",
       " 11587: 'fry',\n",
       " 40905: \"'tv'\",\n",
       " 40906: 'toning',\n",
       " 14361: 'obese',\n",
       " 30589: 'sensationalized',\n",
       " 40907: 'spiv',\n",
       " 6259: 'spit',\n",
       " 7364: 'arkin',\n",
       " 21915: 'charleton',\n",
       " 16823: 'jeon',\n",
       " 21916: 'boardroom',\n",
       " 4989: 'doubts',\n",
       " 3084: 'spin',\n",
       " 53083: 'hepo',\n",
       " 27649: 'wildcat',\n",
       " 10584: 'venoms',\n",
       " 52191: 'misconstrues',\n",
       " 18514: 'mesmerising',\n",
       " 40908: 'misconstrued',\n",
       " 52192: 'rescinds',\n",
       " 52193: 'prostrate',\n",
       " 40909: 'majid',\n",
       " 16479: 'climbed',\n",
       " 34731: 'canoeing',\n",
       " 52195: 'majin',\n",
       " 57804: 'animie',\n",
       " 40910: 'sylke',\n",
       " 14899: 'conditioned',\n",
       " 40911: 'waddell',\n",
       " 52196: '3\\x85',\n",
       " 41188: 'hyperdrive',\n",
       " 34732: 'conditioner',\n",
       " 53153: 'bricklayer',\n",
       " 2576: 'hong',\n",
       " 52198: 'memoriam',\n",
       " 30592: 'inventively',\n",
       " 25249: \"levant's\",\n",
       " 20638: 'portobello',\n",
       " 52200: 'remand',\n",
       " 19504: 'mummified',\n",
       " 27650: 'honk',\n",
       " 19505: 'spews',\n",
       " 40912: 'visitations',\n",
       " 52201: 'mummifies',\n",
       " 25250: 'cavanaugh',\n",
       " 23385: 'zeon',\n",
       " 40913: \"jungle's\",\n",
       " 34733: 'viertel',\n",
       " 27651: 'frenchmen',\n",
       " 52202: 'torpedoes',\n",
       " 52203: 'schlessinger',\n",
       " 34734: 'torpedoed',\n",
       " 69876: 'blister',\n",
       " 52204: 'cinefest',\n",
       " 34735: 'furlough',\n",
       " 52205: 'mainsequence',\n",
       " 40914: 'mentors',\n",
       " 9094: 'academic',\n",
       " 20602: 'stillness',\n",
       " 40915: 'academia',\n",
       " 52206: 'lonelier',\n",
       " 52207: 'nibby',\n",
       " 52208: \"losers'\",\n",
       " 40916: 'cineastes',\n",
       " 4449: 'corporate',\n",
       " 40917: 'massaging',\n",
       " 30593: 'bellow',\n",
       " 19506: 'absurdities',\n",
       " 53241: 'expetations',\n",
       " 40918: 'nyfiken',\n",
       " 75638: 'mehras',\n",
       " 52209: 'lasse',\n",
       " 52210: 'visability',\n",
       " 33946: 'militarily',\n",
       " 52211: \"elder'\",\n",
       " 19023: 'gainsbourg',\n",
       " 20603: 'hah',\n",
       " 13420: 'hai',\n",
       " 34736: 'haj',\n",
       " 25251: 'hak',\n",
       " 4311: 'hal',\n",
       " 4892: 'ham',\n",
       " 53259: 'duffer',\n",
       " 52213: 'haa',\n",
       " 66: 'had',\n",
       " 11930: 'advancement',\n",
       " 16825: 'hag',\n",
       " 25252: \"hand'\",\n",
       " 13421: 'hay',\n",
       " 20604: 'mcnamara',\n",
       " 52214: \"mozart's\",\n",
       " 30731: 'duffel',\n",
       " 30594: 'haq',\n",
       " 13887: 'har',\n",
       " 44: 'has',\n",
       " 2401: 'hat',\n",
       " 40919: 'hav',\n",
       " 30595: 'haw',\n",
       " 52215: 'figtings',\n",
       " 15495: 'elders',\n",
       " 52216: 'underpanted',\n",
       " 52217: 'pninson',\n",
       " 27652: 'unequivocally',\n",
       " 23673: \"barbara's\",\n",
       " 52219: \"bello'\",\n",
       " 12997: 'indicative',\n",
       " 40920: 'yawnfest',\n",
       " 52220: 'hexploitation',\n",
       " 52221: \"loder's\",\n",
       " 27653: 'sleuthing',\n",
       " 32622: \"justin's\",\n",
       " 52222: \"'ball\",\n",
       " 52223: \"'summer\",\n",
       " 34935: \"'demons'\",\n",
       " 52225: \"mormon's\",\n",
       " 34737: \"laughton's\",\n",
       " 52226: 'debell',\n",
       " 39724: 'shipyard',\n",
       " 30597: 'unabashedly',\n",
       " 40401: 'disks',\n",
       " 2290: 'crowd',\n",
       " 10087: 'crowe',\n",
       " 56434: \"vancouver's\",\n",
       " 34738: 'mosques',\n",
       " 6627: 'crown',\n",
       " 52227: 'culpas',\n",
       " 27654: 'crows',\n",
       " 53344: 'surrell',\n",
       " 52229: 'flowless',\n",
       " 52230: 'sheirk',\n",
       " 40923: \"'three\",\n",
       " 52231: \"peterson'\",\n",
       " 52232: 'ooverall',\n",
       " 40924: 'perchance',\n",
       " 1321: 'bottom',\n",
       " 53363: 'chabert',\n",
       " 52233: 'sneha',\n",
       " 13888: 'inhuman',\n",
       " 52234: 'ichii',\n",
       " 52235: 'ursla',\n",
       " 30598: 'completly',\n",
       " 40925: 'moviedom',\n",
       " 52236: 'raddick',\n",
       " 51995: 'brundage',\n",
       " 40926: 'brigades',\n",
       " 1181: 'starring',\n",
       " 52237: \"'goal'\",\n",
       " 52238: 'caskets',\n",
       " 52239: 'willcock',\n",
       " 52240: \"threesome's\",\n",
       " 52241: \"mosque'\",\n",
       " 52242: \"cover's\",\n",
       " 17637: 'spaceships',\n",
       " 40927: 'anomalous',\n",
       " 27655: 'ptsd',\n",
       " 52243: 'shirdan',\n",
       " 21962: 'obscenity',\n",
       " 30599: 'lemmings',\n",
       " 30600: 'duccio',\n",
       " 52244: \"levene's\",\n",
       " 52245: \"'gorby'\",\n",
       " 25255: \"teenager's\",\n",
       " 5340: 'marshall',\n",
       " 9095: 'honeymoon',\n",
       " 3231: 'shoots',\n",
       " 12258: 'despised',\n",
       " 52246: 'okabasho',\n",
       " 8289: 'fabric',\n",
       " 18515: 'cannavale',\n",
       " 3537: 'raped',\n",
       " 52247: \"tutt's\",\n",
       " 17638: 'grasping',\n",
       " 18516: 'despises',\n",
       " 40928: \"thief's\",\n",
       " 8926: 'rapes',\n",
       " 52248: 'raper',\n",
       " 27656: \"eyre'\",\n",
       " 52249: 'walchek',\n",
       " 23386: \"elmo's\",\n",
       " 40929: 'perfumes',\n",
       " 21918: 'spurting',\n",
       " 52250: \"exposition'\\x85\",\n",
       " 52251: 'denoting',\n",
       " 34740: 'thesaurus',\n",
       " 40930: \"shoot'\",\n",
       " 49759: 'bonejack',\n",
       " 52253: 'simpsonian',\n",
       " 30601: 'hebetude',\n",
       " 34741: \"hallow's\",\n",
       " 52254: 'desperation\\x85',\n",
       " 34742: 'incinerator',\n",
       " 10308: 'congratulations',\n",
       " 52255: 'humbled',\n",
       " 5924: \"else's\",\n",
       " 40845: 'trelkovski',\n",
       " 52256: \"rape'\",\n",
       " 59386: \"'chapters'\",\n",
       " 52257: '1600s',\n",
       " 7253: 'martian',\n",
       " 25256: 'nicest',\n",
       " 52259: 'eyred',\n",
       " 9457: 'passenger',\n",
       " 6041: 'disgrace',\n",
       " 52260: 'moderne',\n",
       " 5120: 'barrymore',\n",
       " 52261: 'yankovich',\n",
       " 40931: 'moderns',\n",
       " 52262: 'studliest',\n",
       " 52263: 'bedsheet',\n",
       " 14900: 'decapitation',\n",
       " 52264: 'slurring',\n",
       " 52265: \"'nunsploitation'\",\n",
       " 34743: \"'character'\",\n",
       " 9880: 'cambodia',\n",
       " 52266: 'rebelious',\n",
       " 27657: 'pasadena',\n",
       " 40932: 'crowne',\n",
       " 52267: \"'bedchamber\",\n",
       " 52268: 'conjectural',\n",
       " 52269: 'appologize',\n",
       " 52270: 'halfassing',\n",
       " 57816: 'paycheque',\n",
       " 20606: 'palms',\n",
       " 52271: \"'islands\",\n",
       " 40933: 'hawked',\n",
       " 21919: 'palme',\n",
       " 40934: 'conservatively',\n",
       " 64007: 'larp',\n",
       " 5558: 'palma',\n",
       " 21920: 'smelling',\n",
       " 12998: 'aragorn',\n",
       " 52272: 'hawker',\n",
       " 52273: 'hawkes',\n",
       " 3975: 'explosions',\n",
       " 8059: 'loren',\n",
       " 52274: \"pyle's\",\n",
       " 6704: 'shootout',\n",
       " 18517: \"mike's\",\n",
       " 52275: \"driscoll's\",\n",
       " 40935: 'cogsworth',\n",
       " 52276: \"britian's\",\n",
       " 34744: 'childs',\n",
       " 52277: \"portrait's\",\n",
       " 3626: 'chain',\n",
       " 2497: 'whoever',\n",
       " 52278: 'puttered',\n",
       " 52279: 'childe',\n",
       " 52280: 'maywether',\n",
       " 3036: 'chair',\n",
       " 52281: \"rance's\",\n",
       " 34745: 'machu',\n",
       " 4517: 'ballet',\n",
       " 34746: 'grapples',\n",
       " 76152: 'summerize',\n",
       " 30603: 'freelance',\n",
       " 52283: \"andrea's\",\n",
       " 52284: '\\x91very',\n",
       " 45879: 'coolidge',\n",
       " 18518: 'mache',\n",
       " 52285: 'balled',\n",
       " 40937: 'grappled',\n",
       " 18519: 'macha',\n",
       " 21921: 'underlining',\n",
       " 5623: 'macho',\n",
       " 19507: 'oversight',\n",
       " 25257: 'machi',\n",
       " 11311: 'verbally',\n",
       " 21922: 'tenacious',\n",
       " 40938: 'windshields',\n",
       " 18557: 'paychecks',\n",
       " 3396: 'jerk',\n",
       " 11931: \"good'\",\n",
       " 34748: 'prancer',\n",
       " 21923: 'prances',\n",
       " 52286: 'olympus',\n",
       " 21924: 'lark',\n",
       " 10785: 'embark',\n",
       " 7365: 'gloomy',\n",
       " 52287: 'jehaan',\n",
       " 52288: 'turaqui',\n",
       " 20607: \"child'\",\n",
       " 2894: 'locked',\n",
       " 52289: 'pranced',\n",
       " 2588: 'exact',\n",
       " 52290: 'unattuned',\n",
       " 783: 'minute',\n",
       " 16118: 'skewed',\n",
       " 40940: 'hodgins',\n",
       " 34749: 'skewer',\n",
       " 52291: 'think\\x85',\n",
       " 38765: 'rosenstein',\n",
       " 52292: 'helmit',\n",
       " 34750: 'wrestlemanias',\n",
       " 16826: 'hindered',\n",
       " 30604: \"martha's\",\n",
       " 52293: 'cheree',\n",
       " 52294: \"pluckin'\",\n",
       " 40941: 'ogles',\n",
       " 11932: 'heavyweight',\n",
       " 82190: 'aada',\n",
       " 11312: 'chopping',\n",
       " 61534: 'strongboy',\n",
       " 41342: 'hegemonic',\n",
       " 40942: 'adorns',\n",
       " 41346: 'xxth',\n",
       " 34751: 'nobuhiro',\n",
       " 52298: 'capitães',\n",
       " 52299: 'kavogianni',\n",
       " 13422: 'antwerp',\n",
       " 6538: 'celebrated',\n",
       " 52300: 'roarke',\n",
       " 40943: 'baggins',\n",
       " 31270: 'cheeseburgers',\n",
       " 52301: 'matras',\n",
       " 52302: \"nineties'\",\n",
       " 52303: \"'craig'\",\n",
       " 12999: 'celebrates',\n",
       " 3383: 'unintentionally',\n",
       " 14362: 'drafted',\n",
       " 52304: 'climby',\n",
       " 52305: '303',\n",
       " 18520: 'oldies',\n",
       " 9096: 'climbs',\n",
       " 9655: 'honour',\n",
       " 34752: 'plucking',\n",
       " 30074: '305',\n",
       " 5514: 'address',\n",
       " 40944: 'menjou',\n",
       " 42592: \"'freak'\",\n",
       " 19508: 'dwindling',\n",
       " 9458: 'benson',\n",
       " 52307: 'white’s',\n",
       " 40945: 'shamelessness',\n",
       " 21925: 'impacted',\n",
       " 52308: 'upatz',\n",
       " 3840: 'cusack',\n",
       " 37567: \"flavia's\",\n",
       " 52309: 'effette',\n",
       " 34753: 'influx',\n",
       " 52310: 'boooooooo',\n",
       " 52311: 'dimitrova',\n",
       " 13423: 'houseman',\n",
       " 25259: 'bigas',\n",
       " 52312: 'boylen',\n",
       " 52313: 'phillipenes',\n",
       " 40946: 'fakery',\n",
       " 27658: \"grandpa's\",\n",
       " 27659: 'darnell',\n",
       " 19509: 'undergone',\n",
       " 52315: 'handbags',\n",
       " 21926: 'perished',\n",
       " 37778: 'pooped',\n",
       " 27660: 'vigour',\n",
       " 3627: 'opposed',\n",
       " 52316: 'etude',\n",
       " 11799: \"caine's\",\n",
       " 52317: 'doozers',\n",
       " 34754: 'photojournals',\n",
       " 52318: 'perishes',\n",
       " 34755: 'constrains',\n",
       " 40948: 'migenes',\n",
       " 30605: 'consoled',\n",
       " 16827: 'alastair',\n",
       " 52319: 'wvs',\n",
       " 52320: 'ooooooh',\n",
       " 34756: 'approving',\n",
       " 40949: 'consoles',\n",
       " 52064: 'disparagement',\n",
       " 52322: 'futureistic',\n",
       " 52323: 'rebounding',\n",
       " 52324: \"'date\",\n",
       " 52325: 'gregoire',\n",
       " 21927: 'rutherford',\n",
       " 34757: 'americanised',\n",
       " 82196: 'novikov',\n",
       " 1042: 'following',\n",
       " 34758: 'munroe',\n",
       " 52326: \"morita'\",\n",
       " 52327: 'christenssen',\n",
       " 23106: 'oatmeal',\n",
       " 25260: 'fossey',\n",
       " 40950: 'livered',\n",
       " 13000: 'listens',\n",
       " 76164: \"'marci\",\n",
       " 52330: \"otis's\",\n",
       " 23387: 'thanking',\n",
       " 16019: 'maude',\n",
       " 34759: 'extensions',\n",
       " 52332: 'ameteurish',\n",
       " 52333: \"commender's\",\n",
       " 27661: 'agricultural',\n",
       " 4518: 'convincingly',\n",
       " 17639: 'fueled',\n",
       " 54014: 'mahattan',\n",
       " 40952: \"paris's\",\n",
       " 52336: 'vulkan',\n",
       " 52337: 'stapes',\n",
       " 52338: 'odysessy',\n",
       " 12259: 'harmon',\n",
       " 4252: 'surfing',\n",
       " 23494: 'halloran',\n",
       " 49580: 'unbelieveably',\n",
       " 52339: \"'offed'\",\n",
       " 30607: 'quadrant',\n",
       " 19510: 'inhabiting',\n",
       " 34760: 'nebbish',\n",
       " 40953: 'forebears',\n",
       " 34761: 'skirmish',\n",
       " 52340: 'ocassionally',\n",
       " 52341: \"'resist\",\n",
       " 21928: 'impactful',\n",
       " 52342: 'spicier',\n",
       " 40954: 'touristy',\n",
       " 52343: \"'football'\",\n",
       " 40955: 'webpage',\n",
       " 52345: 'exurbia',\n",
       " 52346: 'jucier',\n",
       " 14901: 'professors',\n",
       " 34762: 'structuring',\n",
       " 30608: 'jig',\n",
       " 40956: 'overlord',\n",
       " 25261: 'disconnect',\n",
       " 82201: 'sniffle',\n",
       " 40957: 'slimeball',\n",
       " 40958: 'jia',\n",
       " 16828: 'milked',\n",
       " 40959: 'banjoes',\n",
       " 1237: 'jim',\n",
       " 52348: 'workforces',\n",
       " 52349: 'jip',\n",
       " 52350: 'rotweiller',\n",
       " 34763: 'mundaneness',\n",
       " 52351: \"'ninja'\",\n",
       " 11040: \"dead'\",\n",
       " 40960: \"cipriani's\",\n",
       " 20608: 'modestly',\n",
       " 52352: \"professor'\",\n",
       " 40961: 'shacked',\n",
       " 34764: 'bashful',\n",
       " 23388: 'sorter',\n",
       " 16120: 'overpowering',\n",
       " 18521: 'workmanlike',\n",
       " 27662: 'henpecked',\n",
       " 18522: 'sorted',\n",
       " 52354: \"jōb's\",\n",
       " 52355: \"'always\",\n",
       " 34765: \"'baptists\",\n",
       " 52356: 'dreamcatchers',\n",
       " 52357: \"'silence'\",\n",
       " 21929: 'hickory',\n",
       " 52358: 'fun\\x97yet',\n",
       " 52359: 'breakumentary',\n",
       " 15496: 'didn',\n",
       " 52360: 'didi',\n",
       " 52361: 'pealing',\n",
       " 40962: 'dispite',\n",
       " 25262: \"italy's\",\n",
       " 21930: 'instability',\n",
       " 6539: 'quarter',\n",
       " 12608: 'quartet',\n",
       " 52362: 'padmé',\n",
       " 52363: \"'bleedmedry\",\n",
       " 52364: 'pahalniuk',\n",
       " 52365: 'honduras',\n",
       " 10786: 'bursting',\n",
       " 41465: \"pablo's\",\n",
       " 52367: 'irremediably',\n",
       " 40963: 'presages',\n",
       " 57832: 'bowlegged',\n",
       " 65183: 'dalip',\n",
       " 6260: 'entering',\n",
       " 76172: 'newsradio',\n",
       " 54150: 'presaged',\n",
       " 27663: \"giallo's\",\n",
       " 40964: 'bouyant',\n",
       " 52368: 'amerterish',\n",
       " 18523: 'rajni',\n",
       " 30610: 'leeves',\n",
       " 34767: 'macauley',\n",
       " 612: 'seriously',\n",
       " 52369: 'sugercoma',\n",
       " 52370: 'grimstead',\n",
       " 52371: \"'fairy'\",\n",
       " 30611: 'zenda',\n",
       " 52372: \"'twins'\",\n",
       " 17640: 'realisation',\n",
       " 27664: 'highsmith',\n",
       " 7817: 'raunchy',\n",
       " 40965: 'incentives',\n",
       " 52374: 'flatson',\n",
       " 35097: 'snooker',\n",
       " 16829: 'crazies',\n",
       " 14902: 'crazier',\n",
       " 7094: 'grandma',\n",
       " 52375: 'napunsaktha',\n",
       " 30612: 'workmanship',\n",
       " 52376: 'reisner',\n",
       " 61306: \"sanford's\",\n",
       " 52377: '\\x91doña',\n",
       " 6108: 'modest',\n",
       " 19153: \"everything's\",\n",
       " 40966: 'hamer',\n",
       " 52379: \"couldn't'\",\n",
       " 13001: 'quibble',\n",
       " 52380: 'socking',\n",
       " 21931: 'tingler',\n",
       " 52381: 'gutman',\n",
       " 40967: 'lachlan',\n",
       " 52382: 'tableaus',\n",
       " 52383: 'headbanger',\n",
       " 2847: 'spoken',\n",
       " 34768: 'cerebrally',\n",
       " 23490: \"'road\",\n",
       " 21932: 'tableaux',\n",
       " 40968: \"proust's\",\n",
       " 40969: 'periodical',\n",
       " 52385: \"shoveller's\",\n",
       " 25263: 'tamara',\n",
       " 17641: 'affords',\n",
       " 3249: 'concert',\n",
       " 87955: \"yara's\",\n",
       " 52386: 'someome',\n",
       " 8424: 'lingering',\n",
       " 41511: \"abraham's\",\n",
       " 34769: 'beesley',\n",
       " 34770: 'cherbourg',\n",
       " 28624: 'kagan',\n",
       " 9097: 'snatch',\n",
       " 9260: \"miyazaki's\",\n",
       " 25264: 'absorbs',\n",
       " 40970: \"koltai's\",\n",
       " 64027: 'tingled',\n",
       " 19511: 'crossroads',\n",
       " 16121: 'rehab',\n",
       " 52389: 'falworth',\n",
       " 52390: 'sequals',\n",
       " ...}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### MApping of words index bacl to words(for understanding)\n",
    "word_index=imdb.get_word_index()\n",
    "#reverse the key to become value, and value to become key in the new dictionary\n",
    "reverse_word_index = {value: key for key, value in word_index.items()}\n",
    "reverse_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From tensorflow documentation, the first 3 indices are reserved for padding, start of sequence and unknown\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in sample_review])\n",
    "decoded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,    19,   178,    32],\n",
       "       [    0,     0,     0, ...,    16,   145,    95],\n",
       "       [    0,     0,     0, ...,     7,   129,   113],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,     4,  3586, 22459],\n",
       "       [    0,     0,     0, ...,    12,     9,    23],\n",
       "       [    0,     0,     0, ...,   204,   131,     9]], dtype=int32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "## Pad the sequences to a fixed length of 500 words each sentence\n",
    "features_len=500\n",
    "\n",
    "X_train=sequence.pad_sequences(X_train,maxlen=features_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=features_len)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     1,    14,    22,    16,    43,   530,\n",
       "         973,  1622,  1385,    65,   458,  4468,    66,  3941,     4,\n",
       "         173,    36,   256,     5,    25,   100,    43,   838,   112,\n",
       "          50,   670, 22665,     9,    35,   480,   284,     5,   150,\n",
       "           4,   172,   112,   167, 21631,   336,   385,    39,     4,\n",
       "         172,  4536,  1111,    17,   546,    38,    13,   447,     4,\n",
       "         192,    50,    16,     6,   147,  2025,    19,    14,    22,\n",
       "           4,  1920,  4613,   469,     4,    22,    71,    87,    12,\n",
       "          16,    43,   530,    38,    76,    15,    13,  1247,     4,\n",
       "          22,    17,   515,    17,    12,    16,   626,    18, 19193,\n",
       "           5,    62,   386,    12,     8,   316,     8,   106,     5,\n",
       "           4,  2223,  5244,    16,   480,    66,  3785,    33,     4,\n",
       "         130,    12,    16,    38,   619,     5,    25,   124,    51,\n",
       "          36,   135,    48,    25,  1415,    33,     6,    22,    12,\n",
       "         215,    28,    77,    52,     5,    14,   407,    16,    82,\n",
       "       10311,     8,     4,   107,   117,  5952,    15,   256,     4,\n",
       "       31050,     7,  3766,     5,   723,    36,    71,    43,   530,\n",
       "         476,    26,   400,   317,    46,     7,     4, 12118,  1029,\n",
       "          13,   104,    88,     4,   381,    15,   297,    98,    32,\n",
       "        2071,    56,    26,   141,     6,   194,  7486,    18,     4,\n",
       "         226,    22,    21,   134,   476,    26,   480,     5,   144,\n",
       "          30,  5535,    18,    51,    36,    28,   224,    92,    25,\n",
       "         104,     4,   226,    65,    16,    38,  1334,    88,    12,\n",
       "          16,   283,     5,    16,  4472,   113,   103,    32,    15,\n",
       "          16,  5345,    19,   178,    32], dtype=int32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Embedding, SimpleRNN, GRU, Dropout, BatchNormalization, Dense\n",
    "\n",
    "# Parameters\n",
    "neurons = 256  # Number of neurons in the RNN layer\n",
    "embedding_dim = 100  # Dimension of the GloVe embeddings, exactly 100-dim as per 'glove.6B.100d.txt'\n",
    "\n",
    "# Create an embedding matrix\n",
    "embedding_matrix = np.zeros((vocabulary_size, embedding_dim))\n",
    "word_index = {word: idx for idx, (word, _) in enumerate(embedding_index.items())}  # Create a word-to-index mapping\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i < vocabulary_size:\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(features_len,)))\n",
    "model.add(Embedding(vocabulary_size, embedding_dim, weights=[embedding_matrix], input_length=features_len, trainable=False))  # Embedding Layer with pre-trained GloVe embeddings\n",
    "\n",
    "model.add(SimpleRNN(neurons, activation='relu'))\n",
    "model.add(Dropout(0.1))  # 10% of the neurons will be dropped out randomly during training, to avoid overfitting\n",
    "model.add(BatchNormalization())  # This may improve the training speed and stability\n",
    "\n",
    "model.add(Dense(1, activation=\"sigmoid\"))  # Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">40,000,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">91,392</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │    \u001b[38;5;34m40,000,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_2 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m91,392\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,092,673</span> (152.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,092,673\u001b[0m (152.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">92,161</span> (360.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m92,161\u001b[0m (360.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,000,512</span> (152.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m40,000,512\u001b[0m (152.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.early_stopping.EarlyStopping at 0x78322c2fbe30>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create an instance of EarlyStoppping Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "# Within 5 epochs, if the validation loss does not improve, stop the training and restore the best weights\n",
    "earlystopping=EarlyStopping(monitor='val_loss',patience=8,restore_best_weights=True)\n",
    "earlystopping\n",
    "# If the validation loss does not improve after 5 epochs, reduce the learning rate by 20%\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - accuracy: 0.5355 - loss: 0.7778 - val_accuracy: 0.5336 - val_loss: 0.7059\n",
      "Epoch 2/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.5962 - loss: 0.6644 - val_accuracy: 0.5446 - val_loss: 0.7267\n",
      "Epoch 3/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.6522 - loss: 0.6139 - val_accuracy: 0.6258 - val_loss: 0.6313\n",
      "Epoch 4/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.7024 - loss: 0.5581 - val_accuracy: 0.6402 - val_loss: 0.6247\n",
      "Epoch 5/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.7326 - loss: 0.5218 - val_accuracy: 0.5660 - val_loss: 1.0005\n",
      "Epoch 6/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.7718 - loss: 0.4719 - val_accuracy: 0.6754 - val_loss: 0.6373\n",
      "Epoch 7/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.8033 - loss: 0.4225 - val_accuracy: 0.6968 - val_loss: 0.6851\n",
      "Epoch 8/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.8200 - loss: 0.3879 - val_accuracy: 0.6224 - val_loss: 0.9098\n",
      "Epoch 9/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.8493 - loss: 0.3457 - val_accuracy: 0.6754 - val_loss: 0.7305\n",
      "Epoch 10/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.8755 - loss: 0.2991 - val_accuracy: 0.6794 - val_loss: 0.6993\n",
      "Epoch 11/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - accuracy: 0.8960 - loss: 0.2581 - val_accuracy: 0.5802 - val_loss: 1.5221\n",
      "Epoch 12/20\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - accuracy: 0.9052 - loss: 0.2346 - val_accuracy: 0.6658 - val_loss: 0.9016\n"
     ]
    }
   ],
   "source": [
    "## Train the model with early sstopping\n",
    "## Using each batch of 32 samples, and find the best weights for each batch. Total we have 25000 samples / 64 = 390 batches\n",
    "## Using batch would reduce memory comsumption and avoid finding the wrong descent, \n",
    "## as there could be multiple of local minimums (local descent), and we only\n",
    "## want to find the global minimum (global descent)\n",
    "## validation_split=0.2, means 20% of the training data will be used as validation data\n",
    "history=model.fit(\n",
    "    X_train,y_train,epochs=20,batch_size=128, # increase the number of epochs or batch_size will not add more training inputs\n",
    "    validation_split=0.2,\n",
    "    callbacks=[earlystopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.038194, -0.24487 ,  0.72812 , ..., -0.1459  ,  0.8278  ,\n",
       "          0.27062 ],\n",
       "        [-0.10767 ,  0.11053 ,  0.59812 , ..., -0.83155 ,  0.45293 ,\n",
       "          0.082577],\n",
       "        [-0.33979 ,  0.20941 ,  0.46348 , ..., -0.23394 ,  0.47298 ,\n",
       "         -0.028803],\n",
       "        ...,\n",
       "        [ 0.36088 , -0.16919 , -0.32704 , ...,  0.27139 , -0.29188 ,\n",
       "          0.16109 ],\n",
       "        [-0.10461 , -0.5047  , -0.49331 , ...,  0.42527 , -0.5125  ,\n",
       "         -0.17054 ],\n",
       "        [ 0.28365 , -0.6263  , -0.44351 , ...,  0.43678 , -0.82607 ,\n",
       "         -0.15701 ]], dtype=float32),\n",
       " array([[-0.02813263, -0.0177936 , -0.01759675, ..., -0.02882946,\n",
       "          0.10573576,  0.09064171],\n",
       "        [-0.0704998 , -0.02397074, -0.11444536, ...,  0.00479393,\n",
       "          0.00966559,  0.04764821],\n",
       "        [ 0.05483513,  0.10239789,  0.10863517, ..., -0.01021458,\n",
       "          0.00336485,  0.09119852],\n",
       "        ...,\n",
       "        [-0.05855448, -0.01211986,  0.02046069, ..., -0.11447552,\n",
       "          0.04384724,  0.05933198],\n",
       "        [-0.12247192, -0.00762466,  0.11153005, ...,  0.01691887,\n",
       "          0.0950985 ,  0.04993893],\n",
       "        [-0.01862229, -0.04779902,  0.04359107, ...,  0.12018511,\n",
       "         -0.10293352, -0.1159651 ]], dtype=float32),\n",
       " array([[-0.01650094,  0.00694194, -0.08635143, ...,  0.03586689,\n",
       "          0.03242715, -0.00462036],\n",
       "        [ 0.00172464, -0.0552492 , -0.09393239, ..., -0.03931665,\n",
       "          0.02954313,  0.07916426],\n",
       "        [-0.08962361, -0.04743648, -0.03345624, ...,  0.01106471,\n",
       "          0.01943517, -0.05190976],\n",
       "        ...,\n",
       "        [-0.01685865,  0.03221409,  0.0659224 , ..., -0.00311488,\n",
       "          0.11223346,  0.06724053],\n",
       "        [ 0.05109037,  0.12865609, -0.02642468, ...,  0.06720541,\n",
       "          0.03335632, -0.06662247],\n",
       "        [ 0.05667503,  0.01030294, -0.013897  , ...,  0.0135336 ,\n",
       "          0.07404743, -0.03428696]], dtype=float32),\n",
       " array([-0.02039163,  0.01038244, -0.01628206,  0.00801811, -0.00482993,\n",
       "        -0.02544345, -0.01598956,  0.00949109, -0.00777996, -0.0065367 ,\n",
       "         0.00647675,  0.02181412, -0.01042655,  0.00579185,  0.00042686,\n",
       "         0.00154382, -0.00781497, -0.00385609,  0.01033783,  0.01434044,\n",
       "        -0.00856467, -0.02486821, -0.01616798, -0.02643391,  0.00483382,\n",
       "        -0.01403739,  0.01937794, -0.00837898, -0.02358824,  0.01663725,\n",
       "        -0.01173368,  0.00567984,  0.01090952, -0.0027435 ,  0.00467631,\n",
       "        -0.01362905, -0.00444673, -0.01157971, -0.01107348, -0.00681747,\n",
       "        -0.00030397, -0.00455451, -0.01028141, -0.03302333,  0.02295077,\n",
       "        -0.04899578,  0.01678656,  0.01634432, -0.013669  , -0.00688463,\n",
       "        -0.0080011 , -0.01533342, -0.03493087, -0.0299794 ,  0.0017145 ,\n",
       "        -0.02430208, -0.01572143,  0.00688535,  0.00767181, -0.01050256,\n",
       "         0.01336195, -0.01266374, -0.01404432, -0.0010847 , -0.00852013,\n",
       "        -0.03595526, -0.00566232,  0.00539673, -0.0235777 ,  0.00357865,\n",
       "        -0.03071326, -0.00735543, -0.00620016, -0.01359553, -0.01129531,\n",
       "        -0.00668007, -0.02474664,  0.00167232,  0.00884702,  0.03052011,\n",
       "        -0.01766123,  0.00490462,  0.00647535, -0.02392769, -0.00151888,\n",
       "         0.0090643 , -0.00707149, -0.03404545, -0.01370384, -0.01830433,\n",
       "        -0.00846584, -0.00105404, -0.00839633, -0.03255812,  0.00804536,\n",
       "        -0.03144225, -0.03583631, -0.00684794, -0.0131912 ,  0.01280097,\n",
       "        -0.01365025,  0.00850045, -0.00783305, -0.01394231,  0.01086026,\n",
       "         0.01373283, -0.00655864, -0.02703058, -0.00213027,  0.00867275,\n",
       "        -0.03246711, -0.00692999, -0.0241357 ,  0.00203342,  0.01110843,\n",
       "        -0.00477259, -0.03026898,  0.00548542, -0.00793043,  0.00875967,\n",
       "         0.00172387, -0.01347807, -0.00443619, -0.00347721, -0.00845053,\n",
       "        -0.01590213, -0.01658663,  0.0020198 , -0.02081207, -0.00073782,\n",
       "        -0.00047313, -0.0121707 ,  0.00253162, -0.01411702, -0.02108641,\n",
       "        -0.01236068, -0.03224854, -0.00836085, -0.0144169 ,  0.00887513,\n",
       "        -0.02154778, -0.03629826, -0.00852689, -0.00764004, -0.007503  ,\n",
       "        -0.02998917,  0.01020721, -0.00915349, -0.02848827,  0.00923138,\n",
       "        -0.0035158 , -0.0195346 , -0.01095555, -0.02788018, -0.00771932,\n",
       "         0.00870306,  0.00534782, -0.02209488,  0.00300658,  0.00486432,\n",
       "        -0.0030722 , -0.0276354 ,  0.00994753, -0.00993695, -0.01713031,\n",
       "        -0.00622869, -0.03981025, -0.00323786,  0.00051538,  0.02530432,\n",
       "        -0.01772173, -0.02766936, -0.01480878,  0.01199524,  0.00554413,\n",
       "         0.00749465,  0.00848851,  0.01508981, -0.00633488,  0.01241448,\n",
       "         0.01251365,  0.0028114 , -0.00399294, -0.01689095,  0.0028948 ,\n",
       "        -0.00553573,  0.01113412, -0.04046326, -0.03435873, -0.01575652,\n",
       "        -0.03204704, -0.01113679,  0.03128295,  0.00789834, -0.01976284,\n",
       "        -0.01541908,  0.00760879, -0.00752561, -0.00921919, -0.0192386 ,\n",
       "         0.00526594, -0.01422111, -0.00853146,  0.00825671,  0.0276546 ,\n",
       "        -0.02216736, -0.04486541, -0.03135648,  0.02181227, -0.00985854,\n",
       "         0.01162506, -0.0033819 , -0.00340386, -0.01729534,  0.00475164,\n",
       "        -0.03401954, -0.00775729,  0.01475685, -0.01424178, -0.01629448,\n",
       "        -0.03374784, -0.03671727, -0.01500967, -0.02467813, -0.00939246,\n",
       "        -0.0326431 , -0.020031  , -0.02270573, -0.02815327, -0.01467104,\n",
       "        -0.01934522, -0.00563928, -0.00111847,  0.02432296,  0.00783204,\n",
       "        -0.02409095, -0.00561346,  0.00698315, -0.00280676, -0.00875122,\n",
       "         0.00111155, -0.01532949, -0.01287889, -0.03179436,  0.00971332,\n",
       "        -0.0171219 , -0.01879543, -0.01222752, -0.01576782, -0.00525824,\n",
       "         0.02457359, -0.00502066, -0.03226224, -0.01140647,  0.0141583 ,\n",
       "        -0.01739824], dtype=float32),\n",
       " array([0.9909206 , 0.97370124, 0.92531735, 0.97019905, 1.0256219 ,\n",
       "        0.96672463, 0.998551  , 0.9889648 , 0.924129  , 1.041345  ,\n",
       "        0.938252  , 0.97230226, 0.9288853 , 0.96609426, 1.0113795 ,\n",
       "        0.9479315 , 0.9532758 , 1.0025581 , 0.92646027, 0.98372626,\n",
       "        0.946101  , 0.9915842 , 1.0082256 , 0.9844562 , 0.9323801 ,\n",
       "        0.9830186 , 1.0084094 , 0.95688194, 1.0464729 , 0.9684184 ,\n",
       "        0.9619919 , 0.9380209 , 0.97832537, 0.97305244, 0.92585516,\n",
       "        1.0114708 , 0.93145216, 0.97367513, 0.9356284 , 0.93916696,\n",
       "        0.97419107, 0.9951218 , 1.0242496 , 0.9438128 , 0.9374689 ,\n",
       "        0.9693149 , 0.9569927 , 0.9765462 , 0.94540817, 0.9570849 ,\n",
       "        1.0337056 , 1.0004284 , 1.0021658 , 0.972211  , 0.95799124,\n",
       "        1.0301192 , 0.9795883 , 0.9521316 , 0.98281807, 0.9537826 ,\n",
       "        0.98907226, 0.99964744, 0.9912923 , 0.95185304, 0.9430058 ,\n",
       "        1.0915022 , 0.9633569 , 0.9251391 , 0.96017265, 0.951888  ,\n",
       "        1.0117106 , 0.9880188 , 1.0007603 , 1.0546328 , 0.9702439 ,\n",
       "        0.9592674 , 1.0213434 , 0.9529369 , 0.9442696 , 0.99371934,\n",
       "        0.9940817 , 0.9428041 , 0.97261006, 0.96181744, 1.0782765 ,\n",
       "        0.94836646, 1.0435396 , 0.9737747 , 0.98253876, 0.9749745 ,\n",
       "        0.966734  , 0.9784139 , 0.99996996, 0.96820563, 0.96151555,\n",
       "        0.98833275, 0.94428366, 1.0086704 , 1.001323  , 0.9544103 ,\n",
       "        0.96164036, 0.98574287, 0.96128076, 0.981831  , 0.9783471 ,\n",
       "        0.9866088 , 0.9586944 , 1.0077484 , 0.9402798 , 0.95587337,\n",
       "        0.9783774 , 0.9854117 , 0.9944425 , 0.9591247 , 0.96902883,\n",
       "        0.9873601 , 0.95424825, 0.9698348 , 0.9679858 , 0.94175684,\n",
       "        1.0089159 , 1.0530488 , 0.97651404, 0.983909  , 0.973736  ,\n",
       "        0.9717035 , 0.9490229 , 0.9286035 , 0.985589  , 0.9750125 ,\n",
       "        0.9683015 , 0.96317023, 0.94647634, 0.96637684, 0.96561104,\n",
       "        0.9521453 , 1.0072347 , 0.99822575, 0.9647509 , 0.9754827 ,\n",
       "        0.9696711 , 0.99237543, 1.014918  , 0.984071  , 1.0107393 ,\n",
       "        0.94680595, 0.95000064, 0.97137547, 1.0189565 , 0.95854515,\n",
       "        0.9794777 , 0.9844631 , 0.95504713, 0.9952338 , 0.9791043 ,\n",
       "        0.9667436 , 0.97885877, 1.0019244 , 0.94843954, 0.9490041 ,\n",
       "        0.94443727, 0.97626483, 1.0001947 , 0.95146924, 0.9361746 ,\n",
       "        0.98194623, 1.0067375 , 0.98569953, 0.9168566 , 0.94160277,\n",
       "        0.96738136, 0.9584822 , 0.9690684 , 0.91935223, 0.9935058 ,\n",
       "        0.9749196 , 0.95968586, 0.94492054, 0.9824325 , 0.98666155,\n",
       "        0.9591594 , 0.93148595, 0.97517264, 0.96463895, 0.9600964 ,\n",
       "        1.0046531 , 0.9950992 , 0.98943335, 1.0528387 , 0.97384137,\n",
       "        0.9869034 , 0.98607284, 0.9676569 , 0.9415415 , 0.98858625,\n",
       "        0.9725292 , 0.96010655, 0.9500132 , 0.9359859 , 0.981617  ,\n",
       "        0.9345498 , 0.95547706, 0.95126593, 1.0118364 , 0.95279974,\n",
       "        0.9599683 , 0.9625118 , 0.98222214, 0.9816075 , 0.97592217,\n",
       "        0.9041988 , 0.9897884 , 0.9419361 , 1.0485846 , 0.9665097 ,\n",
       "        1.0018064 , 0.9285214 , 0.95921683, 1.0103365 , 0.9770798 ,\n",
       "        0.9780101 , 0.97288144, 0.9354632 , 0.9790899 , 0.9771917 ,\n",
       "        0.9733086 , 0.95365584, 1.0349507 , 0.98335207, 0.98321676,\n",
       "        0.99035776, 0.95726216, 0.9280973 , 0.95099884, 0.9804622 ,\n",
       "        0.95766306, 0.958593  , 0.942409  , 0.9689932 , 0.949265  ,\n",
       "        0.94118476, 0.9786797 , 0.9838249 , 0.95563877, 0.9765426 ,\n",
       "        0.9911942 , 1.0024185 , 0.98867524, 1.0430962 , 0.97772574,\n",
       "        0.961306  , 0.9581034 , 1.0213585 , 0.98858374, 0.9438951 ,\n",
       "        0.97633684], dtype=float32),\n",
       " array([-2.72793649e-03,  6.51862531e-04,  1.16937980e-03,  2.61584180e-03,\n",
       "         3.87522206e-03,  1.68906630e-03, -3.06246278e-04, -3.07434093e-05,\n",
       "        -1.23102916e-03,  1.13765818e-04,  6.51382958e-04, -7.27681443e-04,\n",
       "        -2.11828330e-04, -2.71956134e-03,  1.36334056e-04,  9.12617135e-04,\n",
       "        -1.11308536e-02,  3.21837317e-04,  2.81670509e-05,  1.07288198e-03,\n",
       "        -3.03254841e-04,  1.25260430e-03, -1.03246735e-03, -1.83786033e-05,\n",
       "         2.76777660e-04,  3.87467886e-03,  5.99825103e-03, -2.65298528e-04,\n",
       "        -2.56301346e-03,  7.35401525e-04,  3.50681541e-04,  1.35332160e-03,\n",
       "        -8.83281173e-04, -4.47393768e-03,  5.14132989e-06,  3.28576367e-04,\n",
       "         2.76755803e-04,  1.92510930e-03,  6.16995792e-04,  2.16005545e-04,\n",
       "         5.90519561e-03, -4.18299402e-04, -1.14122091e-03, -7.89460668e-04,\n",
       "         5.60551242e-04, -6.62824954e-04,  2.04886380e-03,  1.68091341e-04,\n",
       "         3.45489025e-05, -9.96381277e-04, -4.65888006e-04, -3.20188352e-04,\n",
       "        -1.49143249e-04, -5.93702018e-04, -2.57585896e-04, -2.56014615e-03,\n",
       "        -8.01278278e-04, -2.76373175e-04,  3.82329163e-04, -3.37708252e-03,\n",
       "        -3.02491011e-04,  3.75191506e-04, -4.00810532e-04, -2.29879719e-04,\n",
       "         5.71980199e-04, -7.47396552e-04, -2.31398363e-02,  2.65328621e-04,\n",
       "        -1.61286758e-03, -9.04029643e-04, -9.29449103e-04, -3.96772375e-04,\n",
       "        -2.76690768e-03, -1.19707984e-05,  4.24074766e-04,  6.24451088e-04,\n",
       "         9.98612726e-04,  7.74968998e-04,  4.70509025e-04, -6.53213065e-04,\n",
       "         2.52260041e-04,  5.09170495e-05, -2.80060014e-03, -8.83408880e-04,\n",
       "         1.83881307e-03, -1.81953236e-03,  1.18018326e-03, -1.08960271e-03,\n",
       "        -4.81737021e-04,  1.12604839e-03, -7.14918016e-04,  8.61393055e-04,\n",
       "        -4.89495322e-03,  8.20277375e-04,  1.06285803e-03, -1.17970072e-03,\n",
       "         8.60448417e-05,  1.90206419e-03, -1.54516997e-03,  2.15226272e-03,\n",
       "         1.34698860e-03,  1.48994918e-03, -8.36063828e-03,  1.06939359e-03,\n",
       "         5.33332699e-04,  2.17861682e-03, -5.46409574e-04, -1.30656001e-03,\n",
       "         4.23290359e-04,  1.86929494e-04,  6.51126727e-04,  2.63973372e-04,\n",
       "        -1.17544713e-03,  3.64984677e-04, -1.44498830e-03,  1.23433850e-03,\n",
       "         8.95221659e-04,  1.06466317e-03, -2.01881304e-03,  3.07207520e-04,\n",
       "        -8.90254974e-04, -6.88319746e-03,  1.25848362e-03, -1.10824301e-03,\n",
       "        -5.67701471e-04,  2.61172792e-03,  1.71038904e-03,  1.21219479e-03,\n",
       "         6.94287446e-05,  3.85187170e-03,  1.05293038e-04,  1.06675532e-02,\n",
       "        -6.24584442e-04, -1.41828053e-03, -2.74621329e-04,  7.84463075e-04,\n",
       "        -1.17996102e-03, -3.41440551e-03,  1.87174638e-03,  9.34051524e-04,\n",
       "         1.55695784e-03, -5.37716260e-04,  1.41342334e-03,  3.45245877e-04,\n",
       "         5.57814771e-03, -5.68070333e-04, -9.36907600e-04,  9.80910962e-04,\n",
       "        -4.74567933e-04, -3.55612938e-05,  1.77729072e-03, -1.07227825e-03,\n",
       "         7.98046647e-04, -1.06696284e-03,  2.02494184e-03,  6.45514927e-04,\n",
       "        -1.73432368e-03,  9.42410552e-04, -6.48333749e-04,  4.89701226e-04,\n",
       "        -1.33174995e-04,  5.11113438e-04,  9.51922382e-04,  4.35003691e-04,\n",
       "         1.39682466e-04,  1.85999472e-03,  1.62189733e-03,  5.88567345e-04,\n",
       "        -5.06281271e-04, -5.02612558e-04,  6.60119869e-04, -2.84143520e-04,\n",
       "        -1.66102871e-03, -3.73386545e-03,  3.92148457e-03, -1.39508094e-03,\n",
       "         1.48118299e-04,  7.42954726e-04, -1.82549912e-03,  9.39934806e-04,\n",
       "        -8.20219720e-05, -4.74328117e-05,  7.40599469e-04,  3.68703477e-04,\n",
       "         1.15899090e-03, -8.27743032e-04, -1.47881242e-03, -1.42747001e-03,\n",
       "         6.43667998e-04, -4.45348676e-03,  7.48265884e-04, -7.00565940e-03,\n",
       "         3.25923762e-03, -1.23624195e-04,  2.04674230e-04, -2.54968461e-03,\n",
       "        -7.26408092e-04,  7.07072730e-04,  8.26679461e-04,  1.20286690e-03,\n",
       "        -1.40730652e-03, -1.12373056e-03, -1.56989627e-04, -7.22528028e-04,\n",
       "        -6.70475012e-04, -1.86055375e-04, -6.93987880e-04,  1.16583251e-03,\n",
       "         6.17327343e-04,  4.79116803e-04,  3.98268504e-03,  1.03291618e-02,\n",
       "         8.30502075e-04, -4.31760272e-04,  1.20640686e-03, -2.11095950e-03,\n",
       "        -3.59006342e-04, -2.08430909e-04,  3.97537282e-04, -1.06545340e-03,\n",
       "        -8.91325879e-04, -5.25971176e-04,  4.69568768e-05, -1.37038541e-03,\n",
       "         2.42845053e-04, -6.39826583e-04,  9.41768463e-04,  7.01450626e-04,\n",
       "        -3.20125022e-04,  9.56517993e-04, -2.82651745e-03, -9.45954293e-04,\n",
       "        -5.38432141e-05,  2.12751771e-03, -2.31965026e-03, -5.56592131e-04,\n",
       "         1.38899395e-02,  6.79828576e-04, -1.19317439e-03,  4.99097514e-04,\n",
       "         2.04777753e-04, -1.63468256e-04,  1.44591730e-04,  1.76413786e-02,\n",
       "         2.88393814e-04,  1.87173137e-04,  1.87051808e-03,  9.16722231e-04,\n",
       "        -2.86601367e-04, -4.68717364e-04,  2.02596583e-03,  1.56855531e-04,\n",
       "         6.00983622e-04,  6.58729696e-04, -9.77053773e-04, -9.76332929e-04],\n",
       "       dtype=float32),\n",
       " array([1.56260305e-03, 1.83509097e-01, 8.73862281e-02, 5.35884909e-02,\n",
       "        4.70922282e-03, 4.33834875e-03, 3.18871858e-03, 3.70951705e-02,\n",
       "        1.35143548e-01, 2.62636412e-02, 1.40830055e-01, 2.29132771e-01,\n",
       "        2.60907058e-02, 6.12154901e-01, 2.14117635e-02, 1.88191645e-02,\n",
       "        1.68905836e-02, 4.89393175e-02, 1.96926892e-01, 7.25131482e-02,\n",
       "        2.51190156e-01, 6.23844005e-02, 3.42562012e-02, 3.59120808e-04,\n",
       "        2.82340676e-01, 2.29013246e-03, 6.82964742e-01, 3.28057297e-02,\n",
       "        6.40104245e-03, 2.85801023e-01, 3.82881761e-01, 5.33943057e-01,\n",
       "        3.60934258e-01, 2.18423709e-01, 2.40524948e-01, 2.69556828e-02,\n",
       "        2.79352404e-02, 2.02354956e-02, 2.14288309e-01, 1.75034374e-01,\n",
       "        7.99610138e-01, 9.78800580e-02, 5.78380749e-02, 5.28548053e-03,\n",
       "        2.42105529e-01, 9.01406922e-04, 7.15582013e-01, 3.98746610e-01,\n",
       "        4.66656685e-01, 6.98079020e-02, 6.56424463e-02, 3.76161896e-02,\n",
       "        4.93555563e-04, 3.66096268e-03, 1.50310636e-01, 1.58773421e-03,\n",
       "        3.51907045e-04, 1.87448263e-01, 4.32051897e-01, 3.68592173e-01,\n",
       "        3.94731574e-02, 8.85699913e-02, 9.30096284e-02, 1.84707060e-01,\n",
       "        3.29269581e-02, 4.02215160e-02, 5.68875708e-02, 4.19906557e-01,\n",
       "        2.81468481e-02, 1.91260532e-01, 3.93928902e-04, 1.22937309e-02,\n",
       "        9.34178941e-03, 7.59468647e-03, 7.31443986e-02, 8.03404376e-02,\n",
       "        1.11679931e-03, 3.11254025e-01, 5.87159872e-01, 4.11858082e-01,\n",
       "        2.12906182e-01, 1.35501057e-01, 3.31733644e-01, 1.03837037e-02,\n",
       "        2.17800185e-01, 6.25526488e-01, 2.11832732e-01, 2.59063178e-04,\n",
       "        7.04976148e-04, 8.95665959e-04, 5.03813066e-02, 1.47891194e-01,\n",
       "        2.44979486e-01, 3.41783697e-03, 9.63205937e-03, 2.37774779e-03,\n",
       "        7.06914579e-03, 4.92863990e-02, 2.47081995e-01, 5.05238950e-01,\n",
       "        9.32538807e-02, 7.06449803e-03, 2.83665150e-01, 4.48864000e-03,\n",
       "        1.82131410e-01, 7.46555254e-02, 1.52671784e-01, 6.37777662e-03,\n",
       "        1.41859397e-01, 3.74655575e-01, 2.29801214e-03, 6.11062199e-02,\n",
       "        7.22063298e-04, 3.82045060e-01, 3.10715497e-01, 2.51028109e-02,\n",
       "        5.81867173e-02, 2.53472298e-01, 5.24631023e-01, 5.24954796e-01,\n",
       "        3.71441916e-02, 1.01426607e-02, 1.54475033e-01, 1.49089590e-01,\n",
       "        2.65632153e-01, 4.94646234e-03, 3.44007043e-03, 5.06697297e-01,\n",
       "        6.39194390e-03, 4.63613197e-02, 1.57995224e-01, 3.79144475e-02,\n",
       "        2.00171292e-01, 1.24083742e-01, 2.06157845e-02, 5.05634487e-01,\n",
       "        7.89711475e-02, 1.13759480e-01, 1.31977215e-01, 8.34761411e-02,\n",
       "        4.41657007e-01, 1.09249039e-03, 1.98933765e-01, 5.98843545e-02,\n",
       "        1.07891046e-01, 1.69593026e-03, 1.75492287e-01, 3.63592282e-02,\n",
       "        1.07389465e-01, 2.56612778e-01, 6.97873458e-02, 1.33743614e-01,\n",
       "        1.52127549e-01, 9.72271548e-04, 8.05244982e-01, 2.55178690e-01,\n",
       "        2.25388840e-01, 7.39283906e-03, 2.19624445e-01, 7.53481761e-02,\n",
       "        4.74284440e-01, 1.23015661e-02, 8.24183285e-01, 9.92751494e-03,\n",
       "        1.48214862e-01, 4.07884009e-02, 2.93715335e-02, 4.02523652e-02,\n",
       "        6.54887110e-02, 2.85557270e-01, 3.27764964e-03, 2.44677253e-03,\n",
       "        2.46491674e-02, 7.11142898e-01, 1.49848517e-02, 3.70672494e-01,\n",
       "        1.90987945e-01, 3.88843864e-01, 2.86954343e-01, 5.12217820e-01,\n",
       "        7.86182880e-01, 3.77264231e-01, 3.87909204e-01, 1.08791646e-02,\n",
       "        3.71360093e-01, 7.58762509e-02, 5.48141479e-01, 1.41500763e-03,\n",
       "        1.78291788e-03, 2.93309279e-02, 2.30331832e-04, 5.96397044e-03,\n",
       "        9.63166915e-03, 2.27299765e-01, 1.11884961e-03, 9.94651467e-02,\n",
       "        1.59339249e-01, 1.70715243e-01, 1.60987437e-01, 4.01819445e-04,\n",
       "        1.69620618e-01, 3.43590491e-02, 1.51539415e-01, 9.82629582e-02,\n",
       "        6.41005993e-01, 3.22222686e-03, 5.49931219e-03, 1.17737346e-03,\n",
       "        2.70391136e-01, 3.07213724e-01, 6.96544409e-01, 9.95998234e-02,\n",
       "        1.67653501e-01, 3.59852761e-02, 3.53612274e-01, 1.01336157e-02,\n",
       "        5.21211028e-01, 3.61304879e-01, 4.29748744e-02, 2.90848874e-02,\n",
       "        4.95554041e-03, 5.30391662e-05, 2.60629766e-02, 3.82978120e-04,\n",
       "        6.75615370e-02, 7.84613003e-05, 4.53633163e-03, 5.75904325e-02,\n",
       "        4.14243812e-04, 1.24765988e-02, 8.43045395e-03, 5.60278371e-02,\n",
       "        3.72881889e-01, 4.60734516e-01, 1.32373661e-01, 7.78487476e-04,\n",
       "        1.99689735e-02, 2.20666587e-01, 9.20135528e-02, 2.16031656e-01,\n",
       "        2.60104835e-01, 1.86704844e-02, 4.63610888e-01, 8.20830057e-04,\n",
       "        4.09152508e-01, 8.36131349e-03, 1.32615166e-03, 5.44708967e-03,\n",
       "        6.62910659e-03, 2.77737647e-01, 7.36294627e-01, 2.40657076e-01,\n",
       "        5.72027930e-04, 5.81941344e-02, 3.24007094e-01, 1.99850090e-03],\n",
       "       dtype=float32),\n",
       " array([0.00243068, 0.07554071, 0.03418198, 0.02711687, 0.0041251 ,\n",
       "        0.00403982, 0.0033595 , 0.02142041, 0.05781953, 0.01947216,\n",
       "        0.06104267, 0.09822026, 0.01310844, 0.20100197, 0.01187055,\n",
       "        0.01073929, 0.00828938, 0.02560534, 0.08106975, 0.03365013,\n",
       "        0.12855044, 0.02892354, 0.01848112, 0.00190634, 0.13496733,\n",
       "        0.00254452, 0.27338913, 0.02070693, 0.00421653, 0.11351033,\n",
       "        0.16855718, 0.19109179, 0.16648214, 0.08749985, 0.09579813,\n",
       "        0.01340161, 0.0177193 , 0.01100753, 0.08137837, 0.08778536,\n",
       "        0.2722472 , 0.05146354, 0.02260037, 0.00576509, 0.10970238,\n",
       "        0.0021919 , 0.30550995, 0.16650246, 0.22419278, 0.04184166,\n",
       "        0.03112476, 0.01391444, 0.00201175, 0.00322914, 0.07563268,\n",
       "        0.00246683, 0.00196186, 0.08877923, 0.18217641, 0.15459263,\n",
       "        0.02046414, 0.05781661, 0.0477959 , 0.07598978, 0.01790801,\n",
       "        0.02864377, 0.02814907, 0.15273336, 0.01308029, 0.07536457,\n",
       "        0.00193888, 0.00799074, 0.00637466, 0.00550461, 0.03615406,\n",
       "        0.0411616 , 0.00238973, 0.12344687, 0.20410855, 0.19329545,\n",
       "        0.10094912, 0.06206843, 0.12954277, 0.0067654 , 0.09729245,\n",
       "        0.21863835, 0.07780527, 0.00189811, 0.00213635, 0.00222089,\n",
       "        0.02151104, 0.07363919, 0.12080403, 0.00312962, 0.00580161,\n",
       "        0.00273394, 0.00530415, 0.02885197, 0.12608851, 0.19630525,\n",
       "        0.04097876, 0.0042991 , 0.12156407, 0.00352747, 0.07441219,\n",
       "        0.03565485, 0.05923418, 0.00515964, 0.05711049, 0.14616874,\n",
       "        0.00280032, 0.03023533, 0.00208357, 0.16914001, 0.11620419,\n",
       "        0.013131  , 0.02461019, 0.1107522 , 0.22412542, 0.22173506,\n",
       "        0.01868511, 0.00573906, 0.07824603, 0.07818048, 0.10286412,\n",
       "        0.00367238, 0.00328438, 0.18590654, 0.00488069, 0.02351387,\n",
       "        0.07967339, 0.02328873, 0.08786181, 0.05528741, 0.01052475,\n",
       "        0.22099505, 0.04195423, 0.04988508, 0.05745741, 0.04148887,\n",
       "        0.19990438, 0.00216095, 0.08630059, 0.03137413, 0.05302685,\n",
       "        0.00235553, 0.07450407, 0.02053977, 0.05783089, 0.10481588,\n",
       "        0.03892754, 0.07220978, 0.06308005, 0.00226574, 0.30961332,\n",
       "        0.11778632, 0.1001166 , 0.00513051, 0.09402024, 0.0308935 ,\n",
       "        0.16718987, 0.00667565, 0.33982083, 0.00610486, 0.07224587,\n",
       "        0.01948667, 0.01497633, 0.02293868, 0.03416888, 0.14809245,\n",
       "        0.00343536, 0.00279985, 0.01127262, 0.23861933, 0.0084677 ,\n",
       "        0.13643773, 0.08365346, 0.18335742, 0.10014784, 0.21121441,\n",
       "        0.27556664, 0.14703827, 0.15307583, 0.00626138, 0.14226834,\n",
       "        0.03717034, 0.21480152, 0.00238847, 0.00253659, 0.01386552,\n",
       "        0.00188062, 0.00456017, 0.00627674, 0.10690633, 0.00226468,\n",
       "        0.04240667, 0.07053087, 0.06282977, 0.0674082 , 0.00194353,\n",
       "        0.08773871, 0.01604334, 0.06196983, 0.04790461, 0.25245714,\n",
       "        0.00306595, 0.00378292, 0.00232523, 0.1295264 , 0.13895252,\n",
       "        0.24343   , 0.04551277, 0.0813133 , 0.01958014, 0.13195871,\n",
       "        0.00517242, 0.184975  , 0.14487223, 0.0224876 , 0.01357227,\n",
       "        0.00360367, 0.00182511, 0.01170101, 0.00200448, 0.0346682 ,\n",
       "        0.00183724, 0.00359769, 0.02518841, 0.0019472 , 0.00734815,\n",
       "        0.00465798, 0.02712991, 0.14831312, 0.15527561, 0.05680183,\n",
       "        0.00210106, 0.01102616, 0.11575355, 0.04219214, 0.09285878,\n",
       "        0.10765818, 0.01080869, 0.20349444, 0.0021531 , 0.14019202,\n",
       "        0.00621628, 0.00237372, 0.0041185 , 0.00445639, 0.1256597 ,\n",
       "        0.2642882 , 0.11392276, 0.00205535, 0.0299969 , 0.12740731,\n",
       "        0.00255062], dtype=float32),\n",
       " array([[ 2.25415844e-02],\n",
       "        [-2.23310984e-04],\n",
       "        [-7.21098483e-02],\n",
       "        [ 4.46691038e-03],\n",
       "        [-3.91609855e-02],\n",
       "        [-7.40377232e-02],\n",
       "        [ 4.91429046e-02],\n",
       "        [ 4.21702489e-02],\n",
       "        [ 5.80768026e-02],\n",
       "        [ 5.40266708e-02],\n",
       "        [-5.92312254e-02],\n",
       "        [ 4.77636307e-02],\n",
       "        [ 4.92855571e-02],\n",
       "        [ 5.60524082e-03],\n",
       "        [-8.09468031e-02],\n",
       "        [-6.01319931e-02],\n",
       "        [-3.11488006e-03],\n",
       "        [ 8.05113465e-02],\n",
       "        [-4.69808429e-02],\n",
       "        [-4.54602316e-02],\n",
       "        [ 5.76264113e-02],\n",
       "        [-1.02514766e-01],\n",
       "        [ 6.80221915e-02],\n",
       "        [ 3.86664346e-02],\n",
       "        [ 4.32300381e-02],\n",
       "        [-6.66108332e-04],\n",
       "        [-3.21522839e-02],\n",
       "        [ 7.48892576e-02],\n",
       "        [-4.05786186e-02],\n",
       "        [-7.69211957e-03],\n",
       "        [ 3.18142623e-02],\n",
       "        [ 1.94538739e-02],\n",
       "        [ 2.74550710e-02],\n",
       "        [ 3.23812652e-04],\n",
       "        [ 4.06747572e-02],\n",
       "        [-6.95864931e-02],\n",
       "        [-7.63740093e-02],\n",
       "        [-5.40355742e-02],\n",
       "        [-4.97158319e-02],\n",
       "        [ 6.19118623e-02],\n",
       "        [-1.07990447e-02],\n",
       "        [ 3.59470062e-02],\n",
       "        [-3.84964086e-02],\n",
       "        [ 8.18667412e-02],\n",
       "        [-5.36570475e-02],\n",
       "        [ 1.17724404e-01],\n",
       "        [-3.01154573e-02],\n",
       "        [ 4.79288176e-02],\n",
       "        [ 5.53564616e-02],\n",
       "        [ 1.00609139e-01],\n",
       "        [ 4.68564332e-02],\n",
       "        [ 5.11006638e-02],\n",
       "        [-4.74172533e-02],\n",
       "        [ 1.42060788e-02],\n",
       "        [-2.32833885e-02],\n",
       "        [ 6.54234439e-02],\n",
       "        [ 1.17980085e-01],\n",
       "        [ 6.06485568e-02],\n",
       "        [ 1.25355022e-02],\n",
       "        [ 7.45234918e-03],\n",
       "        [ 5.23962639e-02],\n",
       "        [-9.66016203e-02],\n",
       "        [ 4.90049720e-02],\n",
       "        [ 6.02483153e-02],\n",
       "        [-1.64141860e-02],\n",
       "        [ 2.25361377e-01],\n",
       "        [-1.48842270e-02],\n",
       "        [ 4.34033237e-02],\n",
       "        [ 8.01065266e-02],\n",
       "        [ 7.44367018e-02],\n",
       "        [ 1.30822346e-01],\n",
       "        [-5.59906773e-02],\n",
       "        [ 3.66356000e-02],\n",
       "        [-1.09075032e-01],\n",
       "        [-1.17299803e-01],\n",
       "        [ 4.54255193e-03],\n",
       "        [-4.39299196e-02],\n",
       "        [-4.46481109e-02],\n",
       "        [-5.88617334e-03],\n",
       "        [ 3.27486843e-02],\n",
       "        [-4.01647091e-02],\n",
       "        [ 5.43519035e-02],\n",
       "        [ 7.60958064e-04],\n",
       "        [ 6.07383512e-02],\n",
       "        [ 6.44014031e-02],\n",
       "        [ 3.34637612e-02],\n",
       "        [-5.56782074e-02],\n",
       "        [ 9.88748223e-02],\n",
       "        [ 1.14843197e-01],\n",
       "        [-1.13213792e-01],\n",
       "        [ 2.80831363e-02],\n",
       "        [-1.07464932e-01],\n",
       "        [ 2.54803319e-02],\n",
       "        [-8.89773890e-02],\n",
       "        [-5.93504794e-02],\n",
       "        [ 1.07636027e-01],\n",
       "        [-7.49967545e-02],\n",
       "        [-4.23767194e-02],\n",
       "        [ 7.91673437e-02],\n",
       "        [-2.05827057e-02],\n",
       "        [-9.39292237e-02],\n",
       "        [ 4.62451056e-02],\n",
       "        [ 1.84768916e-03],\n",
       "        [ 2.47483198e-02],\n",
       "        [-8.17737430e-02],\n",
       "        [ 4.60561030e-02],\n",
       "        [ 4.27016579e-02],\n",
       "        [ 7.81568661e-02],\n",
       "        [-8.73826146e-02],\n",
       "        [-4.15125825e-02],\n",
       "        [-4.09817733e-02],\n",
       "        [ 3.38935740e-02],\n",
       "        [ 9.22781751e-02],\n",
       "        [-8.65081027e-02],\n",
       "        [-7.80273695e-03],\n",
       "        [-5.72812334e-02],\n",
       "        [-9.92843658e-02],\n",
       "        [-3.08873458e-03],\n",
       "        [-1.05015989e-02],\n",
       "        [ 5.60860150e-02],\n",
       "        [ 8.49652961e-02],\n",
       "        [ 4.60423790e-02],\n",
       "        [-5.06474040e-02],\n",
       "        [ 5.08102961e-02],\n",
       "        [ 2.20244061e-02],\n",
       "        [-3.81192081e-02],\n",
       "        [-7.00686947e-02],\n",
       "        [-6.10731281e-02],\n",
       "        [-7.92406425e-02],\n",
       "        [-2.90799886e-02],\n",
       "        [-7.91143030e-02],\n",
       "        [-8.87869578e-03],\n",
       "        [ 5.62710874e-02],\n",
       "        [ 9.45328102e-02],\n",
       "        [-5.97398393e-02],\n",
       "        [-6.61076456e-02],\n",
       "        [ 6.83246627e-02],\n",
       "        [ 3.08588408e-02],\n",
       "        [-6.62181526e-02],\n",
       "        [ 1.22268908e-02],\n",
       "        [-2.27360334e-02],\n",
       "        [ 5.94531819e-02],\n",
       "        [-5.58036640e-02],\n",
       "        [-8.29484537e-02],\n",
       "        [-3.60157713e-02],\n",
       "        [ 5.61497472e-02],\n",
       "        [-2.94754244e-02],\n",
       "        [-5.41317128e-02],\n",
       "        [ 5.53597920e-02],\n",
       "        [ 4.47961129e-02],\n",
       "        [-2.87519284e-02],\n",
       "        [ 3.75665575e-02],\n",
       "        [-4.57259342e-02],\n",
       "        [ 9.86651778e-02],\n",
       "        [-1.19243274e-02],\n",
       "        [ 4.69474271e-02],\n",
       "        [-2.57507339e-02],\n",
       "        [-9.92069691e-02],\n",
       "        [-1.86240934e-02],\n",
       "        [-4.17337678e-02],\n",
       "        [-4.48012948e-02],\n",
       "        [-8.18937272e-02],\n",
       "        [-6.08197823e-02],\n",
       "        [ 9.85420272e-02],\n",
       "        [-6.92655593e-02],\n",
       "        [ 2.88087204e-02],\n",
       "        [-1.01276539e-01],\n",
       "        [ 5.20097185e-03],\n",
       "        [ 5.26461713e-02],\n",
       "        [ 5.90596199e-02],\n",
       "        [-1.11728422e-01],\n",
       "        [-3.54352109e-02],\n",
       "        [ 2.65632831e-02],\n",
       "        [ 1.78323139e-03],\n",
       "        [-3.09044328e-02],\n",
       "        [-8.47556686e-04],\n",
       "        [ 6.19124733e-02],\n",
       "        [ 6.20433912e-02],\n",
       "        [-4.35387250e-03],\n",
       "        [-4.21725027e-02],\n",
       "        [ 4.22585718e-02],\n",
       "        [ 5.74300550e-02],\n",
       "        [-6.18788600e-02],\n",
       "        [-2.80847494e-02],\n",
       "        [ 6.29978180e-02],\n",
       "        [ 3.76882367e-02],\n",
       "        [-2.71107499e-02],\n",
       "        [ 7.94641599e-02],\n",
       "        [-1.29621103e-01],\n",
       "        [-8.67157709e-03],\n",
       "        [-1.07933044e-01],\n",
       "        [-2.38203462e-02],\n",
       "        [ 6.73136767e-03],\n",
       "        [ 7.79823437e-02],\n",
       "        [ 7.24866465e-02],\n",
       "        [ 4.31289822e-02],\n",
       "        [ 5.97379953e-02],\n",
       "        [-8.53054300e-02],\n",
       "        [-8.01592544e-02],\n",
       "        [ 1.14499470e-02],\n",
       "        [ 4.70640399e-02],\n",
       "        [ 2.15853825e-02],\n",
       "        [ 7.57182911e-02],\n",
       "        [-3.97547521e-02],\n",
       "        [-7.49078952e-03],\n",
       "        [ 4.90069985e-02],\n",
       "        [ 4.43500951e-02],\n",
       "        [-3.43369506e-02],\n",
       "        [ 2.83355415e-02],\n",
       "        [-7.65920505e-02],\n",
       "        [ 2.18958966e-03],\n",
       "        [-1.61062703e-02],\n",
       "        [-8.74816030e-02],\n",
       "        [ 9.49436873e-02],\n",
       "        [-1.78578626e-02],\n",
       "        [ 4.53899764e-02],\n",
       "        [ 6.63910732e-02],\n",
       "        [-2.09725695e-03],\n",
       "        [-7.47941136e-02],\n",
       "        [ 9.71456766e-02],\n",
       "        [ 1.10146806e-01],\n",
       "        [ 1.11355849e-01],\n",
       "        [ 5.34117147e-02],\n",
       "        [ 7.20387250e-02],\n",
       "        [ 4.15179394e-02],\n",
       "        [ 8.40171799e-02],\n",
       "        [-4.03861180e-02],\n",
       "        [-1.37578011e-01],\n",
       "        [ 7.15581402e-02],\n",
       "        [-8.25751945e-02],\n",
       "        [ 1.84192061e-02],\n",
       "        [ 5.29450551e-02],\n",
       "        [ 6.51602224e-02],\n",
       "        [-6.91492669e-03],\n",
       "        [-1.79019831e-02],\n",
       "        [ 9.40622985e-02],\n",
       "        [-1.30044660e-02],\n",
       "        [ 4.10945527e-02],\n",
       "        [ 9.04711932e-02],\n",
       "        [-7.63168409e-02],\n",
       "        [-1.12804724e-03],\n",
       "        [ 6.85828626e-02],\n",
       "        [-2.95262225e-02],\n",
       "        [-3.67649901e-03],\n",
       "        [ 1.50068011e-02],\n",
       "        [-4.53383401e-02],\n",
       "        [-6.24965020e-02],\n",
       "        [-3.66318189e-02],\n",
       "        [ 6.93480968e-02],\n",
       "        [ 3.81539911e-02],\n",
       "        [ 7.98539259e-03],\n",
       "        [-2.36596782e-02],\n",
       "        [ 7.43331164e-02],\n",
       "        [-7.99137726e-02],\n",
       "        [ 2.24052444e-02],\n",
       "        [ 1.10896081e-01]], dtype=float32),\n",
       " array([-0.00045553], dtype=float32)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "## Save model file\n",
    "model.save('glove_rnn_imdb.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
